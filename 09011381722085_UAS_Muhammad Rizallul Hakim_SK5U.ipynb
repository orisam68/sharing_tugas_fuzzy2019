{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <font color=\"#25B0BF\"><h2>Muhammad Rizallul Hakim (09011381722085)</h2></font>\n",
    "    <h2><em>Gender Classification Based on Voice data</em></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimorphism adalah sifat suara yang sangat diperhatikan oleh manusia. Intonasi, kecepatan bicara,\n",
    "dan durasi adalah karakteristik tertentu yang membedakan suara manusia, terutama suara pria dan wanita. Dimorfisme yang dirasakan mencakup 98,8% yang terdiri dari jenis kelamin pembicara dan\n",
    "frekuensi masing-masing. Namun, variasi dalam gender tidak dapat diprediksi dengan voice vokal. Beberapa\n",
    "Nada suara dapat bervariasi antara pria dan wanita sehingga sulit untuk memprediksi pria dan wanita secara akurat. Dengan Machine Learning kita dapat mengidentifikasi gender voice masing-masing dengan bantuan\n",
    "teknik yang digunakan untuk pemrosesan ucapan di lingkungan waktu nyata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "Dataset ini dibuat untuk mengidentifikasi suara sebagai pria atau wanita, berdasarkan pada sifat akustik suara dan ucapan.<br>\n",
    "Dataset terdiri dari 3.168 sampel suara yang direkam, dikumpulkan dari pembicara pria dan wanita.<br>\n",
    "Sampel suara pra-diproses oleh analisis akustik dalam R menggunakan seewave dan tuneR Package, dengan rentang frekuensi yang dianalisis dari 0 hz-280 hz (human vocal range)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <font color=\"#000000\"><h3>Properti akustik berikut dari setiap suara diukur dan dimasukkan dalam CSV:</h3>\n",
    "<ol align=\"justify\">\n",
    "    <li>meanfreq: mean frequency (in kHz)</li>\n",
    "    <li>sd: standard deviation of frequency</li>\n",
    "    <li>median: median frequency (in kHz)</li>\n",
    "    <li>Q25: first quantile (in kHz)</li>\n",
    "    <li>Q75: third quantile (in kHz)</li>\n",
    "    <li>IQR: interquantile range (in kHz)</li>\n",
    "    <li>skew: skewness (see note in specprop description)</li>\n",
    "    <li>kurt: kurtosis (see note in specprop description)</li>\n",
    "    <li>sp.ent: spectral entropy</li>\n",
    "    <li>sfm: spectral flatness</li>\n",
    "    <li>mode: mode frequency</li>\n",
    "    <li>centroid: frequency centroid (see specprop)</li>\n",
    "    <li>peakf: peak frequency (frequency wit highest energy)</li>\n",
    "    <li>meanfun: average of fundamental frequency measured across acoustic signal</li>\n",
    "    <li>minfun: minimum fundamental frequency measured across acoustic signal</li>\n",
    "    <li>maxfun: maximum fundamental frequency measured across acoustic signal</li>\n",
    "    <li>meandom: average of dominant frequency measured across acoustic signal</li>\n",
    "    <li>mindom: minimum of dominant frequency measured across acoustic signal</li>\n",
    "    <li>maxdom: maximum of dominant frequency measured across acoustic signal</li>\n",
    "    <li>dfrange: range of dominant frequency measured across acoustic signal</li>\n",
    "    <li>modindx: modulation index. Calculated as the accumulated absolute difference between adjacent measurements of fundamental frequenciesdivided by the frequency range</li>\n",
    "    <li>label: male or female</li>\n",
    "        </ol></font>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Library\n",
    "Pertama yang kita lakukan adalah mengimport library yang akan kita gunakan.\n",
    "### Library Numpy \n",
    "Berfungsi untuk melakukan operasi vektor dan matriks dengan mengolah array dan array multidimensi.\n",
    "### Library Pandas\n",
    "Berfungsi untuk membaca file dataset dalam bentuk .CSV.\n",
    "### Library os\n",
    "Berfungsi untuk berinteraksi langsung dengan sistem operasi.\n",
    "### Library Matplotlib \n",
    "Digunakan untuk visualisasi dataset sehingga memudahkan untuk dipahami.\n",
    "### Library Seaborn\n",
    "Digunakan Untuk Visualisasi Data Secara Statistik.\n",
    "### Library Keras\n",
    "Digunakan Untuk Banyaknya Hidden Layers Yang Digunakan Untuk 1 Data Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['voice.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "print(os.listdir(\"data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "from scipy import interp\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from subprocess import check_output\n",
    "#print(check_output([\"ls\", \"data\"]).decode(\"utf8\"))\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import *\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import *\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. import Dataset\n",
    "Dataset ini memiliki 22 kolom dan 3168  baris dengan 21 kolom sebagai features dan 1 kolom (label) sebagai label yang memiliki value \"male\" dan \"female\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.092666</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>22.423285</td>\n",
       "      <td>634.613855</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>30.757155</td>\n",
       "      <td>1024.927705</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.207955</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>1.232831</td>\n",
       "      <td>4.177296</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.247119</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.206045</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>1.101174</td>\n",
       "      <td>4.333713</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>5.476562</td>\n",
       "      <td>0.208274</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       "2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       "3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       "4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       "\n",
       "          kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
       "0   274.402906  0.893369  0.491918  ...  0.059781  0.084279  0.015702   \n",
       "1   634.613855  0.892193  0.513724  ...  0.066009  0.107937  0.015826   \n",
       "2  1024.927705  0.846389  0.478905  ...  0.077316  0.098706  0.015656   \n",
       "3     4.177296  0.963322  0.727232  ...  0.151228  0.088965  0.017798   \n",
       "4     4.333713  0.971955  0.783568  ...  0.135120  0.106398  0.016931   \n",
       "\n",
       "     maxfun   meandom    mindom    maxdom   dfrange   modindx  label  \n",
       "0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000   male  \n",
       "1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632   male  \n",
       "2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512   male  \n",
       "3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119   male  \n",
       "4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274   male  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd .read_csv('data/voice.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['meanfreq', 'sd', 'median', 'Q25', 'Q75', 'IQR', 'skew', 'kurt',\n",
      "       'sp.ent', 'sfm', 'mode', 'centroid', 'meanfun', 'minfun', 'maxfun',\n",
      "       'meandom', 'mindom', 'maxdom', 'dfrange', 'modindx', 'label'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mengecek apakah ada data kosong\n",
    "Setelah kita menimport dataset ada baiknya kita terlebih dahulu melakukan pegecekaan terhadap dataset kita, apakah data tersebut sudah clear atau masih ada data kosong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada hasil diatas \"0\" yang berarti dataset yang digunakan ini tidak ada data yang kosong atau sudah bersih."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk cara lain bisa juga dengan menggunakan perintah dibawah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female    1584\n",
      "male      1584\n",
      "Name: label, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 21 columns):\n",
      "meanfreq    3168 non-null float64\n",
      "sd          3168 non-null float64\n",
      "median      3168 non-null float64\n",
      "Q25         3168 non-null float64\n",
      "Q75         3168 non-null float64\n",
      "IQR         3168 non-null float64\n",
      "skew        3168 non-null float64\n",
      "kurt        3168 non-null float64\n",
      "sp.ent      3168 non-null float64\n",
      "sfm         3168 non-null float64\n",
      "mode        3168 non-null float64\n",
      "centroid    3168 non-null float64\n",
      "meanfun     3168 non-null float64\n",
      "minfun      3168 non-null float64\n",
      "maxfun      3168 non-null float64\n",
      "meandom     3168 non-null float64\n",
      "mindom      3168 non-null float64\n",
      "maxdom      3168 non-null float64\n",
      "dfrange     3168 non-null float64\n",
      "modindx     3168 non-null float64\n",
      "label       3168 non-null object\n",
      "dtypes: float64(20), object(1)\n",
      "memory usage: 519.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "label_value_count = data.label.value_counts()\n",
    "print(label_value_count)\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terlihat pada hasil diatas bahwa data dengan label \"male\" sebanyak 1584 dan data dengan label \"female\" sebanyak 1584.\n",
    "Dan dapat kita lihat apakah dataset kita sudah bersih atau masih ada data yang kosong. Pada dataset yang digunakan ini, tiap data column sudah bersih. Dapat dilihat dari indikasi \"non-null\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert value dari label dari String menjadi binari\n",
    "Karena value pada label berupa string maka akan diubah dahulu menjadi numerik atau binari, Sehingga menjadi:<br>\n",
    "female = 0,\n",
    "male = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>mode</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.092666</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>22.423285</td>\n",
       "      <td>634.613855</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>30.757155</td>\n",
       "      <td>1024.927705</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.207955</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>1.232831</td>\n",
       "      <td>4.177296</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>0.083878</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.247119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.206045</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>1.101174</td>\n",
       "      <td>4.333713</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>0.104261</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>5.476562</td>\n",
       "      <td>0.208274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       "2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       "3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       "4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       "\n",
       "          kurt    sp.ent       sfm      mode  centroid   meanfun    minfun  \\\n",
       "0   274.402906  0.893369  0.491918  0.000000  0.059781  0.084279  0.015702   \n",
       "1   634.613855  0.892193  0.513724  0.000000  0.066009  0.107937  0.015826   \n",
       "2  1024.927705  0.846389  0.478905  0.000000  0.077316  0.098706  0.015656   \n",
       "3     4.177296  0.963322  0.727232  0.083878  0.151228  0.088965  0.017798   \n",
       "4     4.333713  0.971955  0.783568  0.104261  0.135120  0.106398  0.016931   \n",
       "\n",
       "     maxfun   meandom    mindom    maxdom   dfrange   modindx  \n",
       "0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000  \n",
       "1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632  \n",
       "2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512  \n",
       "3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119  \n",
       "4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {'label':{'male':1,'female':0}}      # label = column name\n",
    "data.replace(dict,inplace = True)           # mengubah = str ke numerical\n",
    "x = data.loc[:, data.columns != 'label']\n",
    "y = data.loc[:,'label']\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualisasi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.label.value_counts()\n",
    "sns.countplot(x=\"label\", data=data, palette=\"bwr\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persentase untuk male : 50.00%\n",
      "Persentase untuk female : 50.00%\n"
     ]
    }
   ],
   "source": [
    "female = len(data[data.label == 0])\n",
    "male = len(data[data.label == 1])\n",
    "print(\"Persentase untuk male : {:.2f}%\".format((male / (len(data.label))*100)))\n",
    "print(\"Persentase untuk female : {:.2f}%\".format((female / (len(data.label))*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terlihat pada Informasi diatas persentase untuk laki-laki sebesar 50% dan persentase untuk perempuan sebesar 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FX505DY\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\FX505DY\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "x = x.as_matrix()\n",
    "y = y.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Splitting dan Modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle  \n",
    "x, y = shuffle(x, y, random_state=1010101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2217\n",
      "634\n",
      "317\n"
     ]
    }
   ],
   "source": [
    "trainX = x[:int(len(x) * 0.7)]\n",
    "trainY = y[:int(len(y) * 0.7)]\n",
    "validateX = x[int(len(x) * 0.7) : int(len(x) * 0.9)]\n",
    "validateY = y[int(len(y) * 0.7) : int(len(y) * 0.9)]\n",
    "testX = x[int(len(x) * 0.9):]\n",
    "testY = y[int(len(y) * 0.9):]\n",
    "\n",
    "print (len(trainX))\n",
    "print (len(validateX))\n",
    "print (len(testX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.array(trainX)\n",
    "trainY = np.array(trainY)\n",
    "validateX = np.array(validateX)\n",
    "validateY = np.array(validateY)\n",
    "testX = np.array(testX)\n",
    "testY = np.array(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2217, 20)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Membuat model Artificial Neural Network dengan 100 hiden layer pertama dan 100 hiden layer kedua dan output 1 layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\FX505DY\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\FX505DY\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\FX505DY\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import backend\n",
    "model = Sequential()\n",
    "model.add(Dense(len(trainX[0]), input_dim=len(trainX[0]), activation='relu')) #Input Dim\n",
    "model.add(Dense(100, activation='relu')) #Hidden Layer Pertama\n",
    "model.add(Dense(100, activation='relu')) #Hidden Layer Kedua\n",
    "model.add(Dense(1, activation='sigmoid')) #Hidden Layer Keluaran (Output Hidden Laayer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meenjalankan ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\FX505DY\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setalah itu kita lakukan fit model. Tahap ini dilakukan proses untuk mendapatkan akurasi dan loss dari dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\FX505DY\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\FX505DY\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 2217 samples, validate on 634 samples\n",
      "Epoch 1/1000\n",
      "2217/2217 [==============================] - 2s 1ms/step - loss: 0.2679 - acc: 0.5061 - val_loss: 0.2706 - val_acc: 0.4826\n",
      "Epoch 2/1000\n",
      "2217/2217 [==============================] - 0s 10us/step - loss: 0.2754 - acc: 0.5034 - val_loss: 0.2603 - val_acc: 0.4826\n",
      "Epoch 3/1000\n",
      "2217/2217 [==============================] - 0s 11us/step - loss: 0.2529 - acc: 0.5273 - val_loss: 0.2513 - val_acc: 0.5836\n",
      "Epoch 4/1000\n",
      "2217/2217 [==============================] - 0s 11us/step - loss: 0.2530 - acc: 0.5882 - val_loss: 0.2530 - val_acc: 0.5741\n",
      "Epoch 5/1000\n",
      "2217/2217 [==============================] - 0s 10us/step - loss: 0.2491 - acc: 0.5553 - val_loss: 0.2450 - val_acc: 0.4858\n",
      "Epoch 6/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.2402 - acc: 0.5268 - val_loss: 0.2461 - val_acc: 0.4811\n",
      "Epoch 7/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.2429 - acc: 0.5241 - val_loss: 0.2435 - val_acc: 0.4890\n",
      "Epoch 8/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.2393 - acc: 0.5282 - val_loss: 0.2413 - val_acc: 0.5110\n",
      "Epoch 9/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.2399 - acc: 0.5602 - val_loss: 0.2445 - val_acc: 0.6025\n",
      "Epoch 10/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.2428 - acc: 0.6134 - val_loss: 0.2415 - val_acc: 0.5631\n",
      "Epoch 11/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.2382 - acc: 0.5674 - val_loss: 0.2374 - val_acc: 0.5221\n",
      "Epoch 12/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.2452 - acc: 0.5165 - val_loss: 0.2354 - val_acc: 0.5899\n",
      "Epoch 13/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.2351 - acc: 0.6202 - val_loss: 0.2390 - val_acc: 0.6104\n",
      "Epoch 14/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.2393 - acc: 0.6297 - val_loss: 0.2364 - val_acc: 0.6278\n",
      "Epoch 15/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.2352 - acc: 0.6301 - val_loss: 0.2334 - val_acc: 0.5789\n",
      "Epoch 16/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.2319 - acc: 0.5728 - val_loss: 0.2314 - val_acc: 0.6215\n",
      "Epoch 17/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.2333 - acc: 0.6382 - val_loss: 0.2394 - val_acc: 0.6530\n",
      "Epoch 18/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.2416 - acc: 0.6766 - val_loss: 0.2403 - val_acc: 0.6609\n",
      "Epoch 19/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.2401 - acc: 0.6730 - val_loss: 0.2376 - val_acc: 0.6057\n",
      "Epoch 20/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.2355 - acc: 0.6202 - val_loss: 0.2325 - val_acc: 0.6073\n",
      "Epoch 21/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.2291 - acc: 0.6171 - val_loss: 0.2240 - val_acc: 0.6530\n",
      "Epoch 22/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.2259 - acc: 0.6531 - val_loss: 0.2211 - val_acc: 0.6498\n",
      "Epoch 23/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.2251 - acc: 0.6419 - val_loss: 0.2234 - val_acc: 0.6451\n",
      "Epoch 24/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.2262 - acc: 0.6585 - val_loss: 0.2241 - val_acc: 0.6388\n",
      "Epoch 25/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.2244 - acc: 0.6464 - val_loss: 0.2237 - val_acc: 0.6167\n",
      "Epoch 26/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.2218 - acc: 0.6450 - val_loss: 0.2158 - val_acc: 0.6672\n",
      "Epoch 27/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.2178 - acc: 0.6576 - val_loss: 0.2124 - val_acc: 0.6782\n",
      "Epoch 28/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.2203 - acc: 0.6631 - val_loss: 0.2216 - val_acc: 0.6640\n",
      "Epoch 29/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.2273 - acc: 0.6761 - val_loss: 0.2241 - val_acc: 0.6609\n",
      "Epoch 30/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.2259 - acc: 0.6766 - val_loss: 0.2265 - val_acc: 0.6435\n",
      "Epoch 31/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.2250 - acc: 0.6626 - val_loss: 0.2193 - val_acc: 0.6640\n",
      "Epoch 32/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.2198 - acc: 0.6883 - val_loss: 0.2129 - val_acc: 0.6609\n",
      "Epoch 33/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.2163 - acc: 0.6951 - val_loss: 0.2077 - val_acc: 0.6735\n",
      "Epoch 34/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.2107 - acc: 0.6955 - val_loss: 0.2043 - val_acc: 0.6814\n",
      "Epoch 35/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.2070 - acc: 0.6793 - val_loss: 0.2000 - val_acc: 0.6940\n",
      "Epoch 36/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.2046 - acc: 0.7009 - val_loss: 0.1961 - val_acc: 0.7050\n",
      "Epoch 37/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.2037 - acc: 0.6973 - val_loss: 0.1958 - val_acc: 0.7003\n",
      "Epoch 38/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.2019 - acc: 0.6906 - val_loss: 0.1971 - val_acc: 0.6972\n",
      "Epoch 39/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.2000 - acc: 0.6910 - val_loss: 0.1916 - val_acc: 0.7066\n",
      "Epoch 40/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1982 - acc: 0.7086 - val_loss: 0.1907 - val_acc: 0.7114\n",
      "Epoch 41/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1969 - acc: 0.7190 - val_loss: 0.1903 - val_acc: 0.6987\n",
      "Epoch 42/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1948 - acc: 0.7185 - val_loss: 0.1878 - val_acc: 0.7050\n",
      "Epoch 43/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1925 - acc: 0.7194 - val_loss: 0.1923 - val_acc: 0.6956\n",
      "Epoch 44/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1977 - acc: 0.7068 - val_loss: 0.1943 - val_acc: 0.7019\n",
      "Epoch 45/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.2048 - acc: 0.7122 - val_loss: 0.2010 - val_acc: 0.7114\n",
      "Epoch 46/1000\n",
      "2217/2217 [==============================] - 0s 6us/step - loss: 0.2050 - acc: 0.7091 - val_loss: 0.2043 - val_acc: 0.6767\n",
      "Epoch 47/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.2032 - acc: 0.7009 - val_loss: 0.1945 - val_acc: 0.6987\n",
      "Epoch 48/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1970 - acc: 0.7240 - val_loss: 0.1865 - val_acc: 0.7019\n",
      "Epoch 49/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1911 - acc: 0.7158 - val_loss: 0.1884 - val_acc: 0.6940\n",
      "Epoch 50/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1891 - acc: 0.7009 - val_loss: 0.1800 - val_acc: 0.7366\n",
      "Epoch 51/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1903 - acc: 0.7402 - val_loss: 0.1825 - val_acc: 0.7350\n",
      "Epoch 52/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1894 - acc: 0.7397 - val_loss: 0.1841 - val_acc: 0.7208\n",
      "Epoch 53/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1868 - acc: 0.7361 - val_loss: 0.1771 - val_acc: 0.7271\n",
      "Epoch 54/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1837 - acc: 0.7424 - val_loss: 0.1734 - val_acc: 0.7192\n",
      "Epoch 55/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1805 - acc: 0.7312 - val_loss: 0.1713 - val_acc: 0.7413\n",
      "Epoch 56/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1821 - acc: 0.7492 - val_loss: 0.1780 - val_acc: 0.7461\n",
      "Epoch 57/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1854 - acc: 0.7470 - val_loss: 0.1901 - val_acc: 0.7098\n",
      "Epoch 58/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1900 - acc: 0.7226 - val_loss: 0.1778 - val_acc: 0.7350\n",
      "Epoch 59/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1835 - acc: 0.7542 - val_loss: 0.1726 - val_acc: 0.7334\n",
      "Epoch 60/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1802 - acc: 0.7452 - val_loss: 0.1710 - val_acc: 0.7256\n",
      "Epoch 61/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1747 - acc: 0.7339 - val_loss: 0.1649 - val_acc: 0.7587\n",
      "Epoch 62/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1709 - acc: 0.7704 - val_loss: 0.1615 - val_acc: 0.7697\n",
      "Epoch 63/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1715 - acc: 0.7749 - val_loss: 0.1713 - val_acc: 0.7587\n",
      "Epoch 64/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1772 - acc: 0.7564 - val_loss: 0.1729 - val_acc: 0.7634\n",
      "Epoch 65/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1777 - acc: 0.7704 - val_loss: 0.1748 - val_acc: 0.7539\n",
      "Epoch 66/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1783 - acc: 0.7587 - val_loss: 0.1760 - val_acc: 0.7303\n",
      "Epoch 67/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1787 - acc: 0.7470 - val_loss: 0.1704 - val_acc: 0.7382\n",
      "Epoch 68/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1744 - acc: 0.7578 - val_loss: 0.1636 - val_acc: 0.7634\n",
      "Epoch 69/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1692 - acc: 0.7686 - val_loss: 0.1589 - val_acc: 0.7650\n",
      "Epoch 70/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1655 - acc: 0.7664 - val_loss: 0.1560 - val_acc: 0.7760\n",
      "Epoch 71/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1655 - acc: 0.7758 - val_loss: 0.1544 - val_acc: 0.7855\n",
      "Epoch 72/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1637 - acc: 0.7912 - val_loss: 0.1551 - val_acc: 0.7918\n",
      "Epoch 73/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1606 - acc: 0.7866 - val_loss: 0.1528 - val_acc: 0.7823\n",
      "Epoch 74/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.1591 - acc: 0.7952 - val_loss: 0.1525 - val_acc: 0.7871\n",
      "Epoch 75/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.1579 - acc: 0.7889 - val_loss: 0.1543 - val_acc: 0.7666\n",
      "Epoch 76/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.1588 - acc: 0.7826 - val_loss: 0.1497 - val_acc: 0.7981\n",
      "Epoch 77/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1561 - acc: 0.8029 - val_loss: 0.1480 - val_acc: 0.8044\n",
      "Epoch 78/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1551 - acc: 0.8038 - val_loss: 0.1480 - val_acc: 0.8044\n",
      "Epoch 79/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1544 - acc: 0.8033 - val_loss: 0.1457 - val_acc: 0.8107\n",
      "Epoch 80/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1533 - acc: 0.8078 - val_loss: 0.1452 - val_acc: 0.8107\n",
      "Epoch 81/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1521 - acc: 0.8069 - val_loss: 0.1471 - val_acc: 0.8076\n",
      "Epoch 82/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.1527 - acc: 0.8033 - val_loss: 0.1446 - val_acc: 0.8123\n",
      "Epoch 83/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1506 - acc: 0.8106 - val_loss: 0.1432 - val_acc: 0.8139\n",
      "Epoch 84/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1510 - acc: 0.8083 - val_loss: 0.1439 - val_acc: 0.8123\n",
      "Epoch 85/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1488 - acc: 0.8101 - val_loss: 0.1397 - val_acc: 0.8218\n",
      "Epoch 86/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1484 - acc: 0.8146 - val_loss: 0.1398 - val_acc: 0.8170\n",
      "Epoch 87/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1475 - acc: 0.8092 - val_loss: 0.1413 - val_acc: 0.8123\n",
      "Epoch 88/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1459 - acc: 0.8119 - val_loss: 0.1381 - val_acc: 0.8218\n",
      "Epoch 89/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1449 - acc: 0.8133 - val_loss: 0.1421 - val_acc: 0.7997\n",
      "Epoch 90/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1440 - acc: 0.8151 - val_loss: 0.1421 - val_acc: 0.8107\n",
      "Epoch 91/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1473 - acc: 0.8056 - val_loss: 0.1393 - val_acc: 0.8170\n",
      "Epoch 92/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1432 - acc: 0.8169 - val_loss: 0.1337 - val_acc: 0.8170\n",
      "Epoch 93/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1424 - acc: 0.8146 - val_loss: 0.1335 - val_acc: 0.8265\n",
      "Epoch 94/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1400 - acc: 0.8241 - val_loss: 0.1397 - val_acc: 0.8091\n",
      "Epoch 95/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1405 - acc: 0.8200 - val_loss: 0.1322 - val_acc: 0.8249\n",
      "Epoch 96/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1399 - acc: 0.8196 - val_loss: 0.1315 - val_acc: 0.8265\n",
      "Epoch 97/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1377 - acc: 0.8200 - val_loss: 0.1360 - val_acc: 0.8218\n",
      "Epoch 98/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1373 - acc: 0.8187 - val_loss: 0.1320 - val_acc: 0.8281\n",
      "Epoch 99/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1355 - acc: 0.8245 - val_loss: 0.1302 - val_acc: 0.8265\n",
      "Epoch 100/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1345 - acc: 0.8281 - val_loss: 0.1288 - val_acc: 0.8344\n",
      "Epoch 101/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1355 - acc: 0.8232 - val_loss: 0.1327 - val_acc: 0.8233\n",
      "Epoch 102/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1362 - acc: 0.8214 - val_loss: 0.1301 - val_acc: 0.8297\n",
      "Epoch 103/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1344 - acc: 0.8309 - val_loss: 0.1293 - val_acc: 0.8281\n",
      "Epoch 104/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1324 - acc: 0.8322 - val_loss: 0.1273 - val_acc: 0.8265\n",
      "Epoch 105/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1307 - acc: 0.8331 - val_loss: 0.1272 - val_acc: 0.8265\n",
      "Epoch 106/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1302 - acc: 0.8300 - val_loss: 0.1292 - val_acc: 0.8360\n",
      "Epoch 107/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1309 - acc: 0.8295 - val_loss: 0.1249 - val_acc: 0.8344\n",
      "Epoch 108/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1290 - acc: 0.8313 - val_loss: 0.1288 - val_acc: 0.8328\n",
      "Epoch 109/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1285 - acc: 0.8345 - val_loss: 0.1218 - val_acc: 0.8344\n",
      "Epoch 110/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1270 - acc: 0.8367 - val_loss: 0.1227 - val_acc: 0.8281\n",
      "Epoch 111/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1260 - acc: 0.8372 - val_loss: 0.1230 - val_acc: 0.8375\n",
      "Epoch 112/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1246 - acc: 0.8403 - val_loss: 0.1205 - val_acc: 0.8407\n",
      "Epoch 113/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1241 - acc: 0.8367 - val_loss: 0.1195 - val_acc: 0.8391\n",
      "Epoch 114/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1245 - acc: 0.8354 - val_loss: 0.1214 - val_acc: 0.8438\n",
      "Epoch 115/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1228 - acc: 0.8403 - val_loss: 0.1190 - val_acc: 0.8438\n",
      "Epoch 116/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1213 - acc: 0.8466 - val_loss: 0.1214 - val_acc: 0.8360\n",
      "Epoch 117/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1228 - acc: 0.8412 - val_loss: 0.1196 - val_acc: 0.8438\n",
      "Epoch 118/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1207 - acc: 0.8417 - val_loss: 0.1381 - val_acc: 0.8233\n",
      "Epoch 119/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1529 - acc: 0.8169 - val_loss: 0.1334 - val_acc: 0.8297\n",
      "Epoch 120/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1522 - acc: 0.8151 - val_loss: 0.1376 - val_acc: 0.8233\n",
      "Epoch 121/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1514 - acc: 0.8088 - val_loss: 0.1438 - val_acc: 0.8233\n",
      "Epoch 122/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1497 - acc: 0.8151 - val_loss: 0.1338 - val_acc: 0.8344\n",
      "Epoch 123/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1472 - acc: 0.8187 - val_loss: 0.1412 - val_acc: 0.8107\n",
      "Epoch 124/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1478 - acc: 0.8182 - val_loss: 0.1337 - val_acc: 0.8297\n",
      "Epoch 125/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1464 - acc: 0.8164 - val_loss: 0.1410 - val_acc: 0.8186\n",
      "Epoch 126/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1392 - acc: 0.8119 - val_loss: 0.1632 - val_acc: 0.8013\n",
      "Epoch 127/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1699 - acc: 0.7880 - val_loss: 0.1722 - val_acc: 0.7886\n",
      "Epoch 128/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1664 - acc: 0.7889 - val_loss: 0.1681 - val_acc: 0.7871\n",
      "Epoch 129/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1570 - acc: 0.7966 - val_loss: 0.1646 - val_acc: 0.7839\n",
      "Epoch 130/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1600 - acc: 0.7907 - val_loss: 0.1633 - val_acc: 0.7697\n",
      "Epoch 131/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.1555 - acc: 0.7871 - val_loss: 0.1534 - val_acc: 0.7886\n",
      "Epoch 132/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1473 - acc: 0.8128 - val_loss: 0.1471 - val_acc: 0.8281\n",
      "Epoch 133/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1462 - acc: 0.8268 - val_loss: 0.1499 - val_acc: 0.8170\n",
      "Epoch 134/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1444 - acc: 0.8300 - val_loss: 0.1438 - val_acc: 0.8281\n",
      "Epoch 135/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1412 - acc: 0.8336 - val_loss: 0.1447 - val_acc: 0.8186\n",
      "Epoch 136/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1406 - acc: 0.8295 - val_loss: 0.1427 - val_acc: 0.8218\n",
      "Epoch 137/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1386 - acc: 0.8313 - val_loss: 0.1386 - val_acc: 0.8265\n",
      "Epoch 138/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.1358 - acc: 0.8381 - val_loss: 0.1426 - val_acc: 0.8249\n",
      "Epoch 139/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1360 - acc: 0.8363 - val_loss: 0.1380 - val_acc: 0.8281\n",
      "Epoch 140/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1345 - acc: 0.8363 - val_loss: 0.1357 - val_acc: 0.8170\n",
      "Epoch 141/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1312 - acc: 0.8466 - val_loss: 0.1344 - val_acc: 0.8281\n",
      "Epoch 142/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1298 - acc: 0.8435 - val_loss: 0.1275 - val_acc: 0.8297\n",
      "Epoch 143/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1278 - acc: 0.8512 - val_loss: 0.1306 - val_acc: 0.8297\n",
      "Epoch 144/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1281 - acc: 0.8444 - val_loss: 0.1218 - val_acc: 0.8454\n",
      "Epoch 145/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1221 - acc: 0.8584 - val_loss: 0.1153 - val_acc: 0.8486\n",
      "Epoch 146/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1189 - acc: 0.8557 - val_loss: 0.1137 - val_acc: 0.8486\n",
      "Epoch 147/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1133 - acc: 0.8593 - val_loss: 0.1071 - val_acc: 0.8580\n",
      "Epoch 148/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1145 - acc: 0.8561 - val_loss: 0.1131 - val_acc: 0.8502\n",
      "Epoch 149/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1154 - acc: 0.8539 - val_loss: 0.1180 - val_acc: 0.8517\n",
      "Epoch 150/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1107 - acc: 0.8633 - val_loss: 0.1040 - val_acc: 0.8659\n",
      "Epoch 151/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1109 - acc: 0.8620 - val_loss: 0.1050 - val_acc: 0.8549\n",
      "Epoch 152/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1081 - acc: 0.8651 - val_loss: 0.1185 - val_acc: 0.8470\n",
      "Epoch 153/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.1100 - acc: 0.8606 - val_loss: 0.1053 - val_acc: 0.8565\n",
      "Epoch 154/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1068 - acc: 0.8638 - val_loss: 0.1059 - val_acc: 0.8596\n",
      "Epoch 155/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1063 - acc: 0.8687 - val_loss: 0.0999 - val_acc: 0.8612\n",
      "Epoch 156/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1015 - acc: 0.8742 - val_loss: 0.1157 - val_acc: 0.8454\n",
      "Epoch 157/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1231 - acc: 0.8453 - val_loss: 0.1299 - val_acc: 0.8281\n",
      "Epoch 158/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1282 - acc: 0.8412 - val_loss: 0.1300 - val_acc: 0.8486\n",
      "Epoch 159/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1192 - acc: 0.8588 - val_loss: 0.1097 - val_acc: 0.8644\n",
      "Epoch 160/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1182 - acc: 0.8552 - val_loss: 0.1094 - val_acc: 0.8470\n",
      "Epoch 161/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1124 - acc: 0.8552 - val_loss: 0.1039 - val_acc: 0.8691\n",
      "Epoch 162/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1064 - acc: 0.8624 - val_loss: 0.1060 - val_acc: 0.8565\n",
      "Epoch 163/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1065 - acc: 0.8665 - val_loss: 0.1071 - val_acc: 0.8644\n",
      "Epoch 164/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1024 - acc: 0.8773 - val_loss: 0.0987 - val_acc: 0.8880\n",
      "Epoch 165/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1027 - acc: 0.8818 - val_loss: 0.0941 - val_acc: 0.8817\n",
      "Epoch 166/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0972 - acc: 0.8836 - val_loss: 0.1011 - val_acc: 0.8596\n",
      "Epoch 167/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0980 - acc: 0.8782 - val_loss: 0.0954 - val_acc: 0.8722\n",
      "Epoch 168/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0994 - acc: 0.8800 - val_loss: 0.1045 - val_acc: 0.8675\n",
      "Epoch 169/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1212 - acc: 0.8430 - val_loss: 0.1247 - val_acc: 0.8375\n",
      "Epoch 170/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1226 - acc: 0.8543 - val_loss: 0.1405 - val_acc: 0.8281\n",
      "Epoch 171/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1239 - acc: 0.8539 - val_loss: 0.1205 - val_acc: 0.8502\n",
      "Epoch 172/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1225 - acc: 0.8525 - val_loss: 0.1132 - val_acc: 0.8454\n",
      "Epoch 173/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1166 - acc: 0.8507 - val_loss: 0.1041 - val_acc: 0.8659\n",
      "Epoch 174/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.1083 - acc: 0.8647 - val_loss: 0.1002 - val_acc: 0.8707\n",
      "Epoch 175/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1050 - acc: 0.8687 - val_loss: 0.1015 - val_acc: 0.8722\n",
      "Epoch 176/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.1001 - acc: 0.8773 - val_loss: 0.0948 - val_acc: 0.8738\n",
      "Epoch 177/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0958 - acc: 0.8872 - val_loss: 0.0951 - val_acc: 0.8943\n",
      "Epoch 178/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0950 - acc: 0.8949 - val_loss: 0.0953 - val_acc: 0.8912\n",
      "Epoch 179/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0934 - acc: 0.8967 - val_loss: 0.0914 - val_acc: 0.8849\n",
      "Epoch 180/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0916 - acc: 0.8899 - val_loss: 0.0893 - val_acc: 0.8817\n",
      "Epoch 181/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0913 - acc: 0.8886 - val_loss: 0.0868 - val_acc: 0.8817\n",
      "Epoch 182/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0906 - acc: 0.8850 - val_loss: 0.0884 - val_acc: 0.8864\n",
      "Epoch 183/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0876 - acc: 0.8976 - val_loss: 0.0885 - val_acc: 0.8991\n",
      "Epoch 184/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0877 - acc: 0.9012 - val_loss: 0.0861 - val_acc: 0.8975\n",
      "Epoch 185/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0866 - acc: 0.9017 - val_loss: 0.0878 - val_acc: 0.8975\n",
      "Epoch 186/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0875 - acc: 0.9012 - val_loss: 0.0865 - val_acc: 0.8991\n",
      "Epoch 187/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0855 - acc: 0.9107 - val_loss: 0.0831 - val_acc: 0.9022\n",
      "Epoch 188/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0849 - acc: 0.9044 - val_loss: 0.0860 - val_acc: 0.9022\n",
      "Epoch 189/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0856 - acc: 0.9125 - val_loss: 0.0854 - val_acc: 0.9022\n",
      "Epoch 190/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0828 - acc: 0.9107 - val_loss: 0.0823 - val_acc: 0.8959\n",
      "Epoch 191/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0833 - acc: 0.9035 - val_loss: 0.0814 - val_acc: 0.9069\n",
      "Epoch 192/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0823 - acc: 0.9084 - val_loss: 0.0849 - val_acc: 0.9085\n",
      "Epoch 193/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0826 - acc: 0.9161 - val_loss: 0.0832 - val_acc: 0.9022\n",
      "Epoch 194/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0803 - acc: 0.9107 - val_loss: 0.0804 - val_acc: 0.9006\n",
      "Epoch 195/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0810 - acc: 0.9048 - val_loss: 0.0823 - val_acc: 0.9054\n",
      "Epoch 196/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0809 - acc: 0.9147 - val_loss: 0.0829 - val_acc: 0.9085\n",
      "Epoch 197/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0787 - acc: 0.9170 - val_loss: 0.0783 - val_acc: 0.9180\n",
      "Epoch 198/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0785 - acc: 0.9179 - val_loss: 0.0778 - val_acc: 0.9117\n",
      "Epoch 199/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0767 - acc: 0.9197 - val_loss: 0.0823 - val_acc: 0.8943\n",
      "Epoch 200/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0785 - acc: 0.9147 - val_loss: 0.0789 - val_acc: 0.9069\n",
      "Epoch 201/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0755 - acc: 0.9197 - val_loss: 0.0766 - val_acc: 0.9227\n",
      "Epoch 202/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0780 - acc: 0.9166 - val_loss: 0.0833 - val_acc: 0.8880\n",
      "Epoch 203/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0793 - acc: 0.9147 - val_loss: 0.0869 - val_acc: 0.9038\n",
      "Epoch 204/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0759 - acc: 0.9283 - val_loss: 0.0782 - val_acc: 0.8927\n",
      "Epoch 205/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0807 - acc: 0.8949 - val_loss: 0.0758 - val_acc: 0.9148\n",
      "Epoch 206/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0759 - acc: 0.9157 - val_loss: 0.0869 - val_acc: 0.8817\n",
      "Epoch 207/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0807 - acc: 0.9066 - val_loss: 0.0781 - val_acc: 0.9148\n",
      "Epoch 208/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0735 - acc: 0.9265 - val_loss: 0.0732 - val_acc: 0.9243\n",
      "Epoch 209/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0743 - acc: 0.9202 - val_loss: 0.0715 - val_acc: 0.9117\n",
      "Epoch 210/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0727 - acc: 0.9157 - val_loss: 0.0799 - val_acc: 0.8896\n",
      "Epoch 211/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0768 - acc: 0.9039 - val_loss: 0.0852 - val_acc: 0.9085\n",
      "Epoch 212/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0789 - acc: 0.9197 - val_loss: 0.0786 - val_acc: 0.8959\n",
      "Epoch 213/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0755 - acc: 0.9147 - val_loss: 0.0802 - val_acc: 0.9259\n",
      "Epoch 214/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0720 - acc: 0.9265 - val_loss: 0.0743 - val_acc: 0.8959\n",
      "Epoch 215/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0727 - acc: 0.9157 - val_loss: 0.0773 - val_acc: 0.9164\n",
      "Epoch 216/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0711 - acc: 0.9283 - val_loss: 0.0724 - val_acc: 0.9006\n",
      "Epoch 217/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0693 - acc: 0.9175 - val_loss: 0.0763 - val_acc: 0.9211\n",
      "Epoch 218/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0688 - acc: 0.9278 - val_loss: 0.0774 - val_acc: 0.8959\n",
      "Epoch 219/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0693 - acc: 0.9197 - val_loss: 0.0691 - val_acc: 0.9353\n",
      "Epoch 220/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0677 - acc: 0.9256 - val_loss: 0.0658 - val_acc: 0.9274\n",
      "Epoch 221/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0664 - acc: 0.9287 - val_loss: 0.0741 - val_acc: 0.8975\n",
      "Epoch 222/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0725 - acc: 0.9129 - val_loss: 0.0754 - val_acc: 0.9180\n",
      "Epoch 223/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0724 - acc: 0.9283 - val_loss: 0.0658 - val_acc: 0.9259\n",
      "Epoch 224/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0677 - acc: 0.9215 - val_loss: 0.0704 - val_acc: 0.9306\n",
      "Epoch 225/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0660 - acc: 0.9292 - val_loss: 0.0739 - val_acc: 0.8943\n",
      "Epoch 226/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0702 - acc: 0.9193 - val_loss: 0.0743 - val_acc: 0.9243\n",
      "Epoch 227/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0666 - acc: 0.9310 - val_loss: 0.0731 - val_acc: 0.8975\n",
      "Epoch 228/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0684 - acc: 0.9215 - val_loss: 0.0732 - val_acc: 0.9227\n",
      "Epoch 229/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0654 - acc: 0.9292 - val_loss: 0.0667 - val_acc: 0.9085\n",
      "Epoch 230/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0634 - acc: 0.9292 - val_loss: 0.0662 - val_acc: 0.9322\n",
      "Epoch 231/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0622 - acc: 0.9287 - val_loss: 0.0628 - val_acc: 0.9290\n",
      "Epoch 232/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0625 - acc: 0.9346 - val_loss: 0.0658 - val_acc: 0.9211\n",
      "Epoch 233/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0610 - acc: 0.9373 - val_loss: 0.0674 - val_acc: 0.9306\n",
      "Epoch 234/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0601 - acc: 0.9427 - val_loss: 0.0644 - val_acc: 0.9227\n",
      "Epoch 235/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0592 - acc: 0.9364 - val_loss: 0.0659 - val_acc: 0.9274\n",
      "Epoch 236/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0592 - acc: 0.9423 - val_loss: 0.0624 - val_acc: 0.9290\n",
      "Epoch 237/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0593 - acc: 0.9382 - val_loss: 0.0600 - val_acc: 0.9306\n",
      "Epoch 238/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0583 - acc: 0.9341 - val_loss: 0.0614 - val_acc: 0.9274\n",
      "Epoch 239/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0574 - acc: 0.9405 - val_loss: 0.0625 - val_acc: 0.9227\n",
      "Epoch 240/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0579 - acc: 0.9387 - val_loss: 0.0603 - val_acc: 0.9259\n",
      "Epoch 241/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0603 - acc: 0.9359 - val_loss: 0.0742 - val_acc: 0.9006\n",
      "Epoch 242/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0701 - acc: 0.9242 - val_loss: 0.0653 - val_acc: 0.9306\n",
      "Epoch 243/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0635 - acc: 0.9337 - val_loss: 0.0603 - val_acc: 0.9322\n",
      "Epoch 244/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0607 - acc: 0.9287 - val_loss: 0.0630 - val_acc: 0.9196\n",
      "Epoch 245/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0611 - acc: 0.9292 - val_loss: 0.0597 - val_acc: 0.9227\n",
      "Epoch 246/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0580 - acc: 0.9328 - val_loss: 0.0624 - val_acc: 0.9211\n",
      "Epoch 247/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0605 - acc: 0.9346 - val_loss: 0.0653 - val_acc: 0.9322\n",
      "Epoch 248/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0579 - acc: 0.9468 - val_loss: 0.0578 - val_acc: 0.9338\n",
      "Epoch 249/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0563 - acc: 0.9391 - val_loss: 0.0608 - val_acc: 0.9196\n",
      "Epoch 250/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0565 - acc: 0.9373 - val_loss: 0.0592 - val_acc: 0.9353\n",
      "Epoch 251/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0564 - acc: 0.9405 - val_loss: 0.0583 - val_acc: 0.9385\n",
      "Epoch 252/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0553 - acc: 0.9472 - val_loss: 0.0558 - val_acc: 0.9416\n",
      "Epoch 253/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0540 - acc: 0.9405 - val_loss: 0.0554 - val_acc: 0.9338\n",
      "Epoch 254/1000\n",
      "2217/2217 [==============================] - ETA: 0s - loss: 0.0551 - acc: 0.946 - 0s 7us/step - loss: 0.0531 - acc: 0.9436 - val_loss: 0.0567 - val_acc: 0.9322\n",
      "Epoch 255/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0540 - acc: 0.9414 - val_loss: 0.0557 - val_acc: 0.9385\n",
      "Epoch 256/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0557 - acc: 0.9423 - val_loss: 0.0656 - val_acc: 0.9227\n",
      "Epoch 257/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0616 - acc: 0.9314 - val_loss: 0.0654 - val_acc: 0.9306\n",
      "Epoch 258/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0562 - acc: 0.9436 - val_loss: 0.0601 - val_acc: 0.9132\n",
      "Epoch 259/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0589 - acc: 0.9278 - val_loss: 0.0847 - val_acc: 0.8943\n",
      "Epoch 260/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0675 - acc: 0.9274 - val_loss: 0.0805 - val_acc: 0.8943\n",
      "Epoch 261/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0740 - acc: 0.9026 - val_loss: 0.0719 - val_acc: 0.9227\n",
      "Epoch 262/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0645 - acc: 0.9373 - val_loss: 0.0579 - val_acc: 0.9306\n",
      "Epoch 263/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0606 - acc: 0.9292 - val_loss: 0.0534 - val_acc: 0.9353\n",
      "Epoch 264/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0539 - acc: 0.9400 - val_loss: 0.0649 - val_acc: 0.9101\n",
      "Epoch 265/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0596 - acc: 0.9310 - val_loss: 0.0550 - val_acc: 0.9401\n",
      "Epoch 266/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0535 - acc: 0.9436 - val_loss: 0.0583 - val_acc: 0.9274\n",
      "Epoch 267/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0562 - acc: 0.9337 - val_loss: 0.0589 - val_acc: 0.9338\n",
      "Epoch 268/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0532 - acc: 0.9477 - val_loss: 0.0557 - val_acc: 0.9385\n",
      "Epoch 269/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0502 - acc: 0.9499 - val_loss: 0.0520 - val_acc: 0.9401\n",
      "Epoch 270/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0500 - acc: 0.9445 - val_loss: 0.0526 - val_acc: 0.9385\n",
      "Epoch 271/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0494 - acc: 0.9513 - val_loss: 0.0533 - val_acc: 0.9432\n",
      "Epoch 272/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0490 - acc: 0.9531 - val_loss: 0.0507 - val_acc: 0.9448\n",
      "Epoch 273/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0480 - acc: 0.9508 - val_loss: 0.0515 - val_acc: 0.9432\n",
      "Epoch 274/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0503 - acc: 0.9414 - val_loss: 0.0546 - val_acc: 0.9416\n",
      "Epoch 275/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0491 - acc: 0.9535 - val_loss: 0.0503 - val_acc: 0.9448\n",
      "Epoch 276/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0490 - acc: 0.9423 - val_loss: 0.0490 - val_acc: 0.9448\n",
      "Epoch 277/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0477 - acc: 0.9490 - val_loss: 0.0532 - val_acc: 0.9416\n",
      "Epoch 278/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0480 - acc: 0.9553 - val_loss: 0.0504 - val_acc: 0.9401\n",
      "Epoch 279/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0492 - acc: 0.9414 - val_loss: 0.0544 - val_acc: 0.9306\n",
      "Epoch 280/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0490 - acc: 0.9477 - val_loss: 0.0514 - val_acc: 0.9416\n",
      "Epoch 281/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0486 - acc: 0.9454 - val_loss: 0.0500 - val_acc: 0.9416\n",
      "Epoch 282/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0507 - acc: 0.9432 - val_loss: 0.0617 - val_acc: 0.9101\n",
      "Epoch 283/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0580 - acc: 0.9323 - val_loss: 0.0548 - val_acc: 0.9385\n",
      "Epoch 284/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0507 - acc: 0.9463 - val_loss: 0.0478 - val_acc: 0.9416\n",
      "Epoch 285/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0494 - acc: 0.9459 - val_loss: 0.0475 - val_acc: 0.9479\n",
      "Epoch 286/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0470 - acc: 0.9513 - val_loss: 0.0502 - val_acc: 0.9432\n",
      "Epoch 287/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0470 - acc: 0.9517 - val_loss: 0.0485 - val_acc: 0.9401\n",
      "Epoch 288/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0476 - acc: 0.9423 - val_loss: 0.0509 - val_acc: 0.9385\n",
      "Epoch 289/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0501 - acc: 0.9463 - val_loss: 0.0546 - val_acc: 0.9385\n",
      "Epoch 290/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0497 - acc: 0.9513 - val_loss: 0.0476 - val_acc: 0.9432\n",
      "Epoch 291/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0490 - acc: 0.9441 - val_loss: 0.0493 - val_acc: 0.9416\n",
      "Epoch 292/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0479 - acc: 0.9490 - val_loss: 0.0538 - val_acc: 0.9338\n",
      "Epoch 293/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0474 - acc: 0.9463 - val_loss: 0.0500 - val_acc: 0.9432\n",
      "Epoch 294/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0500 - acc: 0.9409 - val_loss: 0.0540 - val_acc: 0.9369\n",
      "Epoch 295/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0521 - acc: 0.9459 - val_loss: 0.0543 - val_acc: 0.9353\n",
      "Epoch 296/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0492 - acc: 0.9522 - val_loss: 0.0457 - val_acc: 0.9448\n",
      "Epoch 297/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0496 - acc: 0.9427 - val_loss: 0.0466 - val_acc: 0.9385\n",
      "Epoch 298/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0488 - acc: 0.9418 - val_loss: 0.0569 - val_acc: 0.9338\n",
      "Epoch 299/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0516 - acc: 0.9445 - val_loss: 0.0471 - val_acc: 0.9432\n",
      "Epoch 300/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0471 - acc: 0.9454 - val_loss: 0.0497 - val_acc: 0.9432\n",
      "Epoch 301/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0497 - acc: 0.9432 - val_loss: 0.0584 - val_acc: 0.9322\n",
      "Epoch 302/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0540 - acc: 0.9445 - val_loss: 0.0497 - val_acc: 0.9401\n",
      "Epoch 303/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0457 - acc: 0.9513 - val_loss: 0.0502 - val_acc: 0.9353\n",
      "Epoch 304/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0548 - acc: 0.9296 - val_loss: 0.0487 - val_acc: 0.9416\n",
      "Epoch 305/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0498 - acc: 0.9472 - val_loss: 0.0477 - val_acc: 0.9432\n",
      "Epoch 306/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0474 - acc: 0.9459 - val_loss: 0.0462 - val_acc: 0.9432\n",
      "Epoch 307/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0492 - acc: 0.9441 - val_loss: 0.0446 - val_acc: 0.9479\n",
      "Epoch 308/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0473 - acc: 0.9513 - val_loss: 0.0562 - val_acc: 0.9290\n",
      "Epoch 309/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0486 - acc: 0.9495 - val_loss: 0.0429 - val_acc: 0.9464\n",
      "Epoch 310/1000\n",
      "2217/2217 [==============================] - 0s 10us/step - loss: 0.0478 - acc: 0.9450 - val_loss: 0.0462 - val_acc: 0.9432\n",
      "Epoch 311/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0474 - acc: 0.9454 - val_loss: 0.0574 - val_acc: 0.9227\n",
      "Epoch 312/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0512 - acc: 0.9495 - val_loss: 0.0463 - val_acc: 0.9448\n",
      "Epoch 313/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0445 - acc: 0.9499 - val_loss: 0.0455 - val_acc: 0.9511\n",
      "Epoch 314/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0480 - acc: 0.9432 - val_loss: 0.0515 - val_acc: 0.9385\n",
      "Epoch 315/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0523 - acc: 0.9477 - val_loss: 0.0537 - val_acc: 0.9259\n",
      "Epoch 316/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0534 - acc: 0.9346 - val_loss: 0.0446 - val_acc: 0.9401\n",
      "Epoch 317/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0435 - acc: 0.9531 - val_loss: 0.0429 - val_acc: 0.9527\n",
      "Epoch 318/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0437 - acc: 0.9481 - val_loss: 0.0438 - val_acc: 0.9464\n",
      "Epoch 319/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0429 - acc: 0.9553 - val_loss: 0.0440 - val_acc: 0.9479\n",
      "Epoch 320/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0411 - acc: 0.9549 - val_loss: 0.0442 - val_acc: 0.9495\n",
      "Epoch 321/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0416 - acc: 0.9535 - val_loss: 0.0441 - val_acc: 0.9479\n",
      "Epoch 322/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0415 - acc: 0.9549 - val_loss: 0.0518 - val_acc: 0.9385\n",
      "Epoch 323/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0465 - acc: 0.9499 - val_loss: 0.0542 - val_acc: 0.9322\n",
      "Epoch 324/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0467 - acc: 0.9481 - val_loss: 0.0531 - val_acc: 0.9432\n",
      "Epoch 325/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0458 - acc: 0.9553 - val_loss: 0.0453 - val_acc: 0.9432\n",
      "Epoch 326/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0434 - acc: 0.9513 - val_loss: 0.0503 - val_acc: 0.9416\n",
      "Epoch 327/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0452 - acc: 0.9508 - val_loss: 0.0535 - val_acc: 0.9306\n",
      "Epoch 328/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0482 - acc: 0.9454 - val_loss: 0.0550 - val_acc: 0.9401\n",
      "Epoch 329/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0460 - acc: 0.9504 - val_loss: 0.0433 - val_acc: 0.9543\n",
      "Epoch 330/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0426 - acc: 0.9508 - val_loss: 0.0471 - val_acc: 0.9464\n",
      "Epoch 331/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0423 - acc: 0.9549 - val_loss: 0.0487 - val_acc: 0.9416\n",
      "Epoch 332/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0425 - acc: 0.9531 - val_loss: 0.0544 - val_acc: 0.9416\n",
      "Epoch 333/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0508 - acc: 0.9468 - val_loss: 0.0611 - val_acc: 0.9196\n",
      "Epoch 334/1000\n",
      "2217/2217 [==============================] - 0s 10us/step - loss: 0.0513 - acc: 0.9382 - val_loss: 0.0709 - val_acc: 0.9069\n",
      "Epoch 335/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0527 - acc: 0.9423 - val_loss: 0.0533 - val_acc: 0.9322\n",
      "Epoch 336/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0512 - acc: 0.9414 - val_loss: 0.0447 - val_acc: 0.9448\n",
      "Epoch 337/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0416 - acc: 0.9576 - val_loss: 0.0422 - val_acc: 0.9527\n",
      "Epoch 338/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0427 - acc: 0.9504 - val_loss: 0.0449 - val_acc: 0.9464\n",
      "Epoch 339/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0448 - acc: 0.9499 - val_loss: 0.0423 - val_acc: 0.9511\n",
      "Epoch 340/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0403 - acc: 0.9526 - val_loss: 0.0419 - val_acc: 0.9511\n",
      "Epoch 341/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0383 - acc: 0.9567 - val_loss: 0.0416 - val_acc: 0.9464\n",
      "Epoch 342/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0383 - acc: 0.9576 - val_loss: 0.0413 - val_acc: 0.9511\n",
      "Epoch 343/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0376 - acc: 0.9590 - val_loss: 0.0409 - val_acc: 0.9495\n",
      "Epoch 344/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0378 - acc: 0.9590 - val_loss: 0.0420 - val_acc: 0.9495\n",
      "Epoch 345/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0374 - acc: 0.9608 - val_loss: 0.0395 - val_acc: 0.9527\n",
      "Epoch 346/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0373 - acc: 0.9599 - val_loss: 0.0392 - val_acc: 0.9511\n",
      "Epoch 347/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0370 - acc: 0.9599 - val_loss: 0.0402 - val_acc: 0.9527\n",
      "Epoch 348/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0373 - acc: 0.9585 - val_loss: 0.0524 - val_acc: 0.9401\n",
      "Epoch 349/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0446 - acc: 0.9531 - val_loss: 0.0471 - val_acc: 0.9432\n",
      "Epoch 350/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0419 - acc: 0.9535 - val_loss: 0.0390 - val_acc: 0.9558\n",
      "Epoch 351/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0384 - acc: 0.9576 - val_loss: 0.0385 - val_acc: 0.9527\n",
      "Epoch 352/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0384 - acc: 0.9617 - val_loss: 0.0398 - val_acc: 0.9558\n",
      "Epoch 353/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0369 - acc: 0.9621 - val_loss: 0.0386 - val_acc: 0.9527\n",
      "Epoch 354/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0370 - acc: 0.9599 - val_loss: 0.0425 - val_acc: 0.9511\n",
      "Epoch 355/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0416 - acc: 0.9513 - val_loss: 0.0432 - val_acc: 0.9495\n",
      "Epoch 356/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0391 - acc: 0.9612 - val_loss: 0.0381 - val_acc: 0.9511\n",
      "Epoch 357/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0373 - acc: 0.9590 - val_loss: 0.0381 - val_acc: 0.9527\n",
      "Epoch 358/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0364 - acc: 0.9612 - val_loss: 0.0401 - val_acc: 0.9511\n",
      "Epoch 359/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0371 - acc: 0.9599 - val_loss: 0.0387 - val_acc: 0.9574\n",
      "Epoch 360/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0361 - acc: 0.9635 - val_loss: 0.0382 - val_acc: 0.9543\n",
      "Epoch 361/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0352 - acc: 0.9612 - val_loss: 0.0415 - val_acc: 0.9511\n",
      "Epoch 362/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0388 - acc: 0.9599 - val_loss: 0.0472 - val_acc: 0.9432\n",
      "Epoch 363/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0397 - acc: 0.9576 - val_loss: 0.0390 - val_acc: 0.9543\n",
      "Epoch 364/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0385 - acc: 0.9567 - val_loss: 0.0393 - val_acc: 0.9511\n",
      "Epoch 365/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0366 - acc: 0.9639 - val_loss: 0.0396 - val_acc: 0.9543\n",
      "Epoch 366/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0368 - acc: 0.9603 - val_loss: 0.0469 - val_acc: 0.9432\n",
      "Epoch 367/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0447 - acc: 0.9490 - val_loss: 0.0371 - val_acc: 0.9511\n",
      "Epoch 368/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0410 - acc: 0.9549 - val_loss: 0.0392 - val_acc: 0.9511\n",
      "Epoch 369/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0409 - acc: 0.9508 - val_loss: 0.0386 - val_acc: 0.9495\n",
      "Epoch 370/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0393 - acc: 0.9603 - val_loss: 0.0395 - val_acc: 0.9479\n",
      "Epoch 371/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0372 - acc: 0.9594 - val_loss: 0.0382 - val_acc: 0.9543\n",
      "Epoch 372/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0362 - acc: 0.9612 - val_loss: 0.0407 - val_acc: 0.9511\n",
      "Epoch 373/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0365 - acc: 0.9608 - val_loss: 0.0403 - val_acc: 0.9527\n",
      "Epoch 374/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0357 - acc: 0.9608 - val_loss: 0.0400 - val_acc: 0.9527\n",
      "Epoch 375/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0351 - acc: 0.9635 - val_loss: 0.0410 - val_acc: 0.9527\n",
      "Epoch 376/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0361 - acc: 0.9594 - val_loss: 0.0392 - val_acc: 0.9558\n",
      "Epoch 377/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0359 - acc: 0.9599 - val_loss: 0.0396 - val_acc: 0.9558\n",
      "Epoch 378/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0345 - acc: 0.9639 - val_loss: 0.0396 - val_acc: 0.9527\n",
      "Epoch 379/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0360 - acc: 0.9621 - val_loss: 0.0372 - val_acc: 0.9543\n",
      "Epoch 380/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0367 - acc: 0.9612 - val_loss: 0.0380 - val_acc: 0.9574\n",
      "Epoch 381/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0353 - acc: 0.9626 - val_loss: 0.0380 - val_acc: 0.9558\n",
      "Epoch 382/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0366 - acc: 0.9608 - val_loss: 0.0379 - val_acc: 0.9574\n",
      "Epoch 383/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0368 - acc: 0.9576 - val_loss: 0.0381 - val_acc: 0.9574\n",
      "Epoch 384/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0345 - acc: 0.9662 - val_loss: 0.0398 - val_acc: 0.9479\n",
      "Epoch 385/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0361 - acc: 0.9621 - val_loss: 0.0379 - val_acc: 0.9543\n",
      "Epoch 386/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0340 - acc: 0.9671 - val_loss: 0.0403 - val_acc: 0.9527\n",
      "Epoch 387/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0377 - acc: 0.9558 - val_loss: 0.0419 - val_acc: 0.9495\n",
      "Epoch 388/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0359 - acc: 0.9630 - val_loss: 0.0383 - val_acc: 0.9574\n",
      "Epoch 389/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0343 - acc: 0.9648 - val_loss: 0.0363 - val_acc: 0.9558\n",
      "Epoch 390/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0330 - acc: 0.9635 - val_loss: 0.0372 - val_acc: 0.9574\n",
      "Epoch 391/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0345 - acc: 0.9626 - val_loss: 0.0371 - val_acc: 0.9558\n",
      "Epoch 392/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0339 - acc: 0.9639 - val_loss: 0.0377 - val_acc: 0.9527\n",
      "Epoch 393/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0356 - acc: 0.9617 - val_loss: 0.0403 - val_acc: 0.9543\n",
      "Epoch 394/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0353 - acc: 0.9594 - val_loss: 0.0390 - val_acc: 0.9527\n",
      "Epoch 395/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0371 - acc: 0.9608 - val_loss: 0.0357 - val_acc: 0.9574\n",
      "Epoch 396/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0348 - acc: 0.9653 - val_loss: 0.0360 - val_acc: 0.9543\n",
      "Epoch 397/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0340 - acc: 0.9630 - val_loss: 0.0355 - val_acc: 0.9574\n",
      "Epoch 398/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0335 - acc: 0.9635 - val_loss: 0.0383 - val_acc: 0.9574\n",
      "Epoch 399/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0359 - acc: 0.9590 - val_loss: 0.0362 - val_acc: 0.9574\n",
      "Epoch 400/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0324 - acc: 0.9671 - val_loss: 0.0346 - val_acc: 0.9574\n",
      "Epoch 401/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0329 - acc: 0.9635 - val_loss: 0.0347 - val_acc: 0.9621\n",
      "Epoch 402/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0320 - acc: 0.9680 - val_loss: 0.0354 - val_acc: 0.9637\n",
      "Epoch 403/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0323 - acc: 0.9657 - val_loss: 0.0354 - val_acc: 0.9590\n",
      "Epoch 404/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0335 - acc: 0.9639 - val_loss: 0.0348 - val_acc: 0.9606\n",
      "Epoch 405/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0326 - acc: 0.9684 - val_loss: 0.0367 - val_acc: 0.9606\n",
      "Epoch 406/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0329 - acc: 0.9630 - val_loss: 0.0358 - val_acc: 0.9574\n",
      "Epoch 407/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0322 - acc: 0.9680 - val_loss: 0.0366 - val_acc: 0.9621\n",
      "Epoch 408/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0326 - acc: 0.9666 - val_loss: 0.0370 - val_acc: 0.9558\n",
      "Epoch 409/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0322 - acc: 0.9666 - val_loss: 0.0381 - val_acc: 0.9590\n",
      "Epoch 410/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0343 - acc: 0.9617 - val_loss: 0.0445 - val_acc: 0.9464\n",
      "Epoch 411/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0387 - acc: 0.9599 - val_loss: 0.0461 - val_acc: 0.9495\n",
      "Epoch 412/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0392 - acc: 0.9567 - val_loss: 0.0408 - val_acc: 0.9558\n",
      "Epoch 413/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0355 - acc: 0.9608 - val_loss: 0.0350 - val_acc: 0.9590\n",
      "Epoch 414/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0349 - acc: 0.9635 - val_loss: 0.0367 - val_acc: 0.9574\n",
      "Epoch 415/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0358 - acc: 0.9590 - val_loss: 0.0390 - val_acc: 0.9511\n",
      "Epoch 416/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0355 - acc: 0.9653 - val_loss: 0.0340 - val_acc: 0.9574\n",
      "Epoch 417/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0344 - acc: 0.9617 - val_loss: 0.0346 - val_acc: 0.9543\n",
      "Epoch 418/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0340 - acc: 0.9630 - val_loss: 0.0378 - val_acc: 0.9543\n",
      "Epoch 419/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0380 - acc: 0.9558 - val_loss: 0.0348 - val_acc: 0.9574\n",
      "Epoch 420/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0361 - acc: 0.9617 - val_loss: 0.0431 - val_acc: 0.9495\n",
      "Epoch 421/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0387 - acc: 0.9562 - val_loss: 0.0411 - val_acc: 0.9590\n",
      "Epoch 422/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0373 - acc: 0.9617 - val_loss: 0.0429 - val_acc: 0.9511\n",
      "Epoch 423/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0425 - acc: 0.9504 - val_loss: 0.0391 - val_acc: 0.9558\n",
      "Epoch 424/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0370 - acc: 0.9594 - val_loss: 0.0340 - val_acc: 0.9574\n",
      "Epoch 425/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0324 - acc: 0.9648 - val_loss: 0.0346 - val_acc: 0.9590\n",
      "Epoch 426/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0313 - acc: 0.9662 - val_loss: 0.0336 - val_acc: 0.9590\n",
      "Epoch 427/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0309 - acc: 0.9680 - val_loss: 0.0338 - val_acc: 0.9621\n",
      "Epoch 428/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0312 - acc: 0.9680 - val_loss: 0.0343 - val_acc: 0.9606\n",
      "Epoch 429/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0305 - acc: 0.9693 - val_loss: 0.0331 - val_acc: 0.9606\n",
      "Epoch 430/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0308 - acc: 0.9662 - val_loss: 0.0354 - val_acc: 0.9606\n",
      "Epoch 431/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0317 - acc: 0.9662 - val_loss: 0.0362 - val_acc: 0.9543\n",
      "Epoch 432/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0314 - acc: 0.9666 - val_loss: 0.0351 - val_acc: 0.9606\n",
      "Epoch 433/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0318 - acc: 0.9644 - val_loss: 0.0341 - val_acc: 0.9590\n",
      "Epoch 434/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0309 - acc: 0.9680 - val_loss: 0.0355 - val_acc: 0.9637\n",
      "Epoch 435/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0319 - acc: 0.9671 - val_loss: 0.0363 - val_acc: 0.9543\n",
      "Epoch 436/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0319 - acc: 0.9689 - val_loss: 0.0358 - val_acc: 0.9606\n",
      "Epoch 437/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0321 - acc: 0.9644 - val_loss: 0.0362 - val_acc: 0.9543\n",
      "Epoch 438/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0318 - acc: 0.9675 - val_loss: 0.0344 - val_acc: 0.9653\n",
      "Epoch 439/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0306 - acc: 0.9684 - val_loss: 0.0332 - val_acc: 0.9590\n",
      "Epoch 440/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0327 - acc: 0.9648 - val_loss: 0.0426 - val_acc: 0.9558\n",
      "Epoch 441/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0384 - acc: 0.9576 - val_loss: 0.0481 - val_acc: 0.9401\n",
      "Epoch 442/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0403 - acc: 0.9508 - val_loss: 0.0481 - val_acc: 0.9432\n",
      "Epoch 443/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0382 - acc: 0.9608 - val_loss: 0.0369 - val_acc: 0.9606\n",
      "Epoch 444/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0388 - acc: 0.9549 - val_loss: 0.0387 - val_acc: 0.9558\n",
      "Epoch 445/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0343 - acc: 0.9635 - val_loss: 0.0381 - val_acc: 0.9590\n",
      "Epoch 446/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0354 - acc: 0.9630 - val_loss: 0.0339 - val_acc: 0.9606\n",
      "Epoch 447/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0327 - acc: 0.9648 - val_loss: 0.0352 - val_acc: 0.9590\n",
      "Epoch 448/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0361 - acc: 0.9571 - val_loss: 0.0394 - val_acc: 0.9511\n",
      "Epoch 449/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0373 - acc: 0.9617 - val_loss: 0.0329 - val_acc: 0.9574\n",
      "Epoch 450/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0337 - acc: 0.9621 - val_loss: 0.0354 - val_acc: 0.9543\n",
      "Epoch 451/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0336 - acc: 0.9626 - val_loss: 0.0368 - val_acc: 0.9653\n",
      "Epoch 452/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0334 - acc: 0.9653 - val_loss: 0.0376 - val_acc: 0.9543\n",
      "Epoch 453/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0350 - acc: 0.9635 - val_loss: 0.0393 - val_acc: 0.9574\n",
      "Epoch 454/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0381 - acc: 0.9562 - val_loss: 0.0370 - val_acc: 0.9558\n",
      "Epoch 455/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0331 - acc: 0.9648 - val_loss: 0.0394 - val_acc: 0.9495\n",
      "Epoch 456/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0379 - acc: 0.9558 - val_loss: 0.0345 - val_acc: 0.9558\n",
      "Epoch 457/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0341 - acc: 0.9639 - val_loss: 0.0364 - val_acc: 0.9574\n",
      "Epoch 458/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0371 - acc: 0.9549 - val_loss: 0.0341 - val_acc: 0.9574\n",
      "Epoch 459/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0326 - acc: 0.9684 - val_loss: 0.0327 - val_acc: 0.9606\n",
      "Epoch 460/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0314 - acc: 0.9648 - val_loss: 0.0326 - val_acc: 0.9621\n",
      "Epoch 461/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0296 - acc: 0.9684 - val_loss: 0.0340 - val_acc: 0.9606\n",
      "Epoch 462/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0316 - acc: 0.9675 - val_loss: 0.0354 - val_acc: 0.9574\n",
      "Epoch 463/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0336 - acc: 0.9653 - val_loss: 0.0399 - val_acc: 0.9495\n",
      "Epoch 464/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0362 - acc: 0.9571 - val_loss: 0.0359 - val_acc: 0.9574\n",
      "Epoch 465/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0329 - acc: 0.9675 - val_loss: 0.0350 - val_acc: 0.9574\n",
      "Epoch 466/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0310 - acc: 0.9648 - val_loss: 0.0344 - val_acc: 0.9590\n",
      "Epoch 467/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0304 - acc: 0.9689 - val_loss: 0.0323 - val_acc: 0.9621\n",
      "Epoch 468/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0291 - acc: 0.9680 - val_loss: 0.0330 - val_acc: 0.9637\n",
      "Epoch 469/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0294 - acc: 0.9698 - val_loss: 0.0316 - val_acc: 0.9637\n",
      "Epoch 470/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0284 - acc: 0.9698 - val_loss: 0.0331 - val_acc: 0.9653\n",
      "Epoch 471/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0289 - acc: 0.9720 - val_loss: 0.0339 - val_acc: 0.9637\n",
      "Epoch 472/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0294 - acc: 0.9689 - val_loss: 0.0310 - val_acc: 0.9621\n",
      "Epoch 473/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0297 - acc: 0.9662 - val_loss: 0.0336 - val_acc: 0.9606\n",
      "Epoch 474/1000\n",
      "2217/2217 [==============================] - 0s 10us/step - loss: 0.0350 - acc: 0.9617 - val_loss: 0.0545 - val_acc: 0.9259\n",
      "Epoch 475/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0461 - acc: 0.9445 - val_loss: 0.0535 - val_acc: 0.9353\n",
      "Epoch 476/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0452 - acc: 0.9472 - val_loss: 0.0454 - val_acc: 0.9479\n",
      "Epoch 477/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0521 - acc: 0.9305 - val_loss: 0.0432 - val_acc: 0.9432\n",
      "Epoch 478/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0430 - acc: 0.9517 - val_loss: 0.0400 - val_acc: 0.9574\n",
      "Epoch 479/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0429 - acc: 0.9508 - val_loss: 0.0327 - val_acc: 0.9637\n",
      "Epoch 480/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0360 - acc: 0.9603 - val_loss: 0.0349 - val_acc: 0.9606\n",
      "Epoch 481/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0375 - acc: 0.9562 - val_loss: 0.0377 - val_acc: 0.9527\n",
      "Epoch 482/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0347 - acc: 0.9603 - val_loss: 0.0480 - val_acc: 0.9495\n",
      "Epoch 483/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0375 - acc: 0.9562 - val_loss: 0.0347 - val_acc: 0.9606\n",
      "Epoch 484/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0335 - acc: 0.9594 - val_loss: 0.0360 - val_acc: 0.9574\n",
      "Epoch 485/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0315 - acc: 0.9644 - val_loss: 0.0341 - val_acc: 0.9669\n",
      "Epoch 486/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0309 - acc: 0.9675 - val_loss: 0.0367 - val_acc: 0.9495\n",
      "Epoch 487/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0316 - acc: 0.9671 - val_loss: 0.0335 - val_acc: 0.9590\n",
      "Epoch 488/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0331 - acc: 0.9630 - val_loss: 0.0358 - val_acc: 0.9590\n",
      "Epoch 489/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0318 - acc: 0.9630 - val_loss: 0.0382 - val_acc: 0.9558\n",
      "Epoch 490/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0413 - acc: 0.9472 - val_loss: 0.0369 - val_acc: 0.9558\n",
      "Epoch 491/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0328 - acc: 0.9675 - val_loss: 0.0348 - val_acc: 0.9590\n",
      "Epoch 492/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0336 - acc: 0.9626 - val_loss: 0.0327 - val_acc: 0.9590\n",
      "Epoch 493/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0321 - acc: 0.9630 - val_loss: 0.0341 - val_acc: 0.9606\n",
      "Epoch 494/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0294 - acc: 0.9702 - val_loss: 0.0354 - val_acc: 0.9621\n",
      "Epoch 495/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0312 - acc: 0.9621 - val_loss: 0.0332 - val_acc: 0.9621\n",
      "Epoch 496/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0317 - acc: 0.9648 - val_loss: 0.0368 - val_acc: 0.9558\n",
      "Epoch 497/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0322 - acc: 0.9657 - val_loss: 0.0356 - val_acc: 0.9606\n",
      "Epoch 498/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0306 - acc: 0.9684 - val_loss: 0.0321 - val_acc: 0.9590\n",
      "Epoch 499/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0303 - acc: 0.9648 - val_loss: 0.0315 - val_acc: 0.9637\n",
      "Epoch 500/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0281 - acc: 0.9707 - val_loss: 0.0328 - val_acc: 0.9669\n",
      "Epoch 501/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0291 - acc: 0.9711 - val_loss: 0.0335 - val_acc: 0.9606\n",
      "Epoch 502/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0304 - acc: 0.9693 - val_loss: 0.0308 - val_acc: 0.9653\n",
      "Epoch 503/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0280 - acc: 0.9689 - val_loss: 0.0303 - val_acc: 0.9653\n",
      "Epoch 504/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0271 - acc: 0.9702 - val_loss: 0.0306 - val_acc: 0.9621\n",
      "Epoch 505/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0276 - acc: 0.9693 - val_loss: 0.0314 - val_acc: 0.9669\n",
      "Epoch 506/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0294 - acc: 0.9675 - val_loss: 0.0329 - val_acc: 0.9621\n",
      "Epoch 507/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0303 - acc: 0.9693 - val_loss: 0.0315 - val_acc: 0.9685\n",
      "Epoch 508/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0280 - acc: 0.9684 - val_loss: 0.0321 - val_acc: 0.9653\n",
      "Epoch 509/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0289 - acc: 0.9711 - val_loss: 0.0389 - val_acc: 0.9464\n",
      "Epoch 510/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0328 - acc: 0.9599 - val_loss: 0.0376 - val_acc: 0.9527\n",
      "Epoch 511/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0318 - acc: 0.9662 - val_loss: 0.0310 - val_acc: 0.9621\n",
      "Epoch 512/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0282 - acc: 0.9675 - val_loss: 0.0331 - val_acc: 0.9621\n",
      "Epoch 513/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0292 - acc: 0.9698 - val_loss: 0.0310 - val_acc: 0.9653\n",
      "Epoch 514/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0275 - acc: 0.9702 - val_loss: 0.0324 - val_acc: 0.9606\n",
      "Epoch 515/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0280 - acc: 0.9698 - val_loss: 0.0298 - val_acc: 0.9606\n",
      "Epoch 516/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0270 - acc: 0.9698 - val_loss: 0.0306 - val_acc: 0.9669\n",
      "Epoch 517/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0277 - acc: 0.9720 - val_loss: 0.0311 - val_acc: 0.9653\n",
      "Epoch 518/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0280 - acc: 0.9729 - val_loss: 0.0365 - val_acc: 0.9543\n",
      "Epoch 519/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0318 - acc: 0.9648 - val_loss: 0.0358 - val_acc: 0.9574\n",
      "Epoch 520/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0301 - acc: 0.9693 - val_loss: 0.0361 - val_acc: 0.9558\n",
      "Epoch 521/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0314 - acc: 0.9662 - val_loss: 0.0320 - val_acc: 0.9621\n",
      "Epoch 522/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0280 - acc: 0.9711 - val_loss: 0.0319 - val_acc: 0.9637\n",
      "Epoch 523/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0303 - acc: 0.9644 - val_loss: 0.0315 - val_acc: 0.9653\n",
      "Epoch 524/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0282 - acc: 0.9707 - val_loss: 0.0310 - val_acc: 0.9653\n",
      "Epoch 525/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0279 - acc: 0.9689 - val_loss: 0.0312 - val_acc: 0.9637\n",
      "Epoch 526/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0288 - acc: 0.9689 - val_loss: 0.0336 - val_acc: 0.9621\n",
      "Epoch 527/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0300 - acc: 0.9671 - val_loss: 0.0348 - val_acc: 0.9637\n",
      "Epoch 528/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0288 - acc: 0.9707 - val_loss: 0.0309 - val_acc: 0.9621\n",
      "Epoch 529/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0298 - acc: 0.9662 - val_loss: 0.0308 - val_acc: 0.9637\n",
      "Epoch 530/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0289 - acc: 0.9698 - val_loss: 0.0326 - val_acc: 0.9621\n",
      "Epoch 531/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0275 - acc: 0.9716 - val_loss: 0.0295 - val_acc: 0.9653\n",
      "Epoch 532/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0288 - acc: 0.9671 - val_loss: 0.0311 - val_acc: 0.9637\n",
      "Epoch 533/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0289 - acc: 0.9666 - val_loss: 0.0328 - val_acc: 0.9606\n",
      "Epoch 534/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0298 - acc: 0.9698 - val_loss: 0.0334 - val_acc: 0.9574\n",
      "Epoch 535/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0290 - acc: 0.9711 - val_loss: 0.0389 - val_acc: 0.9527\n",
      "Epoch 536/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0336 - acc: 0.9608 - val_loss: 0.0408 - val_acc: 0.9479\n",
      "Epoch 537/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0352 - acc: 0.9621 - val_loss: 0.0441 - val_acc: 0.9448\n",
      "Epoch 538/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0349 - acc: 0.9617 - val_loss: 0.0347 - val_acc: 0.9606\n",
      "Epoch 539/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0293 - acc: 0.9693 - val_loss: 0.0310 - val_acc: 0.9590\n",
      "Epoch 540/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0297 - acc: 0.9680 - val_loss: 0.0321 - val_acc: 0.9637\n",
      "Epoch 541/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0284 - acc: 0.9698 - val_loss: 0.0314 - val_acc: 0.9685\n",
      "Epoch 542/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0280 - acc: 0.9711 - val_loss: 0.0336 - val_acc: 0.9621\n",
      "Epoch 543/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0304 - acc: 0.9657 - val_loss: 0.0297 - val_acc: 0.9653\n",
      "Epoch 544/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0270 - acc: 0.9720 - val_loss: 0.0303 - val_acc: 0.9637\n",
      "Epoch 545/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0279 - acc: 0.9693 - val_loss: 0.0292 - val_acc: 0.9669\n",
      "Epoch 546/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0291 - acc: 0.9675 - val_loss: 0.0305 - val_acc: 0.9669\n",
      "Epoch 547/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0291 - acc: 0.9662 - val_loss: 0.0333 - val_acc: 0.9606\n",
      "Epoch 548/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0356 - acc: 0.9612 - val_loss: 0.0418 - val_acc: 0.9448\n",
      "Epoch 549/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0370 - acc: 0.9571 - val_loss: 0.0383 - val_acc: 0.9590\n",
      "Epoch 550/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0366 - acc: 0.9590 - val_loss: 0.0299 - val_acc: 0.9606\n",
      "Epoch 551/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0326 - acc: 0.9630 - val_loss: 0.0313 - val_acc: 0.9653\n",
      "Epoch 552/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0307 - acc: 0.9644 - val_loss: 0.0327 - val_acc: 0.9637\n",
      "Epoch 553/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0340 - acc: 0.9635 - val_loss: 0.0336 - val_acc: 0.9606\n",
      "Epoch 554/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0293 - acc: 0.9684 - val_loss: 0.0466 - val_acc: 0.9401\n",
      "Epoch 555/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0367 - acc: 0.9608 - val_loss: 0.0398 - val_acc: 0.9511\n",
      "Epoch 556/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0387 - acc: 0.9549 - val_loss: 0.0410 - val_acc: 0.9432\n",
      "Epoch 557/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0412 - acc: 0.9513 - val_loss: 0.0301 - val_acc: 0.9606\n",
      "Epoch 558/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0348 - acc: 0.9562 - val_loss: 0.0345 - val_acc: 0.9574\n",
      "Epoch 559/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0351 - acc: 0.9594 - val_loss: 0.0318 - val_acc: 0.9606\n",
      "Epoch 560/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0322 - acc: 0.9653 - val_loss: 0.0418 - val_acc: 0.9527\n",
      "Epoch 561/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0319 - acc: 0.9662 - val_loss: 0.0367 - val_acc: 0.9558\n",
      "Epoch 562/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0351 - acc: 0.9590 - val_loss: 0.0333 - val_acc: 0.9574\n",
      "Epoch 563/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0315 - acc: 0.9639 - val_loss: 0.0351 - val_acc: 0.9574\n",
      "Epoch 564/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0311 - acc: 0.9680 - val_loss: 0.0288 - val_acc: 0.9621\n",
      "Epoch 565/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0282 - acc: 0.9671 - val_loss: 0.0305 - val_acc: 0.9621\n",
      "Epoch 566/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0283 - acc: 0.9684 - val_loss: 0.0327 - val_acc: 0.9637\n",
      "Epoch 567/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0293 - acc: 0.9693 - val_loss: 0.0288 - val_acc: 0.9637\n",
      "Epoch 568/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0253 - acc: 0.9738 - val_loss: 0.0286 - val_acc: 0.9685\n",
      "Epoch 569/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0263 - acc: 0.9716 - val_loss: 0.0287 - val_acc: 0.9653\n",
      "Epoch 570/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0254 - acc: 0.9711 - val_loss: 0.0304 - val_acc: 0.9637\n",
      "Epoch 571/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0258 - acc: 0.9743 - val_loss: 0.0287 - val_acc: 0.9653\n",
      "Epoch 572/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0248 - acc: 0.9752 - val_loss: 0.0290 - val_acc: 0.9685\n",
      "Epoch 573/1000\n",
      "2217/2217 [==============================] - ETA: 0s - loss: 0.0247 - acc: 0.974 - 0s 7us/step - loss: 0.0268 - acc: 0.9702 - val_loss: 0.0304 - val_acc: 0.9637\n",
      "Epoch 574/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0264 - acc: 0.9711 - val_loss: 0.0340 - val_acc: 0.9574\n",
      "Epoch 575/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0326 - acc: 0.9662 - val_loss: 0.0320 - val_acc: 0.9606\n",
      "Epoch 576/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0289 - acc: 0.9693 - val_loss: 0.0322 - val_acc: 0.9606\n",
      "Epoch 577/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0300 - acc: 0.9671 - val_loss: 0.0306 - val_acc: 0.9621\n",
      "Epoch 578/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0277 - acc: 0.9653 - val_loss: 0.0383 - val_acc: 0.9479\n",
      "Epoch 579/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0306 - acc: 0.9675 - val_loss: 0.0303 - val_acc: 0.9653\n",
      "Epoch 580/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0289 - acc: 0.9648 - val_loss: 0.0294 - val_acc: 0.9606\n",
      "Epoch 581/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0281 - acc: 0.9693 - val_loss: 0.0329 - val_acc: 0.9590\n",
      "Epoch 582/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0303 - acc: 0.9684 - val_loss: 0.0336 - val_acc: 0.9621\n",
      "Epoch 583/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0306 - acc: 0.9657 - val_loss: 0.0305 - val_acc: 0.9590\n",
      "Epoch 584/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0289 - acc: 0.9675 - val_loss: 0.0303 - val_acc: 0.9637\n",
      "Epoch 585/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0274 - acc: 0.9716 - val_loss: 0.0342 - val_acc: 0.9606\n",
      "Epoch 586/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0322 - acc: 0.9621 - val_loss: 0.0331 - val_acc: 0.9621\n",
      "Epoch 587/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0344 - acc: 0.9626 - val_loss: 0.0315 - val_acc: 0.9543\n",
      "Epoch 588/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0327 - acc: 0.9617 - val_loss: 0.0288 - val_acc: 0.9669\n",
      "Epoch 589/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0282 - acc: 0.9729 - val_loss: 0.0295 - val_acc: 0.9653\n",
      "Epoch 590/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0275 - acc: 0.9707 - val_loss: 0.0302 - val_acc: 0.9590\n",
      "Epoch 591/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0280 - acc: 0.9662 - val_loss: 0.0344 - val_acc: 0.9558\n",
      "Epoch 592/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0284 - acc: 0.9711 - val_loss: 0.0312 - val_acc: 0.9653\n",
      "Epoch 593/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0261 - acc: 0.9738 - val_loss: 0.0396 - val_acc: 0.9527\n",
      "Epoch 594/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0330 - acc: 0.9612 - val_loss: 0.0481 - val_acc: 0.9338\n",
      "Epoch 595/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0354 - acc: 0.9576 - val_loss: 0.0466 - val_acc: 0.9464\n",
      "Epoch 596/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0339 - acc: 0.9608 - val_loss: 0.0395 - val_acc: 0.9511\n",
      "Epoch 597/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0368 - acc: 0.9549 - val_loss: 0.0369 - val_acc: 0.9527\n",
      "Epoch 598/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0323 - acc: 0.9635 - val_loss: 0.0377 - val_acc: 0.9590\n",
      "Epoch 599/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0334 - acc: 0.9621 - val_loss: 0.0313 - val_acc: 0.9621\n",
      "Epoch 600/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0302 - acc: 0.9689 - val_loss: 0.0294 - val_acc: 0.9590\n",
      "Epoch 601/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0284 - acc: 0.9684 - val_loss: 0.0309 - val_acc: 0.9606\n",
      "Epoch 602/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0278 - acc: 0.9675 - val_loss: 0.0300 - val_acc: 0.9621\n",
      "Epoch 603/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0268 - acc: 0.9711 - val_loss: 0.0308 - val_acc: 0.9637\n",
      "Epoch 604/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0284 - acc: 0.9711 - val_loss: 0.0284 - val_acc: 0.9669\n",
      "Epoch 605/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0249 - acc: 0.9720 - val_loss: 0.0284 - val_acc: 0.9653\n",
      "Epoch 606/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0249 - acc: 0.9747 - val_loss: 0.0290 - val_acc: 0.9621\n",
      "Epoch 607/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0264 - acc: 0.9711 - val_loss: 0.0285 - val_acc: 0.9653\n",
      "Epoch 608/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0246 - acc: 0.9752 - val_loss: 0.0294 - val_acc: 0.9637\n",
      "Epoch 609/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0273 - acc: 0.9720 - val_loss: 0.0302 - val_acc: 0.9653\n",
      "Epoch 610/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0253 - acc: 0.9743 - val_loss: 0.0319 - val_acc: 0.9606\n",
      "Epoch 611/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0254 - acc: 0.9734 - val_loss: 0.0354 - val_acc: 0.9511\n",
      "Epoch 612/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0299 - acc: 0.9675 - val_loss: 0.0324 - val_acc: 0.9621\n",
      "Epoch 613/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0275 - acc: 0.9698 - val_loss: 0.0301 - val_acc: 0.9621\n",
      "Epoch 614/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0284 - acc: 0.9671 - val_loss: 0.0308 - val_acc: 0.9637\n",
      "Epoch 615/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0285 - acc: 0.9702 - val_loss: 0.0300 - val_acc: 0.9606\n",
      "Epoch 616/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0288 - acc: 0.9675 - val_loss: 0.0290 - val_acc: 0.9637\n",
      "Epoch 617/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0266 - acc: 0.9707 - val_loss: 0.0275 - val_acc: 0.9669\n",
      "Epoch 618/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0258 - acc: 0.9729 - val_loss: 0.0278 - val_acc: 0.9669\n",
      "Epoch 619/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0253 - acc: 0.9729 - val_loss: 0.0308 - val_acc: 0.9637\n",
      "Epoch 620/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0258 - acc: 0.9725 - val_loss: 0.0316 - val_acc: 0.9606\n",
      "Epoch 621/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0263 - acc: 0.9702 - val_loss: 0.0314 - val_acc: 0.9606\n",
      "Epoch 622/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0263 - acc: 0.9729 - val_loss: 0.0367 - val_acc: 0.9543\n",
      "Epoch 623/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0289 - acc: 0.9648 - val_loss: 0.0344 - val_acc: 0.9606\n",
      "Epoch 624/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0281 - acc: 0.9698 - val_loss: 0.0291 - val_acc: 0.9637\n",
      "Epoch 625/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0267 - acc: 0.9711 - val_loss: 0.0287 - val_acc: 0.9621\n",
      "Epoch 626/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0246 - acc: 0.9765 - val_loss: 0.0294 - val_acc: 0.9637\n",
      "Epoch 627/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0256 - acc: 0.9720 - val_loss: 0.0300 - val_acc: 0.9637\n",
      "Epoch 628/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0256 - acc: 0.9729 - val_loss: 0.0303 - val_acc: 0.9653\n",
      "Epoch 629/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0255 - acc: 0.9747 - val_loss: 0.0295 - val_acc: 0.9637\n",
      "Epoch 630/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0253 - acc: 0.9729 - val_loss: 0.0273 - val_acc: 0.9669\n",
      "Epoch 631/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0241 - acc: 0.9738 - val_loss: 0.0290 - val_acc: 0.9653\n",
      "Epoch 632/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0243 - acc: 0.9743 - val_loss: 0.0290 - val_acc: 0.9653\n",
      "Epoch 633/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0247 - acc: 0.9743 - val_loss: 0.0284 - val_acc: 0.9653\n",
      "Epoch 634/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0246 - acc: 0.9720 - val_loss: 0.0290 - val_acc: 0.9669\n",
      "Epoch 635/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0255 - acc: 0.9725 - val_loss: 0.0272 - val_acc: 0.9685\n",
      "Epoch 636/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0236 - acc: 0.9747 - val_loss: 0.0273 - val_acc: 0.9669\n",
      "Epoch 637/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0238 - acc: 0.9761 - val_loss: 0.0275 - val_acc: 0.9669\n",
      "Epoch 638/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0238 - acc: 0.9752 - val_loss: 0.0273 - val_acc: 0.9685\n",
      "Epoch 639/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0238 - acc: 0.9752 - val_loss: 0.0277 - val_acc: 0.9669\n",
      "Epoch 640/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0236 - acc: 0.9770 - val_loss: 0.0283 - val_acc: 0.9685\n",
      "Epoch 641/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0241 - acc: 0.9756 - val_loss: 0.0282 - val_acc: 0.9669\n",
      "Epoch 642/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0235 - acc: 0.9774 - val_loss: 0.0286 - val_acc: 0.9653\n",
      "Epoch 643/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0274 - acc: 0.9711 - val_loss: 0.0300 - val_acc: 0.9669\n",
      "Epoch 644/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0257 - acc: 0.9729 - val_loss: 0.0277 - val_acc: 0.9669\n",
      "Epoch 645/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0242 - acc: 0.9770 - val_loss: 0.0288 - val_acc: 0.9606\n",
      "Epoch 646/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0263 - acc: 0.9716 - val_loss: 0.0314 - val_acc: 0.9574\n",
      "Epoch 647/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0273 - acc: 0.9693 - val_loss: 0.0297 - val_acc: 0.9621\n",
      "Epoch 648/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0247 - acc: 0.9747 - val_loss: 0.0298 - val_acc: 0.9590\n",
      "Epoch 649/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0272 - acc: 0.9680 - val_loss: 0.0285 - val_acc: 0.9637\n",
      "Epoch 650/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0241 - acc: 0.9761 - val_loss: 0.0352 - val_acc: 0.9590\n",
      "Epoch 651/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0287 - acc: 0.9698 - val_loss: 0.0279 - val_acc: 0.9653\n",
      "Epoch 652/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0248 - acc: 0.9729 - val_loss: 0.0293 - val_acc: 0.9653\n",
      "Epoch 653/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0260 - acc: 0.9729 - val_loss: 0.0336 - val_acc: 0.9590\n",
      "Epoch 654/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0276 - acc: 0.9693 - val_loss: 0.0352 - val_acc: 0.9574\n",
      "Epoch 655/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0275 - acc: 0.9720 - val_loss: 0.0319 - val_acc: 0.9637\n",
      "Epoch 656/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0257 - acc: 0.9716 - val_loss: 0.0320 - val_acc: 0.9590\n",
      "Epoch 657/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0287 - acc: 0.9675 - val_loss: 0.0296 - val_acc: 0.9621\n",
      "Epoch 658/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0247 - acc: 0.9747 - val_loss: 0.0302 - val_acc: 0.9621\n",
      "Epoch 659/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0256 - acc: 0.9725 - val_loss: 0.0289 - val_acc: 0.9637\n",
      "Epoch 660/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0274 - acc: 0.9689 - val_loss: 0.0485 - val_acc: 0.9322\n",
      "Epoch 661/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0374 - acc: 0.9571 - val_loss: 0.0385 - val_acc: 0.9574\n",
      "Epoch 662/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0307 - acc: 0.9680 - val_loss: 0.0318 - val_acc: 0.9590\n",
      "Epoch 663/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0304 - acc: 0.9635 - val_loss: 0.0311 - val_acc: 0.9637\n",
      "Epoch 664/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0260 - acc: 0.9702 - val_loss: 0.0337 - val_acc: 0.9590\n",
      "Epoch 665/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0290 - acc: 0.9698 - val_loss: 0.0302 - val_acc: 0.9637\n",
      "Epoch 666/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0319 - acc: 0.9639 - val_loss: 0.0559 - val_acc: 0.9306\n",
      "Epoch 667/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0448 - acc: 0.9468 - val_loss: 0.0511 - val_acc: 0.9290\n",
      "Epoch 668/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0396 - acc: 0.9567 - val_loss: 0.0293 - val_acc: 0.9637\n",
      "Epoch 669/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0294 - acc: 0.9653 - val_loss: 0.0321 - val_acc: 0.9606\n",
      "Epoch 670/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0284 - acc: 0.9653 - val_loss: 0.0307 - val_acc: 0.9590\n",
      "Epoch 671/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0280 - acc: 0.9693 - val_loss: 0.0282 - val_acc: 0.9669\n",
      "Epoch 672/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0252 - acc: 0.9725 - val_loss: 0.0288 - val_acc: 0.9637\n",
      "Epoch 673/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0254 - acc: 0.9698 - val_loss: 0.0270 - val_acc: 0.9669\n",
      "Epoch 674/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0241 - acc: 0.9729 - val_loss: 0.0290 - val_acc: 0.9653\n",
      "Epoch 675/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0249 - acc: 0.9729 - val_loss: 0.0278 - val_acc: 0.9716\n",
      "Epoch 676/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0233 - acc: 0.9774 - val_loss: 0.0278 - val_acc: 0.9685\n",
      "Epoch 677/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0233 - acc: 0.9761 - val_loss: 0.0284 - val_acc: 0.9637\n",
      "Epoch 678/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0237 - acc: 0.9738 - val_loss: 0.0281 - val_acc: 0.9685\n",
      "Epoch 679/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0237 - acc: 0.9752 - val_loss: 0.0286 - val_acc: 0.9590\n",
      "Epoch 680/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0255 - acc: 0.9702 - val_loss: 0.0279 - val_acc: 0.9669\n",
      "Epoch 681/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0240 - acc: 0.9738 - val_loss: 0.0276 - val_acc: 0.9669\n",
      "Epoch 682/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0240 - acc: 0.9734 - val_loss: 0.0290 - val_acc: 0.9653\n",
      "Epoch 683/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0266 - acc: 0.9707 - val_loss: 0.0278 - val_acc: 0.9653\n",
      "Epoch 684/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0238 - acc: 0.9738 - val_loss: 0.0274 - val_acc: 0.9653\n",
      "Epoch 685/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0227 - acc: 0.9783 - val_loss: 0.0281 - val_acc: 0.9700\n",
      "Epoch 686/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0235 - acc: 0.9756 - val_loss: 0.0269 - val_acc: 0.9700\n",
      "Epoch 687/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0236 - acc: 0.9756 - val_loss: 0.0282 - val_acc: 0.9653\n",
      "Epoch 688/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0238 - acc: 0.9743 - val_loss: 0.0314 - val_acc: 0.9621\n",
      "Epoch 689/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0256 - acc: 0.9743 - val_loss: 0.0323 - val_acc: 0.9606\n",
      "Epoch 690/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0275 - acc: 0.9698 - val_loss: 0.0307 - val_acc: 0.9637\n",
      "Epoch 691/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0251 - acc: 0.9725 - val_loss: 0.0278 - val_acc: 0.9669\n",
      "Epoch 692/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0226 - acc: 0.9765 - val_loss: 0.0295 - val_acc: 0.9637\n",
      "Epoch 693/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0234 - acc: 0.9756 - val_loss: 0.0282 - val_acc: 0.9653\n",
      "Epoch 694/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0228 - acc: 0.9770 - val_loss: 0.0278 - val_acc: 0.9700\n",
      "Epoch 695/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0225 - acc: 0.9774 - val_loss: 0.0274 - val_acc: 0.9685\n",
      "Epoch 696/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0224 - acc: 0.9770 - val_loss: 0.0295 - val_acc: 0.9621\n",
      "Epoch 697/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0251 - acc: 0.9725 - val_loss: 0.0283 - val_acc: 0.9669\n",
      "Epoch 698/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0236 - acc: 0.9761 - val_loss: 0.0298 - val_acc: 0.9606\n",
      "Epoch 699/1000\n",
      "2217/2217 [==============================] - 0s 10us/step - loss: 0.0249 - acc: 0.9752 - val_loss: 0.0326 - val_acc: 0.9558\n",
      "Epoch 700/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0299 - acc: 0.9666 - val_loss: 0.0361 - val_acc: 0.9558\n",
      "Epoch 701/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0283 - acc: 0.9720 - val_loss: 0.0321 - val_acc: 0.9621\n",
      "Epoch 702/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0269 - acc: 0.9725 - val_loss: 0.0293 - val_acc: 0.9590\n",
      "Epoch 703/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0259 - acc: 0.9729 - val_loss: 0.0309 - val_acc: 0.9621\n",
      "Epoch 704/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0280 - acc: 0.9684 - val_loss: 0.0488 - val_acc: 0.9353\n",
      "Epoch 705/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0383 - acc: 0.9553 - val_loss: 0.0351 - val_acc: 0.9558\n",
      "Epoch 706/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0289 - acc: 0.9689 - val_loss: 0.0306 - val_acc: 0.9590\n",
      "Epoch 707/1000\n",
      "2217/2217 [==============================] - 0s 10us/step - loss: 0.0312 - acc: 0.9617 - val_loss: 0.0294 - val_acc: 0.9621\n",
      "Epoch 708/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0261 - acc: 0.9702 - val_loss: 0.0297 - val_acc: 0.9637\n",
      "Epoch 709/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0263 - acc: 0.9729 - val_loss: 0.0289 - val_acc: 0.9653\n",
      "Epoch 710/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0252 - acc: 0.9725 - val_loss: 0.0307 - val_acc: 0.9621\n",
      "Epoch 711/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0265 - acc: 0.9720 - val_loss: 0.0356 - val_acc: 0.9558\n",
      "Epoch 712/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0297 - acc: 0.9684 - val_loss: 0.0349 - val_acc: 0.9574\n",
      "Epoch 713/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0328 - acc: 0.9653 - val_loss: 0.0308 - val_acc: 0.9558\n",
      "Epoch 714/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0283 - acc: 0.9671 - val_loss: 0.0280 - val_acc: 0.9669\n",
      "Epoch 715/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0237 - acc: 0.9756 - val_loss: 0.0279 - val_acc: 0.9669\n",
      "Epoch 716/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0229 - acc: 0.9752 - val_loss: 0.0277 - val_acc: 0.9685\n",
      "Epoch 717/1000\n",
      "2217/2217 [==============================] - ETA: 0s - loss: 0.0222 - acc: 0.979 - 0s 7us/step - loss: 0.0229 - acc: 0.9770 - val_loss: 0.0278 - val_acc: 0.9685\n",
      "Epoch 718/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0226 - acc: 0.9770 - val_loss: 0.0278 - val_acc: 0.9669\n",
      "Epoch 719/1000\n",
      "2217/2217 [==============================] - 0s 10us/step - loss: 0.0220 - acc: 0.9770 - val_loss: 0.0281 - val_acc: 0.9669\n",
      "Epoch 720/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0228 - acc: 0.9761 - val_loss: 0.0272 - val_acc: 0.9700\n",
      "Epoch 721/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0226 - acc: 0.9765 - val_loss: 0.0314 - val_acc: 0.9558\n",
      "Epoch 722/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0254 - acc: 0.9711 - val_loss: 0.0300 - val_acc: 0.9621\n",
      "Epoch 723/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0235 - acc: 0.9756 - val_loss: 0.0302 - val_acc: 0.9637\n",
      "Epoch 724/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0238 - acc: 0.9770 - val_loss: 0.0284 - val_acc: 0.9653\n",
      "Epoch 725/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0248 - acc: 0.9729 - val_loss: 0.0300 - val_acc: 0.9637\n",
      "Epoch 726/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0327 - acc: 0.9639 - val_loss: 0.0514 - val_acc: 0.9274\n",
      "Epoch 727/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0389 - acc: 0.9513 - val_loss: 0.0377 - val_acc: 0.9606\n",
      "Epoch 728/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0321 - acc: 0.9671 - val_loss: 0.0307 - val_acc: 0.9590\n",
      "Epoch 729/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0292 - acc: 0.9680 - val_loss: 0.0304 - val_acc: 0.9606\n",
      "Epoch 730/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0259 - acc: 0.9707 - val_loss: 0.0312 - val_acc: 0.9606\n",
      "Epoch 731/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0251 - acc: 0.9729 - val_loss: 0.0297 - val_acc: 0.9653\n",
      "Epoch 732/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0251 - acc: 0.9720 - val_loss: 0.0342 - val_acc: 0.9574\n",
      "Epoch 733/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0314 - acc: 0.9626 - val_loss: 0.0371 - val_acc: 0.9527\n",
      "Epoch 734/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0344 - acc: 0.9617 - val_loss: 0.0323 - val_acc: 0.9606\n",
      "Epoch 735/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0285 - acc: 0.9716 - val_loss: 0.0290 - val_acc: 0.9685\n",
      "Epoch 736/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0242 - acc: 0.9729 - val_loss: 0.0291 - val_acc: 0.9606\n",
      "Epoch 737/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0258 - acc: 0.9711 - val_loss: 0.0326 - val_acc: 0.9558\n",
      "Epoch 738/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0265 - acc: 0.9702 - val_loss: 0.0298 - val_acc: 0.9637\n",
      "Epoch 739/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0257 - acc: 0.9720 - val_loss: 0.0326 - val_acc: 0.9606\n",
      "Epoch 740/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0337 - acc: 0.9621 - val_loss: 0.0471 - val_acc: 0.9369\n",
      "Epoch 741/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0399 - acc: 0.9508 - val_loss: 0.0485 - val_acc: 0.9385\n",
      "Epoch 742/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0412 - acc: 0.9526 - val_loss: 0.0333 - val_acc: 0.9558\n",
      "Epoch 743/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0425 - acc: 0.9481 - val_loss: 0.0296 - val_acc: 0.9590\n",
      "Epoch 744/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0314 - acc: 0.9639 - val_loss: 0.0331 - val_acc: 0.9527\n",
      "Epoch 745/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0274 - acc: 0.9698 - val_loss: 0.0364 - val_acc: 0.9558\n",
      "Epoch 746/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0302 - acc: 0.9648 - val_loss: 0.0336 - val_acc: 0.9558\n",
      "Epoch 747/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0273 - acc: 0.9707 - val_loss: 0.0290 - val_acc: 0.9669\n",
      "Epoch 748/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0257 - acc: 0.9693 - val_loss: 0.0286 - val_acc: 0.9621\n",
      "Epoch 749/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0256 - acc: 0.9702 - val_loss: 0.0286 - val_acc: 0.9685\n",
      "Epoch 750/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0244 - acc: 0.9743 - val_loss: 0.0285 - val_acc: 0.9637\n",
      "Epoch 751/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0238 - acc: 0.9743 - val_loss: 0.0287 - val_acc: 0.9637\n",
      "Epoch 752/1000\n",
      "2217/2217 [==============================] - ETA: 0s - loss: 0.0192 - acc: 0.980 - 0s 7us/step - loss: 0.0227 - acc: 0.9761 - val_loss: 0.0292 - val_acc: 0.9574\n",
      "Epoch 753/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0223 - acc: 0.9761 - val_loss: 0.0271 - val_acc: 0.9700\n",
      "Epoch 754/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0228 - acc: 0.9761 - val_loss: 0.0270 - val_acc: 0.9700\n",
      "Epoch 755/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0229 - acc: 0.9738 - val_loss: 0.0273 - val_acc: 0.9716\n",
      "Epoch 756/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0226 - acc: 0.9765 - val_loss: 0.0279 - val_acc: 0.9685\n",
      "Epoch 757/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0227 - acc: 0.9756 - val_loss: 0.0274 - val_acc: 0.9700\n",
      "Epoch 758/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0225 - acc: 0.9770 - val_loss: 0.0290 - val_acc: 0.9669\n",
      "Epoch 759/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0234 - acc: 0.9738 - val_loss: 0.0280 - val_acc: 0.9653\n",
      "Epoch 760/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0220 - acc: 0.9783 - val_loss: 0.0271 - val_acc: 0.9685\n",
      "Epoch 761/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0215 - acc: 0.9779 - val_loss: 0.0268 - val_acc: 0.9669\n",
      "Epoch 762/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0223 - acc: 0.9747 - val_loss: 0.0277 - val_acc: 0.9685\n",
      "Epoch 763/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0221 - acc: 0.9774 - val_loss: 0.0289 - val_acc: 0.9637\n",
      "Epoch 764/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0234 - acc: 0.9743 - val_loss: 0.0271 - val_acc: 0.9669\n",
      "Epoch 765/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0230 - acc: 0.9743 - val_loss: 0.0270 - val_acc: 0.9653\n",
      "Epoch 766/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0227 - acc: 0.9761 - val_loss: 0.0282 - val_acc: 0.9700\n",
      "Epoch 767/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0224 - acc: 0.9765 - val_loss: 0.0387 - val_acc: 0.9558\n",
      "Epoch 768/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0316 - acc: 0.9639 - val_loss: 0.0306 - val_acc: 0.9590\n",
      "Epoch 769/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0253 - acc: 0.9734 - val_loss: 0.0344 - val_acc: 0.9558\n",
      "Epoch 770/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0256 - acc: 0.9743 - val_loss: 0.0303 - val_acc: 0.9637\n",
      "Epoch 771/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0258 - acc: 0.9702 - val_loss: 0.0311 - val_acc: 0.9621\n",
      "Epoch 772/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0244 - acc: 0.9734 - val_loss: 0.0314 - val_acc: 0.9606\n",
      "Epoch 773/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0273 - acc: 0.9716 - val_loss: 0.0283 - val_acc: 0.9669\n",
      "Epoch 774/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0235 - acc: 0.9756 - val_loss: 0.0312 - val_acc: 0.9637\n",
      "Epoch 775/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0253 - acc: 0.9729 - val_loss: 0.0280 - val_acc: 0.9606\n",
      "Epoch 776/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0253 - acc: 0.9725 - val_loss: 0.0278 - val_acc: 0.9685\n",
      "Epoch 777/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0225 - acc: 0.9774 - val_loss: 0.0277 - val_acc: 0.9637\n",
      "Epoch 778/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0225 - acc: 0.9783 - val_loss: 0.0271 - val_acc: 0.9685\n",
      "Epoch 779/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0232 - acc: 0.9738 - val_loss: 0.0285 - val_acc: 0.9653\n",
      "Epoch 780/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0235 - acc: 0.9738 - val_loss: 0.0272 - val_acc: 0.9700\n",
      "Epoch 781/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0217 - acc: 0.9783 - val_loss: 0.0267 - val_acc: 0.9669\n",
      "Epoch 782/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0217 - acc: 0.9783 - val_loss: 0.0298 - val_acc: 0.9621\n",
      "Epoch 783/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0249 - acc: 0.9734 - val_loss: 0.0362 - val_acc: 0.9543\n",
      "Epoch 784/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0262 - acc: 0.9725 - val_loss: 0.0311 - val_acc: 0.9637\n",
      "Epoch 785/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0238 - acc: 0.9752 - val_loss: 0.0291 - val_acc: 0.9590\n",
      "Epoch 786/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0237 - acc: 0.9747 - val_loss: 0.0310 - val_acc: 0.9621\n",
      "Epoch 787/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0242 - acc: 0.9734 - val_loss: 0.0301 - val_acc: 0.9621\n",
      "Epoch 788/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0251 - acc: 0.9716 - val_loss: 0.0285 - val_acc: 0.9621\n",
      "Epoch 789/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0237 - acc: 0.9743 - val_loss: 0.0300 - val_acc: 0.9590\n",
      "Epoch 790/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0240 - acc: 0.9747 - val_loss: 0.0291 - val_acc: 0.9669\n",
      "Epoch 791/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0242 - acc: 0.9734 - val_loss: 0.0330 - val_acc: 0.9558\n",
      "Epoch 792/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0266 - acc: 0.9684 - val_loss: 0.0335 - val_acc: 0.9574\n",
      "Epoch 793/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0273 - acc: 0.9698 - val_loss: 0.0447 - val_acc: 0.9369\n",
      "Epoch 794/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0339 - acc: 0.9639 - val_loss: 0.0317 - val_acc: 0.9590\n",
      "Epoch 795/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0269 - acc: 0.9716 - val_loss: 0.0283 - val_acc: 0.9621\n",
      "Epoch 796/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0256 - acc: 0.9698 - val_loss: 0.0308 - val_acc: 0.9606\n",
      "Epoch 797/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0323 - acc: 0.9644 - val_loss: 0.0463 - val_acc: 0.9432\n",
      "Epoch 798/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0385 - acc: 0.9553 - val_loss: 0.0350 - val_acc: 0.9527\n",
      "Epoch 799/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0299 - acc: 0.9693 - val_loss: 0.0321 - val_acc: 0.9637\n",
      "Epoch 800/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0306 - acc: 0.9644 - val_loss: 0.0327 - val_acc: 0.9574\n",
      "Epoch 801/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0287 - acc: 0.9648 - val_loss: 0.0321 - val_acc: 0.9590\n",
      "Epoch 802/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0251 - acc: 0.9747 - val_loss: 0.0306 - val_acc: 0.9621\n",
      "Epoch 803/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0260 - acc: 0.9711 - val_loss: 0.0278 - val_acc: 0.9669\n",
      "Epoch 804/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0230 - acc: 0.9752 - val_loss: 0.0264 - val_acc: 0.9685\n",
      "Epoch 805/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0229 - acc: 0.9761 - val_loss: 0.0271 - val_acc: 0.9716\n",
      "Epoch 806/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0230 - acc: 0.9765 - val_loss: 0.0275 - val_acc: 0.9685\n",
      "Epoch 807/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0223 - acc: 0.9761 - val_loss: 0.0270 - val_acc: 0.9669\n",
      "Epoch 808/1000\n",
      "2217/2217 [==============================] - 0s 10us/step - loss: 0.0226 - acc: 0.9743 - val_loss: 0.0283 - val_acc: 0.9637\n",
      "Epoch 809/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0244 - acc: 0.9743 - val_loss: 0.0313 - val_acc: 0.9606\n",
      "Epoch 810/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0251 - acc: 0.9729 - val_loss: 0.0281 - val_acc: 0.9669\n",
      "Epoch 811/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0243 - acc: 0.9734 - val_loss: 0.0265 - val_acc: 0.9716\n",
      "Epoch 812/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0221 - acc: 0.9765 - val_loss: 0.0278 - val_acc: 0.9669\n",
      "Epoch 813/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0225 - acc: 0.9770 - val_loss: 0.0268 - val_acc: 0.9685\n",
      "Epoch 814/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0212 - acc: 0.9779 - val_loss: 0.0277 - val_acc: 0.9669\n",
      "Epoch 815/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0214 - acc: 0.9783 - val_loss: 0.0282 - val_acc: 0.9653\n",
      "Epoch 816/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0219 - acc: 0.9761 - val_loss: 0.0329 - val_acc: 0.9574\n",
      "Epoch 817/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0259 - acc: 0.9698 - val_loss: 0.0295 - val_acc: 0.9621\n",
      "Epoch 818/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0231 - acc: 0.9765 - val_loss: 0.0293 - val_acc: 0.9653\n",
      "Epoch 819/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0233 - acc: 0.9756 - val_loss: 0.0284 - val_acc: 0.9637\n",
      "Epoch 820/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0229 - acc: 0.9761 - val_loss: 0.0285 - val_acc: 0.9653\n",
      "Epoch 821/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0221 - acc: 0.9765 - val_loss: 0.0276 - val_acc: 0.9685\n",
      "Epoch 822/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0222 - acc: 0.9774 - val_loss: 0.0268 - val_acc: 0.9700\n",
      "Epoch 823/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0208 - acc: 0.9783 - val_loss: 0.0268 - val_acc: 0.9700\n",
      "Epoch 824/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0210 - acc: 0.9788 - val_loss: 0.0264 - val_acc: 0.9685\n",
      "Epoch 825/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0209 - acc: 0.9788 - val_loss: 0.0263 - val_acc: 0.9669\n",
      "Epoch 826/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0209 - acc: 0.9797 - val_loss: 0.0282 - val_acc: 0.9669\n",
      "Epoch 827/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0231 - acc: 0.9743 - val_loss: 0.0275 - val_acc: 0.9669\n",
      "Epoch 828/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0212 - acc: 0.9783 - val_loss: 0.0279 - val_acc: 0.9669\n",
      "Epoch 829/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0218 - acc: 0.9779 - val_loss: 0.0268 - val_acc: 0.9669\n",
      "Epoch 830/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0206 - acc: 0.9788 - val_loss: 0.0292 - val_acc: 0.9606\n",
      "Epoch 831/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0219 - acc: 0.9770 - val_loss: 0.0290 - val_acc: 0.9621\n",
      "Epoch 832/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0222 - acc: 0.9774 - val_loss: 0.0294 - val_acc: 0.9621\n",
      "Epoch 833/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0231 - acc: 0.9752 - val_loss: 0.0303 - val_acc: 0.9621\n",
      "Epoch 834/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0238 - acc: 0.9752 - val_loss: 0.0310 - val_acc: 0.9621\n",
      "Epoch 835/1000\n",
      "2217/2217 [==============================] - ETA: 0s - loss: 0.0236 - acc: 0.975 - 0s 8us/step - loss: 0.0232 - acc: 0.9765 - val_loss: 0.0286 - val_acc: 0.9653\n",
      "Epoch 836/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0226 - acc: 0.9770 - val_loss: 0.0292 - val_acc: 0.9637\n",
      "Epoch 837/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0220 - acc: 0.9774 - val_loss: 0.0273 - val_acc: 0.9669\n",
      "Epoch 838/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0218 - acc: 0.9779 - val_loss: 0.0276 - val_acc: 0.9637\n",
      "Epoch 839/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0220 - acc: 0.9765 - val_loss: 0.0270 - val_acc: 0.9669\n",
      "Epoch 840/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0207 - acc: 0.9793 - val_loss: 0.0265 - val_acc: 0.9669\n",
      "Epoch 841/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0207 - acc: 0.9788 - val_loss: 0.0264 - val_acc: 0.9685\n",
      "Epoch 842/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0205 - acc: 0.9802 - val_loss: 0.0269 - val_acc: 0.9700\n",
      "Epoch 843/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0211 - acc: 0.9788 - val_loss: 0.0268 - val_acc: 0.9669\n",
      "Epoch 844/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0204 - acc: 0.9802 - val_loss: 0.0269 - val_acc: 0.9700\n",
      "Epoch 845/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0207 - acc: 0.9806 - val_loss: 0.0273 - val_acc: 0.9669\n",
      "Epoch 846/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0209 - acc: 0.9793 - val_loss: 0.0273 - val_acc: 0.9685\n",
      "Epoch 847/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0206 - acc: 0.9797 - val_loss: 0.0285 - val_acc: 0.9653\n",
      "Epoch 848/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0254 - acc: 0.9707 - val_loss: 0.0297 - val_acc: 0.9653\n",
      "Epoch 849/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0252 - acc: 0.9743 - val_loss: 0.0288 - val_acc: 0.9653\n",
      "Epoch 850/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0222 - acc: 0.9756 - val_loss: 0.0289 - val_acc: 0.9621\n",
      "Epoch 851/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0239 - acc: 0.9734 - val_loss: 0.0319 - val_acc: 0.9574\n",
      "Epoch 852/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0281 - acc: 0.9684 - val_loss: 0.0348 - val_acc: 0.9527\n",
      "Epoch 853/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0273 - acc: 0.9702 - val_loss: 0.0276 - val_acc: 0.9653\n",
      "Epoch 854/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0239 - acc: 0.9720 - val_loss: 0.0281 - val_acc: 0.9637\n",
      "Epoch 855/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0229 - acc: 0.9743 - val_loss: 0.0309 - val_acc: 0.9590\n",
      "Epoch 856/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0231 - acc: 0.9752 - val_loss: 0.0338 - val_acc: 0.9558\n",
      "Epoch 857/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0275 - acc: 0.9675 - val_loss: 0.0272 - val_acc: 0.9685\n",
      "Epoch 858/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0227 - acc: 0.9761 - val_loss: 0.0279 - val_acc: 0.9653\n",
      "Epoch 859/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0233 - acc: 0.9752 - val_loss: 0.0317 - val_acc: 0.9590\n",
      "Epoch 860/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0248 - acc: 0.9752 - val_loss: 0.0274 - val_acc: 0.9637\n",
      "Epoch 861/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0247 - acc: 0.9738 - val_loss: 0.0272 - val_acc: 0.9669\n",
      "Epoch 862/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0231 - acc: 0.9747 - val_loss: 0.0288 - val_acc: 0.9653\n",
      "Epoch 863/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0257 - acc: 0.9725 - val_loss: 0.0296 - val_acc: 0.9621\n",
      "Epoch 864/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0234 - acc: 0.9752 - val_loss: 0.0274 - val_acc: 0.9637\n",
      "Epoch 865/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0277 - acc: 0.9675 - val_loss: 0.0275 - val_acc: 0.9669\n",
      "Epoch 866/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0238 - acc: 0.9756 - val_loss: 0.0300 - val_acc: 0.9606\n",
      "Epoch 867/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0227 - acc: 0.9761 - val_loss: 0.0282 - val_acc: 0.9621\n",
      "Epoch 868/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0252 - acc: 0.9720 - val_loss: 0.0295 - val_acc: 0.9653\n",
      "Epoch 869/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0231 - acc: 0.9747 - val_loss: 0.0270 - val_acc: 0.9653\n",
      "Epoch 870/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0220 - acc: 0.9774 - val_loss: 0.0281 - val_acc: 0.9637\n",
      "Epoch 871/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0217 - acc: 0.9779 - val_loss: 0.0277 - val_acc: 0.9669\n",
      "Epoch 872/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0213 - acc: 0.9779 - val_loss: 0.0272 - val_acc: 0.9637\n",
      "Epoch 873/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0220 - acc: 0.9783 - val_loss: 0.0273 - val_acc: 0.9700\n",
      "Epoch 874/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0207 - acc: 0.9774 - val_loss: 0.0266 - val_acc: 0.9700\n",
      "Epoch 875/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0213 - acc: 0.9788 - val_loss: 0.0262 - val_acc: 0.9700\n",
      "Epoch 876/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0203 - acc: 0.9793 - val_loss: 0.0263 - val_acc: 0.9700\n",
      "Epoch 877/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0204 - acc: 0.9797 - val_loss: 0.0265 - val_acc: 0.9700\n",
      "Epoch 878/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0202 - acc: 0.9802 - val_loss: 0.0273 - val_acc: 0.9685\n",
      "Epoch 879/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0204 - acc: 0.9793 - val_loss: 0.0267 - val_acc: 0.9685\n",
      "Epoch 880/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0203 - acc: 0.9797 - val_loss: 0.0265 - val_acc: 0.9685\n",
      "Epoch 881/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0204 - acc: 0.9802 - val_loss: 0.0266 - val_acc: 0.9700\n",
      "Epoch 882/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0203 - acc: 0.9788 - val_loss: 0.0278 - val_acc: 0.9669\n",
      "Epoch 883/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0231 - acc: 0.9765 - val_loss: 0.0302 - val_acc: 0.9621\n",
      "Epoch 884/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0235 - acc: 0.9747 - val_loss: 0.0289 - val_acc: 0.9621\n",
      "Epoch 885/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0236 - acc: 0.9743 - val_loss: 0.0271 - val_acc: 0.9685\n",
      "Epoch 886/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0206 - acc: 0.9779 - val_loss: 0.0276 - val_acc: 0.9685\n",
      "Epoch 887/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0211 - acc: 0.9783 - val_loss: 0.0277 - val_acc: 0.9653\n",
      "Epoch 888/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0214 - acc: 0.9774 - val_loss: 0.0292 - val_acc: 0.9637\n",
      "Epoch 889/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0224 - acc: 0.9743 - val_loss: 0.0286 - val_acc: 0.9669\n",
      "Epoch 890/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0208 - acc: 0.9774 - val_loss: 0.0294 - val_acc: 0.9653\n",
      "Epoch 891/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0227 - acc: 0.9765 - val_loss: 0.0277 - val_acc: 0.9653\n",
      "Epoch 892/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0207 - acc: 0.9779 - val_loss: 0.0269 - val_acc: 0.9653\n",
      "Epoch 893/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0213 - acc: 0.9783 - val_loss: 0.0281 - val_acc: 0.9621\n",
      "Epoch 894/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0213 - acc: 0.9793 - val_loss: 0.0279 - val_acc: 0.9669\n",
      "Epoch 895/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0209 - acc: 0.9793 - val_loss: 0.0275 - val_acc: 0.9669\n",
      "Epoch 896/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0205 - acc: 0.9779 - val_loss: 0.0265 - val_acc: 0.9669\n",
      "Epoch 897/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0213 - acc: 0.9783 - val_loss: 0.0273 - val_acc: 0.9669\n",
      "Epoch 898/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0205 - acc: 0.9774 - val_loss: 0.0271 - val_acc: 0.9669\n",
      "Epoch 899/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0203 - acc: 0.9793 - val_loss: 0.0271 - val_acc: 0.9653\n",
      "Epoch 900/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0199 - acc: 0.9802 - val_loss: 0.0268 - val_acc: 0.9700\n",
      "Epoch 901/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0205 - acc: 0.9788 - val_loss: 0.0260 - val_acc: 0.9700\n",
      "Epoch 902/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0199 - acc: 0.9806 - val_loss: 0.0263 - val_acc: 0.9700\n",
      "Epoch 903/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0201 - acc: 0.9797 - val_loss: 0.0266 - val_acc: 0.9700\n",
      "Epoch 904/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0198 - acc: 0.9802 - val_loss: 0.0267 - val_acc: 0.9653\n",
      "Epoch 905/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0201 - acc: 0.9811 - val_loss: 0.0281 - val_acc: 0.9653\n",
      "Epoch 906/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0208 - acc: 0.9783 - val_loss: 0.0277 - val_acc: 0.9685\n",
      "Epoch 907/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0220 - acc: 0.9779 - val_loss: 0.0267 - val_acc: 0.9685\n",
      "Epoch 908/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0203 - acc: 0.9793 - val_loss: 0.0273 - val_acc: 0.9653\n",
      "Epoch 909/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0205 - acc: 0.9788 - val_loss: 0.0272 - val_acc: 0.9669\n",
      "Epoch 910/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0203 - acc: 0.9797 - val_loss: 0.0273 - val_acc: 0.9685\n",
      "Epoch 911/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0205 - acc: 0.9802 - val_loss: 0.0275 - val_acc: 0.9653\n",
      "Epoch 912/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0200 - acc: 0.9788 - val_loss: 0.0272 - val_acc: 0.9700\n",
      "Epoch 913/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0209 - acc: 0.9774 - val_loss: 0.0264 - val_acc: 0.9700\n",
      "Epoch 914/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0199 - acc: 0.9788 - val_loss: 0.0267 - val_acc: 0.9685\n",
      "Epoch 915/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0203 - acc: 0.9788 - val_loss: 0.0270 - val_acc: 0.9685\n",
      "Epoch 916/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0208 - acc: 0.9774 - val_loss: 0.0272 - val_acc: 0.9653\n",
      "Epoch 917/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0198 - acc: 0.9802 - val_loss: 0.0272 - val_acc: 0.9669\n",
      "Epoch 918/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0199 - acc: 0.9802 - val_loss: 0.0297 - val_acc: 0.9637\n",
      "Epoch 919/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0246 - acc: 0.9743 - val_loss: 0.0382 - val_acc: 0.9543\n",
      "Epoch 920/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0275 - acc: 0.9716 - val_loss: 0.0288 - val_acc: 0.9669\n",
      "Epoch 921/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0232 - acc: 0.9752 - val_loss: 0.0297 - val_acc: 0.9574\n",
      "Epoch 922/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0240 - acc: 0.9743 - val_loss: 0.0306 - val_acc: 0.9590\n",
      "Epoch 923/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0224 - acc: 0.9765 - val_loss: 0.0301 - val_acc: 0.9606\n",
      "Epoch 924/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0224 - acc: 0.9765 - val_loss: 0.0273 - val_acc: 0.9669\n",
      "Epoch 925/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0214 - acc: 0.9779 - val_loss: 0.0269 - val_acc: 0.9685\n",
      "Epoch 926/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0200 - acc: 0.9793 - val_loss: 0.0260 - val_acc: 0.9700\n",
      "Epoch 927/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0207 - acc: 0.9788 - val_loss: 0.0281 - val_acc: 0.9669\n",
      "Epoch 928/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0212 - acc: 0.9774 - val_loss: 0.0281 - val_acc: 0.9653\n",
      "Epoch 929/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0220 - acc: 0.9774 - val_loss: 0.0312 - val_acc: 0.9590\n",
      "Epoch 930/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0269 - acc: 0.9702 - val_loss: 0.0311 - val_acc: 0.9606\n",
      "Epoch 931/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0250 - acc: 0.9747 - val_loss: 0.0290 - val_acc: 0.9606\n",
      "Epoch 932/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0278 - acc: 0.9675 - val_loss: 0.0311 - val_acc: 0.9574\n",
      "Epoch 933/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0242 - acc: 0.9734 - val_loss: 0.0327 - val_acc: 0.9574\n",
      "Epoch 934/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0248 - acc: 0.9729 - val_loss: 0.0272 - val_acc: 0.9653\n",
      "Epoch 935/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0225 - acc: 0.9779 - val_loss: 0.0364 - val_acc: 0.9574\n",
      "Epoch 936/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0282 - acc: 0.9666 - val_loss: 0.0293 - val_acc: 0.9653\n",
      "Epoch 937/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0237 - acc: 0.9756 - val_loss: 0.0260 - val_acc: 0.9685\n",
      "Epoch 938/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0221 - acc: 0.9756 - val_loss: 0.0284 - val_acc: 0.9606\n",
      "Epoch 939/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0226 - acc: 0.9743 - val_loss: 0.0266 - val_acc: 0.9653\n",
      "Epoch 940/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0224 - acc: 0.9761 - val_loss: 0.0304 - val_acc: 0.9637\n",
      "Epoch 941/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0233 - acc: 0.9738 - val_loss: 0.0270 - val_acc: 0.9669\n",
      "Epoch 942/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0216 - acc: 0.9765 - val_loss: 0.0283 - val_acc: 0.9621\n",
      "Epoch 943/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0226 - acc: 0.9756 - val_loss: 0.0273 - val_acc: 0.9669\n",
      "Epoch 944/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0225 - acc: 0.9756 - val_loss: 0.0304 - val_acc: 0.9621\n",
      "Epoch 945/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0225 - acc: 0.9761 - val_loss: 0.0291 - val_acc: 0.9606\n",
      "Epoch 946/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0242 - acc: 0.9738 - val_loss: 0.0262 - val_acc: 0.9700\n",
      "Epoch 947/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0212 - acc: 0.9793 - val_loss: 0.0286 - val_acc: 0.9669\n",
      "Epoch 948/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0208 - acc: 0.9779 - val_loss: 0.0270 - val_acc: 0.9653\n",
      "Epoch 949/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0213 - acc: 0.9783 - val_loss: 0.0276 - val_acc: 0.9669\n",
      "Epoch 950/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0207 - acc: 0.9783 - val_loss: 0.0337 - val_acc: 0.9574\n",
      "Epoch 951/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0230 - acc: 0.9756 - val_loss: 0.0299 - val_acc: 0.9669\n",
      "Epoch 952/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0225 - acc: 0.9770 - val_loss: 0.0296 - val_acc: 0.9606\n",
      "Epoch 953/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0233 - acc: 0.9752 - val_loss: 0.0308 - val_acc: 0.9621\n",
      "Epoch 954/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0225 - acc: 0.9752 - val_loss: 0.0312 - val_acc: 0.9590\n",
      "Epoch 955/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0237 - acc: 0.9738 - val_loss: 0.0303 - val_acc: 0.9621\n",
      "Epoch 956/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0216 - acc: 0.9774 - val_loss: 0.0270 - val_acc: 0.9685\n",
      "Epoch 957/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0205 - acc: 0.9779 - val_loss: 0.0265 - val_acc: 0.9685\n",
      "Epoch 958/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0201 - acc: 0.9779 - val_loss: 0.0286 - val_acc: 0.9669\n",
      "Epoch 959/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0204 - acc: 0.9783 - val_loss: 0.0266 - val_acc: 0.9685\n",
      "Epoch 960/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0200 - acc: 0.9806 - val_loss: 0.0263 - val_acc: 0.9700\n",
      "Epoch 961/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0201 - acc: 0.9802 - val_loss: 0.0293 - val_acc: 0.9653\n",
      "Epoch 962/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0219 - acc: 0.9770 - val_loss: 0.0279 - val_acc: 0.9685\n",
      "Epoch 963/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0209 - acc: 0.9783 - val_loss: 0.0278 - val_acc: 0.9685\n",
      "Epoch 964/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0208 - acc: 0.9765 - val_loss: 0.0304 - val_acc: 0.9637\n",
      "Epoch 965/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0222 - acc: 0.9765 - val_loss: 0.0313 - val_acc: 0.9621\n",
      "Epoch 966/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0245 - acc: 0.9743 - val_loss: 0.0279 - val_acc: 0.9653\n",
      "Epoch 967/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0218 - acc: 0.9765 - val_loss: 0.0296 - val_acc: 0.9653\n",
      "Epoch 968/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0221 - acc: 0.9765 - val_loss: 0.0284 - val_acc: 0.9637\n",
      "Epoch 969/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0211 - acc: 0.9779 - val_loss: 0.0315 - val_acc: 0.9590\n",
      "Epoch 970/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0213 - acc: 0.9774 - val_loss: 0.0303 - val_acc: 0.9590\n",
      "Epoch 971/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0234 - acc: 0.9747 - val_loss: 0.0270 - val_acc: 0.9716\n",
      "Epoch 972/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0206 - acc: 0.9774 - val_loss: 0.0261 - val_acc: 0.9716\n",
      "Epoch 973/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0203 - acc: 0.9793 - val_loss: 0.0264 - val_acc: 0.9685\n",
      "Epoch 974/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0197 - acc: 0.9797 - val_loss: 0.0278 - val_acc: 0.9653\n",
      "Epoch 975/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0208 - acc: 0.9793 - val_loss: 0.0267 - val_acc: 0.9653\n",
      "Epoch 976/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0197 - acc: 0.9806 - val_loss: 0.0265 - val_acc: 0.9669\n",
      "Epoch 977/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0197 - acc: 0.9811 - val_loss: 0.0266 - val_acc: 0.9700\n",
      "Epoch 978/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0196 - acc: 0.9783 - val_loss: 0.0269 - val_acc: 0.9653\n",
      "Epoch 979/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0194 - acc: 0.9793 - val_loss: 0.0267 - val_acc: 0.9653\n",
      "Epoch 980/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0191 - acc: 0.9811 - val_loss: 0.0270 - val_acc: 0.9669\n",
      "Epoch 981/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0198 - acc: 0.9811 - val_loss: 0.0281 - val_acc: 0.9653\n",
      "Epoch 982/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0220 - acc: 0.9765 - val_loss: 0.0316 - val_acc: 0.9653\n",
      "Epoch 983/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0224 - acc: 0.9774 - val_loss: 0.0287 - val_acc: 0.9653\n",
      "Epoch 984/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0207 - acc: 0.9793 - val_loss: 0.0276 - val_acc: 0.9637\n",
      "Epoch 985/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0213 - acc: 0.9779 - val_loss: 0.0283 - val_acc: 0.9653\n",
      "Epoch 986/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0198 - acc: 0.9802 - val_loss: 0.0314 - val_acc: 0.9558\n",
      "Epoch 987/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0220 - acc: 0.9761 - val_loss: 0.0286 - val_acc: 0.9637\n",
      "Epoch 988/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0204 - acc: 0.9788 - val_loss: 0.0328 - val_acc: 0.9558\n",
      "Epoch 989/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0236 - acc: 0.9747 - val_loss: 0.0308 - val_acc: 0.9606\n",
      "Epoch 990/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0230 - acc: 0.9747 - val_loss: 0.0274 - val_acc: 0.9685\n",
      "Epoch 991/1000\n",
      "2217/2217 [==============================] - 0s 7us/step - loss: 0.0205 - acc: 0.9779 - val_loss: 0.0301 - val_acc: 0.9621\n",
      "Epoch 992/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0210 - acc: 0.9770 - val_loss: 0.0275 - val_acc: 0.9653\n",
      "Epoch 993/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0201 - acc: 0.9797 - val_loss: 0.0284 - val_acc: 0.9653\n",
      "Epoch 994/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0196 - acc: 0.9779 - val_loss: 0.0274 - val_acc: 0.9685\n",
      "Epoch 995/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0199 - acc: 0.9793 - val_loss: 0.0267 - val_acc: 0.9700\n",
      "Epoch 996/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0197 - acc: 0.9811 - val_loss: 0.0274 - val_acc: 0.9685\n",
      "Epoch 997/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0201 - acc: 0.9779 - val_loss: 0.0311 - val_acc: 0.9621\n",
      "Epoch 998/1000\n",
      "2217/2217 [==============================] - 0s 9us/step - loss: 0.0222 - acc: 0.9761 - val_loss: 0.0276 - val_acc: 0.9669\n",
      "Epoch 999/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0200 - acc: 0.9774 - val_loss: 0.0268 - val_acc: 0.9685\n",
      "Epoch 1000/1000\n",
      "2217/2217 [==============================] - 0s 8us/step - loss: 0.0209 - acc: 0.9783 - val_loss: 0.0278 - val_acc: 0.9685\n"
     ]
    }
   ],
   "source": [
    "acc_training = model.fit(trainX, trainY, epochs=1000, batch_size=1000, validation_data = (validateX, validateY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah data di training, lalu data dapat dievaluasi melalui proses evaluasi model dan hasil dari akurasi akan dapat ditampilkan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634/634 [==============================] - 0s 43us/step\n",
      "akurasinya adalah 96.85%\n",
      "Test Loss: 2.78%\n"
     ]
    }
   ],
   "source": [
    "acc_testing  = model.evaluate(validateX, validateY) \n",
    "print('akurasinya adalah {:.2f}%\\nTest Loss: {:.2f}%'.format(acc_testing[1]*100,acc_testing[0]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Plotting Model Akurasi dan Loss Akurasi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tahap ini untuk melihat visualisasi dari data yang sudah di trainning tadi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">Perintah dibawah ini untuk menampilkan Grafik Dari Akurasi.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1d057381b08>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAFNCAYAAAApR1icAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOydd3gUVRfG35sCCaGEEEpC7yWU0EORIr0oCiJFBATkQ5SioqKIYENFFCwooiACSlEBEaWDIL330EMPkETSE0iy5/vj7OzMZHfTSEiA83ueeXbmtrk7M7vzzplzz1VEBEEQBEEQBEEQMoZLbndAEARBEARBEO4nREALgiAIgiAIQiYQAS0IgiAIgiAImUAEtCAIgiAIgiBkAhHQgiAIgiAIgpAJREALgiAIgiAIQiYQAS0IgpDLKKUqKKVIKeWWgbKDlVLb7kW/BEEQBMeIgBYEQcgESqkLSqk7SinfVOmHrCK4Qu70zNQXL6VUrFLq79zuiyAIwoOICGhBEITMEwKgn7ahlKoDwDP3umPHUwBuA+iolPK7lzvOiBVdEAThfkcEtCAIQuZZAGCgYXsQgPnGAkqpIkqp+UqpMKXURaXU20opF2ueq1JqmlIqXCl1HkA3B3XnKKVClVJXlVIfKKVcM9G/QQBmATgC4JlUbZdVSi2z9itCKfW1Ie95pVSwUipGKXVCKdXAmk5KqSqGcvOUUh9Y19sopa4opd5QSl0H8KNSqqhSapV1H7es62UM9X2UUj8qpa5Z81dY048ppR4zlHO3HqPATHx3QRCEHEcEtCAIQubZBaCwUqqmVdj2AbAwVZmvABQBUAlAa7Dgfs6a9zyA7gDqA2gEthgb+QlAMoAq1jIdAQzLSMeUUuUAtAHws3UZaMhzBbAKwEUAFQCUBrDYmtcbwGRr+cIAHgcQkZF9AigFwAdAeQDDwfeWH63b5QAkAPjaUH4BgAIAAgCUADDdmj4fwABDua4AQonoUAb7IQiCcE+QV22CIAhZQ7NCbwFwEsBVLcMgqusTUQyAGKXUZwCeBTAHwNMAZhDRZWv5j8CiF0qpkgC6APAmogQAcUqp6WBh+l0G+jUQwBEiOqGUigQwVSlVn4gOAmgCwB/Aa0SUbC2vDUgcBmAqEe21bp/NxLGwAJhERLet2wkAfjccjw8BbLau+1m/XzEiumUtssX6uRDARKVUYSKKBh+vBZnohyAIwj1BBLQgCELWWABgK4CKSOW+AcAXQD6wpVfjItjiC7CIvZwqT6M8AHcAoUopLc0lVfm0GAjgewAgomtKqS1gl46DAMoCuGgQz0bKAjiXwX2kJoyIErUNpVQBsFW5M4Ci1uRC1geLsgD+M4hnG9b+bgfQSym1HCy0x2SxT4IgCDmGuHAIgiBkASK6CB5M2BXAslTZ4QCSwGJYoxx0K3UoWEga8zQugwcA+hKRt3UpTEQB6fVJKdUcQFUAbyqlrlt9kpsC6Gcd3HcZQDknA/0uA6jspOl4sMuFRqlU+ZRq+1UA1QE0JaLCAFppXbTux0cp5e1kXz+B3Th6A9hJRFedlBMEQcg1REALgiBknaEAHiWiOGMiEaUAWArgQ6VUIaVUeQCvQPeTXgpgtFKqjFKqKIDxhrqhANYB+EwpVVgp5aKUqqyUap2B/gwCsB5ALQCB1qU2WPx2AbAHLN4/toa681BKtbDW/QHAOKVUQ8VUsfYbAA4B6G8d/NgZ7NOdFoXAbhyRSikfAJNSfb/VAL6xDjZ0V0q1MtRdAaAB2PKc2rIvCIKQJxABLQiCkEWI6BwR7XOSPQpAHIDzYD/jXwDMteZ9D2AtgMMADsDegj0Q7AJyAsAtAL8BSDMcnVLKA+xb/RURXTcsIWB3k0FWYf8YeHDiJQBXwL7aIKJfAXxo7WcMWMj6WJsfY60XCY7qsSKtvgCYAQ7rFw4ecLkmVf6zYAv9SQA3AYzVMqx+37+DXWNSHxdBEIQ8gSJK/eZNEARBEHIPpdQ7AKoR0YB0CwuCIOQCMohQEARByDNYXT6Ggq3UgiAIeRJx4RAEQRDyBEqp58GDDFcT0dbc7o8gCIIzxIVDEARBEARBEDKBWKAFQRAEQRAEIRPkmIBWSs1VSt1USh1zkq+UUl8qpc4qpY4opRrkVF8EQRAEQRAEIbvIyUGE8wB8DedxPLuAA/5XBQf6/9b6mSa+vr5UoUKF7OmhIAiCIAiCIDhh//794URUPHV6jgloItqqlKqQRpEeAOYTO2HvUkp5K6X8rEH2nVKhQgXs2+cs7KogCIIgCIIgZA9KqYuO0nPTB7o0eLS1xhVrmiAIgiAIgiDkWXJTQCsHaQ5Dgiilhiul9iml9oWFheVwtwRBEARBEATBObkpoK8AKGvYLgPgmqOCRDSbiBoRUaPixe3cUARBEARBEAThnpGbMxGuBPCSUmoxePBgVHr+z85ISkrClStXkJiYmK0dFHIPDw8PlClTBu7u7rndFUEQBEEQBBM5JqCVUosAtAHgq5S6AmASAHcAIKJZAP4G0BXAWQDxAJ7L6r6uXLmCQoUKoUKFClDKkWeIcD9BRIiIiMCVK1dQsWLF3O6OIAiCIAiCiZyMwtEvnXwC8GJ27CsxMVHE8wOEUgrFihWD+LsLgiAIgpAXeWBmIhTx/GAh51MQBEEQhLzKAyOg8wLLly+HUgonT560pf3zzz/o3r37PevDrFmzMH++ee6aDz/8EIGBgQgMDISrq6tt/csvv8xwu7t378bLL7+cZpmUlBQ88sgjWeq3IAiCIAjC/YJiT4r7h0aNGlHqiVSCg4NRs2bNXOqRztNPP43Q0FC0a9cOkydPBsACetq0aVi1alWm2yMiEBFcXLLvOadgwYKIjY11mJecnAw3t9wcV2omr5xXQRAEQRAeTpRS+4moUep0sUBnE7Gxsdi+fTvmzJmDxYsXOyyzd+9e1K9fH+fPn8fkyZMxbdo0W17t2rVx4cIFXLhwATVr1sTIkSPRoEEDXL58GS+88AIaNWqEgIAATJo0yVZn/PjxqFWrFurWrYtx48YBgF276TFgwAC8+uqraNu2Ld566y3s2rULzZo1Q/369dGiRQucOXMGALBhwwY88cQTAIC3334bQ4cORevWrVGpUiXMnDkTAAtwb29vW/l27dqhZ8+eqF69OgYOHGjb58qVK1G9enU88sgjGDVqlK1dQRAEQciz3LgBJCfndi+YiAjg1i1g06bc7gkQGQnEx6df7tgxYNs2ICQEmDcPiIlJu/y2bcD169nSxZwg75gb73NWrFiBzp07o1q1avDx8cGBAwfQoEEDW/6OHTswatQo/PHHHyhXrlyabZ06dQo//vgjvvnmGwDsguHj44OUlBS0a9cOR44cQZkyZbB8+XKcPHkSSilERkZmue/nzp3Dxo0b4eLigqioKGzbtg2urq5Ys2YN3n77bSxZssSuzunTp7Fx40ZERkaiZs2aGDFihF2ZAwcO4MSJEyhRogSCgoKwa9cu1K1bFyNHjsT27dtRrlw5PP3001nutyAIwkMDEXA/jg3JTL+JWKCmpAAeHtnXB4sFSP0m98wZ4K+/gP/+A959l8VdzZpA6rew8+cDM2YABw/yto8P8OmnwJAhWesLEQvx778Hfv0VcHfnPrz0EvDqq3oZ7ZglJgKzZwNFigADBwJvvQV8/LG5zZkzgUuXgPXrgXLlgClTgAsXgFGjAC8vYN8+3g8AHDoE7NkD9O8PFCyYsT5v2sTno04doFAhc15sLFC7NgvoXbuAatXs68+dC3z3He/XyLlzgLc3f7/Ro4G+fYFixXh73z4+Rq1bA5s3s+iuVClj/b1HPHgCeuxYvkCyk8BA/gGlwaJFizB27FgAQN++fbFo0SKbgA4ODsbw4cOxbt06+Pv7p7u78uXLIygoyLa9dOlSzJ49G8nJyQgNDcWJEydQq1YteHh4YNiwYejWrdtd+Vn37t3b5iYSGRmJgQMH4ty5c2nW6d69O/Lly4cSJUrAx8cHYWFh8PX1NZUJCgqCn58fACAwMBAXLlyAm5sbqlevjvLlywMA+vXrZ+ezLQiCkKsQsVWtaFHnZQ4e5HtNvnx8jyhYELD+r90V8+YBNWoAhnsA5s8Hhg0Drl0DtP/ZyEhgxw4WF0OHcp2MsnMncPw4ULcuC56oKBZq1avfff8BtoyeOsXCdP9+4KmngMGD+TglJLAYNHLpEtC+PdCyJYu1GzdY4JYpk7n9xsTwuStcmLfPngVeew34+29g7VqgQQPA1ZWF6nff6fXef58//fyARYt4v/PmAdOm8XHRqFQJOH8e+OCDzAvoP/4APvwQCA5m0QkAtWoBN2+yKB83DmjcmPe5eTMwciSfo507WWADfAyNdO8OrFoFvGgNaObuDhw4AKxYYS53/Dgf+w0b+FxERfFDwIwZQLduQFwci9cpU1gkA9zHfPl4addOb2vgQGDCBBa6w4cDW7cC4eGcV706MH488N57wIIFLJzr1gW+/ZYFeK1awIkTelsffKCvv/QS8MUXgL8/sGWLnr5lC9CoEXDxItctUSJzxz0HefAEdC4QERGBTZs24dixY1BKISUlBUopTJ06FQDg5+eHxMREHDx40Cag3dzcYLFYbG0YJ4Hx8vKyrYeEhGDatGnYu3cvihYtisGDByMxMRFubm7Ys2cPNm7ciMWLF+Prr7/Gpiy+yjHub8KECejUqRNGjhyJs2fPonPnzg7r5M+f37bu6uqKZAevtRyVud987gVBuMfcvAmsXg08+6y91TCrREezRW7/fhYArq5pl//ySzbGnD7NN/7SpYHbt1lMDBnCwvnIEXMdDw8WKu+8w4LIOEj74kVOS229S014OPCcdUqEd98FXnmFhfmkSUBSEtC0KQsxIhYmGtOmsciYP5+tqM5ISACeeAJYt85xvsWSNSt3Sgrw9tvAN9/wsU7Nt9/yki8ff58bN/gcREXxd3R1ZcFsdRkEwNZHPz+gTx/+vqGhQECA4/0HB7PwHjeOv8O8eUCrVkC9eiyALRagbVtznVdfBSpWZOEG8PcODQXatNGvO+0efegQC8bSpXkfX33FQrFNG6BzZxa4y5YBP/3EbQ4cyEJv1y4WuGFh/EDh5cX9uHaNj1WTJtx+XByLy9at9f5Z9QOqVAGWLgV272YB7O/PQrNAAcDTk/fx449sUQ4KYuvtihVAqVL8kPX333w89u0Dtm/n+m+9BbzxBn+XgAAW6atW8dKqFQvV8HB+WIuK0vtUvDhfY/Pnc7/OngWefBJ4+mm2fs+dy9Zxo4V8+3Z+sDx9ms//1q1AyZLcxpQpfB1rvyXjNdCzJ/C//wGdOvFDwYwZvP+8hDZQ7X5ZGjZsSKk5ceKEXdq9ZNasWTR8+HBTWqtWrWjr1q20efNm6tatG12/fp3q1q1LmzdvJiKiBQsWUJ8+fYiIaP/+/eTi4kIhISEUEhJCAQEBtnYOHTpEdevWpZSUFLp+/TqVKFGCfvzxR4qJiaEbN24QEVFERAQVLVqUiIgmTZpEn376qdO+enl5mbafeeYZWr58uW27e/futGLFCiIimjBhAlWuXJmIiNavX089evSwpU+fPt1Wp3r16nT58mVKSkqiIkWK2JUnIvrf//5HCxYsoLi4OCpdujRdunSJLBYLPf3006ZyRnL7vArCQ8ft20Tr1xOlpNz7fX/0EdHbbxMVKEAEEK1Zk36dXbuIwsKI/vyTaMAA5+Xq1+c2teXNN/W85GSi33/n733kCNGlS0T16pnLA0T58hE98oh9urPlxx+Jrl8nslh428/Pef8sFqKICKLBg+3b6ddPX3dz489SpfjziSeIJk3S8597jig4mOjff/W2Dx/m42SxEG3erJc9coSoWTPzvg4c4DpxcUTr1nGd2FiiTZt43RnNm3P99u3t++/jY59WvjxRhQr690hrKV6cyN2dSCmilSvt933ihF72kUeIatUy19+7l68r4zHavp3rJibqfbRY+Brw9iZq2pTo8mWi8HCiM2fM+5s509z+rVtERYpk7JrQ9uuIFSv0cgsX8mfz5tyHrGKxmI9/3bpEV69y3ssvZ/xaBoj27SM6fpyoTh09rXp1fV/JyXzdaNfrY4/x7xIgmjXLvm/x8dwmEdGVK0T9+3PZIkWIYmL0chs2EP31V9aPQTYAYB850KO5JoSzuuRFAd26dWtavXq1Ke2LL76gESNG2AQ0EdHFixepVq1atGvXLoqPj6cOHTpQvXr1aNiwYVSjRg2HApqIaNCgQVSjRg3q2rUrPfnkk/Tjjz/StWvXqHHjxlSnTh2qXbs2zZs3j4juXkD/+++/VLVqVWrevHmOCGgiouXLl1O1atWoRYsWNHbsWBo4cKDDvub2eRWEXMViIerRg+i99+6+rQ0biJYtY2GsCaH9+4m2bTPvr3Fjvi2sXEm0cyfR1q1EISGcf/Ik0blzLEAiI4n+/pvo6FG9/vHjRBMm8A322rXM9S852f6G7e/P+0nNmTNEI0cS3bnD5ZTS6xhvvEREN24Qvf66Y0Ggtf3JJ+b0ihV5MaY1a0ZUrBivt2vHx8piIdq9O33hUbasvr57t+Pv/913RAD9g1b0Zr5PiRYvtm9n/XqiU6f07RYtuO6+ffZlXVz4u8fG6gKqUyei2bN5XTunV6+a6332Gae/8AJvv/UWUevWvF65MlHHjuZ+R0SwWNeOS2Iifd57By0eu5Po4kWiV14hio4mOnuW6KuvzEI29TJ6NNHQoUTvv080diynBQWZy7RpQ3TsGPcvPp77YBVpIShPg7vdpOizN4iGD6cl6E1fNP2ZyyxbxvU9POyP/ebN/NCkoZ1bZ6xZY+5Tx47m7d9/J3r0UcffMT3+/Vd/WFmyhAXp3aIJ2oAAsxifM8dxH0eNYsH7xhv8fxEcTPTaa/wb1UhOJvrwQ34wS01SEv9/3L5NsbFEvbvG0Gvj0jieRo4cYTGdxxABLeQZYqw3OYvFQs8//zx9+eWXDsvJeRVynMjItG+WzggOJvriC71uSgrfWO/cYcGQ2T7ExOhW35QUvgk3aKDf1KKiMtdm1aps0bFYiLZs0dspWJCoTh2KGjOR7sBqzTx7lsWR8SZaurR5+9VXzdt9+/Jn48YslIYNowgU1fNfecXx93TGmjUUDw+KgydRQACFV2hINjG7ZQuXWbaMj0uNGpy3dq39zf/0aS5rsbDAHzSIbJY8X19+IHnlFft6LVoQ1a5tTuvdm8VZQgK3d+wYRU/+jFJuhNlOWVJMAlGlSs5Feupl7Fi2mBYoQPTii/r3tx7/YggjgJ9r4lt24DqenrTc5Uny9rbQu+8S0ZNPEgGUMncetWhBNHUqEe3YoX/XKlX4c+pUFj4AUc+eNrGX4p6fTh5PpqtXues7qwxgYevtzQ8mly+zxRcgqlWLolCIkuGifwdN1FlFbgoU3UIRSj55hgIC9GIdOrDGTUxknX3rFlHZkom0Ga3Nx2T2bIr8axtFX42mGTNYh6ckW/ggJCWxmJsyxf68jR/PeaNGEQH0RL6/COCfJZFeLCyM+IEBICpfniIi+LKtXJl/xumRlETUpw9R4cLct6ijF/X9e3jwepcudBvuFAMvfnAh4v5rnZg3z/aw2aUL/wwLFuRLbtMmoiZN+PK+c4f7lJTkvD9//MGnqmBBom7d+K/hzBm+RC9cYMN+w4ZEhw5ZK1y6xG8qQkOJiOidd/hnYNmy1e76jEZBuvP3etP+Nm7kn9x//5n7YbHwX0d4OD/XfPABP2MbX15tNezi6FGiuXOJWrVy/oLr9m39GXjKFKKWLflvIzSUn5tyCxHQQp5h6tSpVK9ePapRowYNGDCAEhISHJaT8ypkmuBgXXA5wmLh16OPPmq+IQ8dynefjPDmm3q9BQv0163a4u7OlsKMoN3YrWKFNmwwWyw1C9zXXzusnpxMtGH8ehYRkZEs+L74Qq8/dSpZAFqLDpRUrCQRQOvRjgCizviby3TrRpQ/P0U/9Rxt6D0rY0JQWwICiCZMoF1oQgDRCjxOx1CL5rsOpvgdB/WOrlzJ5ffsMX+B0FB+nQ9QHbfj5F8qhebP56IHYXCj0F7vGpbrr06lHUhlodTO/bp1trSTLYfSxYuGfUZEmOrsRFNa/NZhSrl+k6haNU5v2ND2cLR/P4uEc+fYCO3np1dv25Zo9Wpe6PPP9YxWrfhcaBZ9wPxApC2JiUTnz9MOBNHeyn1MWfnyWWjeK4fp6slo6v14AgEseOnMGTo+eCot/zXJVvaHH4huvzCGN959l6io4WHGy4u/gLs7HUUAtfDcZ9qPTcc3bMgKsVMndhVp356S4EoA0f/aniTq3JkrnDrFKgegiyhLvbGEAP7ppf562ssBFxeiIUN4vQv+4pUVK+jotkg6c8a+3oYN5sskKopo+7Qd5kLagwJAp/MFUMGCFgL4mevkSXPRPbst7Opy5AgNH66n16zJx+6HH9j4aeTIETYIa88exuXYuqt8fbRvz8f66lXqgeUEsPjfsoXF4ElUo7OoZGvzt9/06+bll/nUaG2WK6c/p44fz/vWbo1//qn3s2ZNvg47WJ+vtOvRkffMZ59xG2vXcnd//lnP277NQvT997aEO3AjgOjZJ6IpKoron3/YJtC9u7lPmzZxn/7+2/FfwsyZ+jFcskRPHzNGX1+xwrEg7tbN+ts/qJdt1IgvRxcXh3+B9wQR0MJ9h5xXIVMY/VZPnCCTajp0iOjbb9nNwJkYLFdOtyjfvMk+ualNQdodqGFDh218j6F0FAF8s9aIirK5Snzx7i0KmTiHXRyOHmWl4KQ/Jz5fTZ98QpTcqCm7RThg0gQWUVvwCJuWHLTzC/paxZeFWrdIMmVHoyBFoRC903Gn7XliHgYSARSLAjQeU2hG5S/I0oFfU0eiME2p/TNFojAX9vUl6t+f3sZ7LJiQYmt7js84Sr6dTO+9a6GzLbhN+uor7viWLexa0KYNEUBxroXsuv5xNf0V83SMofOoYCrwTMn1BBBtQhv6GK/TTfiy6wMRnzuA7rTrbKvy3nvskfDnn8QPHIULU3Qhf3JR3OelS4loxgwu3LcvRUezQRbgG7imrZ0tV68SUVgY3f7sKxr3qoVsL9Y2bCAaPpzopZfsK23bRgl1GqfZbrlybP3Uth0JToBowuNHeOXff03X5y8lxvBzxaOPUmPsJoBdYbV6b77JDwA/N9UfvC6NmkqfdN5Ip1HFVs72JmP9ett6AcTa8idP5s/ff2fvH2ffZyS+tjbIVmB/f/syw4aZr3NNHMaMdewCMqTwr1SoEP88lbJ3YS9blgXbW2+xK/uQISwE8+fXy9SuzfuyWNh4b6z/2GPm7SZNuIzl0mX68OUwOn1az9O8X/r00dOmT+dnKm1b8/g8dYqvuxdf5HTjcw/Azwhduth/5e7d2bXb2TE2Gr+1NufP5+PdsCFbsBs3tnpljBlDaz/YQ8Mqb0zzOjQuu3fzsQSIXF3NruytWrFY/u47/efkzKNl6FD2+lq4kI+Hlu7qysb9qlX138Avv6T575+jiIAW7jvkvD6E7NnDluGUFLYiNmnCfpxGQkKIRoxg60mLFuwzd+2a43/oEiX4zmFQP3fgRs/iJ1rg/pz57gmwC4DBekldu+ruExYLka8vWZo1J0tCIvtODhlCBxBIj5feS7FN2upio1EjrvP777a2bpyJ4l3hiF0/U6DY+mfd/rjxb7rAabeLVy5dIouF6Nln9bFUnepfJ4DoDzxm114CWB08jhVOb4Q7EEQj8I0prYPfEbIA1K+abqn09iYqX0YX30+0i2ZFChBVq0Ydi+2za/sFzKQdPxy3bSfDhV0KiPi4WjNu+deiBg0sdvU7tU0kWrmSwt+ezqcS18ny+zLqG3iCVuV/kjphNQFEFUrGEUDUG0tYqWjmq+LFTRY345KUxM84VuM3AVb33r17aQGeocp+cQ7FzNq17BJw5w4bjydN0sXDypW8a20MJMCvtadMYU3bseo5+g/eNA5TqSW20pv4kN4NWEzDMNu0n8BA835r1OB+amPXWrbU88qU0dd79LAQnT/PLrxd2ZT3O54kgC3XKZu3kK/bf9SrK/sO37zJzz9GMb0V3Hj9Wmzx/gwv2/K6tImjY6jFvrOffUYEOL6mdvApXruWL+ljx8z5z2ABzcYwGjDA8bmpXJmtqt278/GMjtbzTqy/QgSQxboMwo+0Fh2onOcN6tmT96tZZt3c2G1k40ayiTKtnf37uWxkJHs4vPoqWzhv3rR3cdbGpsbHs1X5tdd0d3jtxQpgfnGU3nL9uvkvzSjAjc/mvr76+q5d/PzfsiX/RSUns3t6/fp8bfTowV412vjYjz827/N//+PPjz7SXeG1MXzp9Tf1WM85c/iFRN26/Ds4c4b/qjULsrZUr84v5Hbs4DcDL7zA3iS+vkSFCrEbilb2qafMdceP1x9C3nknS3eTbEMEtHDfIef1AePqVf3ORcR3gzJl2Lwzbx7Rp5+a/6G1V95LlnD5iAhWLFokgiwun2Ms31BdUmhT8wlUTl2koU+Ec75mMjEuLi78Wvs5Ftxj2h+jRo1YIJw/rxf7+B3dGkeennRpzXGKqVCbzqAyJcGV9qM+AURFYXYhGIUvqFK5JLr24gdEAP1TdxQB/PWbNuViy9GDaM4cunJFrxobGk1+XpEEEC0dstqWEY2CVA8HyQ13aGGHeeTubi9OtaUPFtml1axpoeVLbhNA9OHzIdS5k319pYguzeCHg6MIIFeVbMt74QWioIZ3qCl20vs1F9rS/0ZnSuzyBJ09Y6ET3s3IAtB5VND70ofFzqRJbJny9Ex7zFnqpZNaS9SvH1natKUG2EePF/mHihTh45g6SILxxl2smG68/+MPPT1fPhYdM2akfVnHxJjHMaa1rEYnp3lt2rAYuX5dfy1vDHJAZBbPr73GXkfaduPGuht0Ppc7FA4fKoxI8nG9RQAbjgEeo6ehiXXteLyMz+gK/G1ttsZmUx8r4SyfoLFjiQrZvzUA9PGJRj77jI3WTZsSdah3nR6pH2NX74UX+MHmyy+dH791ay20eNh68vO9Tf+ihSlP83LS3AYCA/XzYyyn/Z0YMQbA0JYRI9gyHBZmXz4sjK8PLfhI6qVHD/u06dOJxo0zH38Ni0V/y7BwIXuG/VJykiMAACAASURBVPqrHsAFSPsadMY33+j1tQeltWvZdxngNyyp3V0cLU89ZbIF2JbBg83708az+vjowyjKlnXev9RjWLWlQgXOnzCBt3M5CAeJgBbuO+S8PkCsW6ebUwIC2OQyerTzf2wPDw5fBbAJyKhsjEu5cuZto4NqTAzRqlX69q+/EgH0KDY4bGpjjZGUDBf6BX0pGrrCSkB++gnPkgWgpXgqQ0IpHh6m7WewgFbgcQKIiuaPtWXsQJCtzHMtOcLC0yX/IR8f9l1MSCCqW9dCNXGc6K23TBav5thmW2/QgGhB+Ql0AIHUpNBxp/3av59fH3/1FW8XAYsrY5S3ggX5FaynJwuamBg+dL/+yu4PWtCF90aGUgLy2+p9+SX7TRLpp7YCzlNdHCLvIik0vPJ6mlhkhq38Ko9e9DVGEsAWMSPffpv+MbYTLYXZ1LgdzWxpPj4s6M6f51f2hw7p5T09rd/jPbMQBfhZKbWVMC2Mg+fSWsZgutM844sW7Rin9tzZYXUDfustPe3wYX6+y5fP3N5HeIMAojWzLxLAghDgZ1UN7bx/8EHGj7Nl8HO0oPk3FFqWXU+aNeMBZlq+kyEtRGR2hcifn/vcpQu/qk/93bWlSRN9fc4c/WVSdQTb0l1d9ehsiYlsMTWO0dTK/fmn435pQi4oiGjaNP06TgtHPsfG/WzapHu9pHZJccT27WxJ1oKLaBw9qluKM8vq1eZ+ubiw+DcKc0fLhg18rc2bx9uffGL2S9YWa8RbE7t383gB7WGuceO0+5j6LdGYMfpvLyFBf5DITURAC/cdcl7vY/75h+8aFgs7w2kmukceYYXWtSubGQyOgUlwpRdrbqDgP06ZTYbNm+sD9yZPZjU0bRpRnz507Wg4DRlC1APL6UV8RZa//qZjqEU98RsNHMh/5HGTPqHhDfdRnz4W6lJ8L+VzuUNt2+r63Lho/sIVcZ5GND9Ea9HBlmd0dfjzT31MlaPlDzyW5g3qF/Slw6hDhRFJBRFN/foRubulUEesIUD3dCBi99lSLteJRoyw+Zk6W9zBlmPjOEKAPVyMgjA0VM9rVO8ORUfzK+IpU/T0pk2dn9727dmt4OIJ3epuDBRifH28vvYYCggg6lnnFD2DBbb0/g1PEkBUoVyyXfu7dtl/N801omVLoueft4qo6np+l/Ls3z4eUwjg87t2rbnd+Hi9/Lx5LK61iADG8L5aIIWMkjqk7sCB5m1n560Ertu+kxFNkC5bZr+v69ftoxgYnxONbdf358gLxlfwxgF6JUpw2saNRErpbxq++YbddgCzmwhA9Ge9CXy8i/AD3E8/cVtaflr06qWXmzqVH1zi4szHOzxcL1OyJAcFMfoqO1oef9y8nxs3zBHgHF2jqTFeCxnB6mZvWrp25YGBxv2cP597AjC1dXnKFD3v2Wftj2vr1vZjqS9fZpelyEi93KRJbNG+c8f5vrUQ0KNHp93HHanGhqYVrCe3EAF9D1i2bBkBoGBDbBxjHOh7wbfffks/af9ohj4EBQWZ0pKSkqhEiRJ0LY14rcaY0hMnTqT169fblbmb79esWbM08/PKeb0vOHGC33fl5D/14cOs5hYv5lFCP/xAtGwZWSxE0VEWfu+o3Tm095GaOalNGz1vxAiag+fIHbepbplwugFWsnun/0sAG5zvzF1AcfCkKBTi+v7+FF++hs26NWoUC6TUgQ2Ct0fQaOhWzvr1eT4LbbtaNdbjWogn42AbgKh9vi1p3qjruh23WQo1UaQNNNMWT08LdcBa23bHgCtO23PDHfocY02Wohrl40xWqDFjiAq7RBP17k0DBxIVco9Ps4/fdGEHaW3bkUVQmz8C4GhtGosW6em9ejm/FLRjqlmoUgu9H37Q24nYfYZatCB6tMEt+h++NfXV3d1xgJHbtzlSnnEwmjGwydfWcWialQsgCqx9h6hKFeqINVTf47jTvmvlN240p4eF6XmZ5cYN9u28fFlP27uXI87FxJgjVEz/XzBNnMgDLgshisaU+/2uf7ZGP2HjXCxfP85PEMYIfcbjqFlz//uPyNODB1OOBvusdOrEecaoFQBRD6/1pm0tKsPSpeaxs44wDohbutR5OUfnwdn13rIl+y6nxZIl7A6UnWghwF1c2FYAsLU0L5GQoB+nsWPtHxAsFh5Q2bo1vx1IL6zfSy/p5zsjZOSBxPgwn5Xf3r1ABPQ9oHfv3tSyZUuaZPgXuRuBabFYKCUbZgRLSUmhMmXKUIjBOW316tX06KOPplkvvUlZiHL2ASGvnNc8yZ07bGY8eJDv0lqMqIyYzlJS0n7P6oBLy/bSqQqpJgywLt/NYstVCMrzPzER3Spbh/agkX7HPHeObt7km87mN9eaojV8hDfoNtypX1f25/Xw0OduAIhiwabH6p4XqGhRjiVqHBDk7a3fwIzLM8/Ypzma1Csx0TyYzN/fuc/wxlL9bfW0uRkMkaAIYGtYIfCAwVo4RifWXHTa3myvsURdutDFi3ra8VTab/x4Ind1h6hdO+rUiahxoRNU0uUGAUQDu4Xb6n3Y4Dd6Ex9S3EccCHf//rRv6Nor/9df19O0uK2+vmlH4rt8mctpYwG3bjXnG31KU1K4XMP6yfQUllINnLDlZcS3UStr9EX95x9O+/RTFsIVK7K10nIrkoohjIa2PpNue46+H8CDm7Ib4/n9+Wez9XJ84Or0G8gAc+cSTZzIwlRre//GW0TELgAffsi+yEaxfvYsj7ElIvLx4et+PNhMqYWQfv119sDSfk9loV/PrVvz7yejnD/PvsBTp/JDkjMciSnjhIuFrM/VHm53cs26m5zML8r8/NjaPXVq5o7FvQJgY0NeZvZsflGpDUDNa4iAzmFiYmLI39+fTp06RdUNIz+MAnPPnj0UGBhI586dsxOnAQEBtpkIa9SoQS+88AIFBgbShQsXaMSIEdSwYUOqVasWvWMYjvrGG29QzZo1qU6dOvTqq68SkXPR+/LLL9PHH39s2x40aBB9//33REQ0e/ZsatSoEdWtW5d69uxJcdZ3X8a2Bg0aRL9a78arV6+m6tWrU4sWLWjUqFG277d7925q1qwZBQYGUrNmzejkyZNERHTs2DFq3Lgx1atXj+rUqUOnrZMdpJ4VMTV54bzmWYzv2o2LMZjpv/+yCfbnn/kds2Ye0yZ90N6/xcaymfPWLRbWL71EdP48paTwTSEsTA9PRr6+5jADAHWtxxbWZXjCqnhjqUPhXQQQDcNs+qDkl/TJJ+bR/mXdr9nWfRCeZqSIrlhF3+F5U5qrK78mL1CA3amNs/kC7GIQHa2HcGrd2jCxgAOMA2SM0eC0QBPaklhNd0q1WPgQWzj4AR05wuJXe5YBiFYuiDRNsnfwoDn8lDZzckqKYR+pbsLvvsvpyfUaUP0KEdQNf1LbEkcJ0ENJAUTJw6zD7I2BWNNAq/fdd3qa9p0y8txuDOuW+qdqtOwTmcM4t8C/NLgbPwAk23tvOO1n6oiCO3bo9SdOZEvgTz9x2Tlz0m/P0SRvp0/b5pvIVozW7ZUrzWNV3+v4b/oNZAJjEJlz5zJerySHCad3MZGIdAur9uLR0eSImZ0zKKNcumTvSnDpkr5f7b+kWrWc2X9GGTiQLfV5mVOnMu+SJJgRAZ3DLFiwgIYMGUJE7Jqw3xptQBPQ27dvpwYNGtBFa2zatAS0Uop27txpy4uIiCAiouTkZGrdujUdPnyYIiIiqFq1amSxPn7funXLYbsamngnIkpMTKTixYvTf9aphcINZrkJEybYZgZ0JKATEhKoTJkydPr0abJYLNS7d2+bgI6KiqIk611u/fr11NMaV+ill16ihdZAj7dv36Z46/tpEdBZID5eD47paDE6OGoR8DV3CldX80gQ7e6qqcSPPtLjEhcuTGue51Bqz3XWxe6Q4n/Q1++Zo0gMwHwCiL7IbzVZ7dhBLkh22kVt6d6d/9yLeN2xpY0enfbXA4iWL+dXthaLLjaNvq0AT1RAxPmJiWn76hGZ/fAOHmTD+ZIlZleHUfiCzcHpYJyUbtu//PscPJgtbxpavtEKZxScRrSYtDFlalBpz3B6DnPok14cz9c4p4vNl0Sbii0dtHqp5zbJKNqgNMD+FbrR95JIj40LED3mt5eSE5My/BLE2XExos1hUqkSPzOmNZPbvHn8gHUviYvTv8emTXoYMYDo02cPZ+u+jNeyozcuztAE9Kf9D5j6rfHXX3q7wzGL4p9Px7k1mzG6qWhRLjp0uKddsOPOnfT/W4T7H2cC2g0PGGPHAocOZW+bgYHAjBlpl1m0aBHGjh0LAOjbty8WLVqEBg0aAACCg4MxfPhwrFu3Dv7+/unur3z58ggKCrJtL126FLNnz0ZycjJCQ0Nx4sQJ1KpVCx4eHhg2bBi6deuG7t27p9lm48aNERsbi1OnTiE4OBhBQUEoWrQoAODYsWN4++23ERkZidjYWHTq1MlpOydPnkTFihVRtWpVAMCAAQMwe/ZsAEBUVBQGDRqEM2fOQCmFpKQkAECzZs3w4Ycf4sqVK+jZs6etrgDg2DEgJQUoUwZ4/31gyhSgQAHn5X/4AThzhtfLlAGuXDHnt28PHD2KkKQyqLTqT2xCW7SN/ofzUlKA+vX1sufPA5UqAadP8/b06ah/exfKYQW+iR6Js99vAtALyWvWAxgIAJgb9jjmvgO0qfQYAs7/CXz+OfAKVz/ZeyKw8FPgwAEUUHUQSwVNXevbFxgwANAu1UqVgGrVgD/+cseGDcDkyYCrK3DxIn/FZ54Bfv6Zy9aumohjZzxw4gRQs6beZv78/Onpqae9+SbQr585Pz38/PT1gADg77/17c8+A5o2BVqU6gZUqJBuW76++rpPMQUA+PFHc5lNm4DDh4F8+fS0334DEhPt29O+W5Mrv+MqiqFEccKoBU0QWhZ48UUgKAiIjgaw1/p3npycbh+N1KmTqeI22rUDZs3idetfiQ3jMQCAIkX0dbegRnDND7hmbbcO8fbmz/PngXffBdzSuLMNGsTLvcTDQ18vVMh8vXr6F7WvcBcUNPzsChfOeD0ia3+a6/8Rxr+iQoX0dV+Ew7NkJhrPBozfS/sZli9/T7tgh7t77u5fyF0eOAGdG0RERGDTpk04duwYlFJISUmBUgpTp04FAPj5+SExMREHDx60CWg3NzdYLBZbG4mGO6eXl5dtPSQkBNOmTcPevXtRtGhRDB48GImJiXBzc8OePXuwceNGLF68GF9//TU2bdqUZj/79u2LxYsXIzg4GP00hQFg8ODBWLFiBerVq4d58+bhn3/+SbMdpZTD9IkTJ6Jt27ZYvnw5Lly4gDZt2gAA+vfvj6ZNm+Kvv/5Cp06d8MMPP+DRRx9Ncx8PDZp6efll4IsveHvoUOflDx8GAFigsKT6ZLS68g6W4mnUxRG0g/X8v/IKNpxqBeBtTMXraIt/TE3cQAnsRWN037QJmD0b+PVXAEDczVgcQkUcQkWsRA/0wy8AAHck2eoGNUnBrj2uOPTWUgRU3gVUroywV44DAI6EFAR8fJB06BgSiBVD2bLA5cvAuHHAp5/yuoYmWlu35kVDE2P16+sCessuD6xbZxbPqdm2DShRAsjK85nWl8ces78pvvKKtlY5Q22ZBLSP4zJt2/JipFcvx2U1sRWMWgCA4l4J8PQEpk/n9NKlrQUffQM4eTLD6rB0aeDqVbO4ywydO+vrqQWrJmgdbYeFZW4/p08DERFplzEKeOvfTp7CxUVfL1jQLEw9yxXP1n0ZhWZmBJ4moJ09vxsFdLEX+wET0jcGZSfG244moMuVu6ddEAQTD5yATs9SnBP89ttvGDhwIL777jtbWuvWrbFt2zYAgLe3N+bMmYOOHTvCy8sLbdq0QYUKFbBq1SoAwIEDBxASEuKw7ejoaHh5eaFIkSK4ceMGVq9ejTZt2iA2Nhbx8fHo2rUrgoKCUKVKlXT72a9fP/To0QNRUVGYM2eOLT0mJgZ+fn5ISkrCzz//jNK2O7I9NWrUQEhICM6dO4fKlStj0aJFtryoqChb3Xnz5tnSz58/j0qVKmH06NE4f/48jhw58nAI6ORkYNkyNhH6+6dtFgsP589hw1gxnT3LymHhQr3MuHGA9bx9itcwfuNQ5MczuA0PeCABESiGAkgA1q/HSfBbhKtFayPxVn68gs/RF4vxK3pjF4KwD40x96Pn8Cf6YjJOoiaC0Qu/m7q0CP0BAMFg1Tqq4Q5M2dgchQoBf230wLK/2+Cpp4AbJV2BG8CePQpxgXVxffsVpMANH7dbj5f+6ICwMDaWA0DJknr7RquvEc1q5mowUfr4sAU7LVq0SDs/LfLnBy5cMIjRu8AooFNbZrOC0VoJANHuTlS5vz+wdm2G2z1+PNPGahMFCwLPPstvDFLj6gp4eQEjR+rbGpGRmdtP1arpPxQZj3PFiplr/15jZ4EumsUnGCcULJh+GUfYLNCejvON1myfRpWA7O12ptDOcW5boIWHmwdOQOcGixYtwvjx401pvXr1wi+//II+ffoAAEqWLIk///wTXbp0wdy5c9GrVy/Mnz8fgYGBaNy4MapVq+aw7Xr16qF+/foICAhApUqV0MKqEmJiYtCjRw8kJiaCiDBdM0elQa1atVCgQAE0bNjQZOV+//330bRpU5QvXx516tRBTEyM0zY8PDwwe/ZsdOvWDb6+vmjZsiWOHTsGAHj99dcxaNAgfP755yaBvGTJEixcuBDu7u4oVaoU3nnnnXT7+kAwcyb7FAH8rr1fPxbTmprQ7lgAjq4LxSDsx2p0QclnntHbsApoSkpG4mcz4Qkgvt1j+O7sFOAicNt6F0uEJ97FJCxGX7Rw2YnLFlaCR2+Vxbd4Ad9iJL7FSFP3hoD9CqpWIRQ4ewRr0RmOOIx6AIDm1SNQsCALX+25adkyAPC3eZMEnZmPbyJZeNevFgcvLxZSGkaXhcBAx4ftzTdZlA0cCMTFsRX7XpBdN2OjgDZ+36ySWtAMq7UTsD7c3A1Gt4qsMn++87zYWH3d+JeS2p0lOzBauI0PaXkROwu0E8GaVYy/t6yQEQu0szcr94pWrYAnnmA3IkHINRw5RuflJa8OIhSyn/v+vBrDMWjLiBF6vmH6riH4gQCiBXiG9qKhXj4lhchiodkYRgDRP2hly/riC6IF/f6iAx+vpXaPJJp2o5BCI5ofIjc35yHZUi9NsIvGPX3Baf7mcauIyPH0tePG6aGlFuNpAoiOrLnq8LBkZFDY/Yw2vXf//umXzQjGGNG/ohePyLvPmDPH2v8cipNrDBOXV9H6l5ysR7gAiNasyd79ZHX652LFuI6DcP9EZI4p/G/2Bg7JMHn9HAsPJnAyiNAlXYUtCELWOHLEPm3WLODmTV4PDQUARKMQFoP9E57FQjTGPsTBaga6cgVo3x7L8SQAoB90l5nOnYEBv3RF/Tc6YthI82g5ggte6XUJH3zg2F/dEQ2xH0VLOHeaLFmcffY1b6EaNfS8ypWBiRN5/ZzVV9ivoWMfydOnHb/2f1CoWBHYuhUweDHdFUYLpR9Cs+60nIs89xwfE2d+3ndLap/rvIyra85aoJ0MUUkXbUiOs/4YB+Teq7dCgpCXEQEtCFng+HGOEnHnjpMCBw8C+/Y5ztPee1+7BgLwa/f5iIcX3N11l45wWP0AfvoJyzcVxmp0BQCEwh+Pl96HyEiOYKHhyO/Tr2pBvPEGD9wLDk7/OxVHGIqWMoszo99jKc8oALrrhTGvUiV9+9Tjr8PdHShWzPF+qlZ98Af/PPJI9o3QtxPQd+O4nEsoxcckq+IuPYzuBfcDJh/obBbQd4szFw6leJDt++/nnu/xpEl6FB9ByG3EB1oQssDYscCGDWxZa9/enBcdDSTN/QPF8uUDLl1ip8T69Vl5btmC8Nc+huuuUyhUIAWPYCd2rQpCwYJAUJDChg3cRjh8UR6XAIsFPbHc1P6jlS+hSJFGpjRHArpAaR5ZVaaMbl3Kn5/HKUZFmccn1sERjMaXWOv3hqmN6tWBvXuBfLgN7/a8T2t0RlM0hYoV9UgJp254o1SpnBNLDxtGgeWPa/elgM5p7rdrLSct0AAPv6hePXN10htECAArV2a9T9nB5Mm5u39BMPLAWKDJMCBLuP/J6+dTi9Zw4QKQkGCNBHf4MDBjBlq1Any/noztlQfiXGxJhCcWxOp3dgKzZiGsZG0URzh6/t4fKxdEYhc43nfx4sDo0Xr7M/EiUuCC2Iv28buav9/FLq24g0hYLmV0FwoXF2D9eo5y9vXXwNy5wE8/6fvciHYohv+gPMyuINpNuGTZ/FA12WdDs0Abw5iVL69boE+fBkqVcnzchMxjFDQeuC0C2gmbNwPnzuV2L5xjtJIbz2laYd+zysiRmR9gl14YO0EQzDwQFmgPDw9ERESgWLFiTmMUC/cPRISIiAh45JavZ0wMcP2689hZBw6gTOn6ABQu/LYPg5ZUxq8biuI4+qEWgnEYHHmjZfD3QBWehGP3bl/s3QsctvD7x3/QFl2w2takry+/Hl21il9R/oghaI0tqHDc/hjUaWJvIlKK3SjOnzcklihhKmO0lLu7c5SLfv3Yml68EofRI5h/P5qANgriIkX4wcHPjyPzLVjA0Sa0qA63bmVPhAeBsRM0vXvnSj/yOnkx/rORy5d1ly9jqLm84sKREQu0IAg6D4SALlOmDK5cuYKwzEboF/IsHh4eKKMFD77XtG0L7N/Pd5Q1a3iWD09PJIVHwe2DyVBfzADwPoC3cXbtWfwKdm24A45ZVgVncBa6+N69m4XmDz8AlRI5xpQbknClXjeA50WxCc5mzfRuJMATJ/dE2XXP2XPFuXPsXp2ZWdbc3a3uHydPApcu4fFmQLdu3NbJk/ozROrQYJoP5Jdf8gKYfaKzGotWsMckaPL4mxnBOabZGN04ZPe33zp+e5QblCzJ7mcZnb1TEB52HggB7e7ujop5PXq+cP+wfz9/hoRgb5eJqNerKm7/+AsKFy+C9+GFtwEkWuMvh0G/+/2LR1Abx+ysuJ06sQjieXb+BwBIhjvOlW5tE9AaxmgCqkkTOwG9bl3aXc/y69fq1YHq1VEQuhX85EkW635+GRv0ZxTQ99ugrryMdk5btcrdfgjZS8eOvOQV1q1je0Fmpv8WhIeZB8YHWhDulshIHnyj2fhO7YlCE+zF+BVBtgFyszEcgC6gT0MPhTEaX6E2juEczLNCVq1qtixr/P23vq4N8jNO+ftfxYY4CT1WnLs70KFD2t8hu/wXNU8oIraUTZqUfh0R0DlD/vz8FsM6cakg5AgVKgAjRuR2LwTh/kEEtCAAABGGDiG89BKwz+qScfFEHABgX0qgadzWCvTATLwEALgCc0DUUwbBC7CoHDPG+TTUmlDVBDQA9OjBn7eSCuIKysALsXZlnJFdAvrNN7nvLVsCderYuVM7RFw4co4mTeShRBAEIS8hAlp46Ll1C4jpOQghyw8CAFzASvXSWR7x44FExD/7P1v5J7Ei3TZ79gTGj2erdpUq7ALx0Uf25T79lD+NcVVXrGC3iVu3CyAWBTn2LzInoO92LG3z5hzqzjgtdXq4uelTV4vYEwRBEB5kHggfaEHIEocPA/XqwccH8MPHKIQYAEAKXAEAIRdYhbohGXG7eFbBy8jYDCCtWrHl2YhmlS1SBJg+HXj6aQ4R7efHETiMFC0K/JfggTi4ohpO4yyqZmj8WHYJ6Kzi6cmRBsQCLQiCIDzIiAVaeDhZsQIIDAS9MR4Az/AXB46QkQBPzMRILN3BwZ5vogTi4dw3wg1JdmmOLLBaGhFPwOLFu0P//vblfXyAW/H5EQcvlML1DH+t3BbQ2vcQC7QgCILwICMCWni42L+fR8UdPw4A+G/q97asq+CweQnwxEuYaQtFF+pW1iauHeFI4Doaya5ZZTPiilG0KBAR7Y54eKEkbqRfwUpeEdBigRYEQRAeZERACw8PP/0ENGrEU+itXQsACIF9+MPodz4zbd9I8UUsnCvCYiXtPaFcHPyyNHGZEQHt4wNcu8Ht3k8WaE04iwVaEARBeJARAS08HBABgwfbNn/7twT2oSHOo5Jd0RtxZrGcQq54B+85bbpQVT+7tIQE+3KZtUCHR7AK9sF/ADI2QYomoIcNS79sTqAJZzcZXSEIgiA8wMhtTng4uHnTtroZbdAbv6ESzqEj7GcmuR5lP5dt6tjORhzNDNi2rX1aZizQRYvq6wURi+jojE2x6+bG0TO8nHuc5ChavxMTc2f/giAIgnAvyFELtFKqs1LqlFLqrFJqvIP88kqpjUqpI0qpf5RSuTR3s/DAExJiW12LTgCAq67l8Av645maB0xFD5/T1aen2510m3Z3N28fPQr4+9uXy4wF2sdHX/dCHAoVyrhVt3BhwNU1Y2Wzm6++Ap5/nmdfFARBEIQHlRwT0EopVwAzAXQBUAtAP6VUrVTFpgGYT0R1AbwHwEGkXEHIBnbuxCa0xZcYhd/z9QMA3E5xRzSK4OnnzObavzbr26XK5ku36dQC2tkAuqxaoL0Ql36FPIKfHzB7Ns+eJwiCIAgPKjnpwtEEwFkiOg8ASqnFAHoAOGEoUwvAy9b1zUAGZqgQhMzy8su4NWMeuuEaEuEJ3AEKeSYjJoEv/9bDqwOvO65aqpTJeO2Q1ALa2QC6LFugBz+dfgVBEARBEO4ZOenCURrAZcP2FWuakcMAelnXnwRQSClVLHVDSqnhSql9Sql9YWFhOdJZ4cHk2O44PPLFUxhV9GckwhO9e3N6yzZu+OQTYORIntjEGaVKpb+PjFqg8+cHunUDVq1Kv02TBfql59KvIAiCIAjCPSMnLdCOAmmlnkttHICvlVKDAWwFcBVAsl0lotkAZgNAo0aNMjAfm/DQ89VXgI8PNm6qg23UAttuAY8/DgwZAvz6KxAeDrzuxOpsxJGAtk5gaKNWKsckZ+4LSmVMPAOpBhFKTGVBEARB52qgqAAAIABJREFUyFPkpAX6CoCyhu0yAK4ZCxDRNSLqSUT1AUywpkXlYJ+Eh4Bf3j2Di6OnAQMG4L+rHE/u++mx+PlnoH59LvPEExlrq2RJ+7Ry1tm8hw8HVq8G3npLz9u16y46bsDkwpFLETUEQRAEQXBMTlqg9wKoqpSqCLYs9wXQ31hAKeUL4D8isgB4E8DcHOyP8BCQnAw8M7kqgIsgKIRetaAkrmPYmJKAYmtuWJhZoALAe+8BS5bYJii0UaKEvh4VBaSkAN7ewK1b3JYWGaNXL85r2jR7voePD1CtGnD7NlC8ePa0KQiCIAhC9pBjApqIkpVSLwFYC8AVwFwiOq6Ueg/APiJaCaANgI+UUgR24Xgxp/ojPBxEGd5f3II3Qi/dgZ97BKB0XwxfX/t6EyfyknoGP6P7hHF6bm9vc7nffruLTjvA1RU4dSp72xQEQRAEIXvI0YlUiOhvAH+nSnvHsP4bgGyWHsKDzp49QNmyHDItNZGR+vo+NEZotBf8imTeK6hPH7ZIa/GUNbcNQRAEQRAEmYlQuO9o2pRn5YuPt88zWqAPPDoOoZv8UM9ld4bbrlrVfhKSCxfSjtQhCIIgCMLDRY7ORCgI2Q1ZY7AkJMA0PbdGZGiCbX11fCtcQ2lUcb2Q4fZPnwaCg81p5cvbu2wIgiAIgvDwIgJauK+4fVtfj2/Q0i4/6vR1AECTKhHYsssDAPDoV0/ek74JgiAIgvBwIAJauK+IjtbXT18tACxYYMqPPBsBAHhtOBf09gYaPlUx0/vp2JE/U8d4FgRBEARBEAEt3FfExOjrkfAGBg40maWjLrETdLs+vjh1CjhxQg81lxmeew64fh0IDLzbHguCIAiC8KAhgwiF+wqjgI6GNa5cYqJt+r+oq7EAgMKlC6Goa+raGUcpx5OoCIIgCIIgiAVayNusWwfs2GHbjA6/Y1uPGjSGVxL0gYORN++goEu8XSQNQRAEQRCE7EIs0ELehQjo1ElfBxBzIQIAB4B+c2UQ2qI0yiQmAuDZAVdeb4wKhSMAFMiFDguCIAiC8DAgFmgh73Lhgl1S9MVbtvWrt7zQDX/ZLNAvDE/G5RR/zO694V71UBAEQRCEhxCxQAt5l23b+NPqj9GkCbB3rzksxhHUAxIPIj4eWP6HC17ATDR7VJyXBUEQBEHIOcQCLeQpwsKA334DDwz8919OrFABALB3r+M6STGJ2L4duJPkgk5Yy1MVCoIgCIIg5BBigRbyFH37WLBpswtCUQGlcIMTExLw3nvO68TduoMjZ3k9qGY0UDHzcZ8FQRAEQRAyilighTzFucMchu4a/EEAbsEbyXG3MWmSXqZwvgRTnbjIJERGAi5IgXfjqvewt4IgCIIgPIyIgBbyDleuIF9yPADgMsriWSyAD24hJK6EqZh3EXO1+OhkREUSCiMaLqXMZQVBEARBELIbEdBC7rNjB+JKVsIHZWfZ5ure1ncmfsYAAMDhZPPAwSLFXNGggb4dF52CyLAkFEGUzH4iCIIgCEKOIwJayH3eegvTb/bHRHyAM6gGAJi2uIwt+xSqm4qXreSOvXuBv34KBwDExyQjKuwOvBEJlBALtCAIgiAIOYsIaCH38fdHDAo5zT6JGrZ1X7db+P57BRcXoLAPj4GN++RrRAVfEwu0IAiCIAj3BBHQQu4SFwdcuIAo3yp2WQ0b8qfRAv3dNynw9+f1AkXzAwDiUQCRofFsgRYBLQiCIAhCDiMCWshdAgKAnTsRovTQc8WL82ejRvxpFNCFKvja1r2K5gMA/IancBiBYoEWBEEQBOGeIAJayF0uXsQv6Id1YTwqcOxYYMQIzipaFPDIl4Jo6GE3iPSqBQrxDIUL8SwAwKNVExHQgiAIgiDkOCKghaxz/ToL1p07s1Y/KAgE4BO8AVeVgr17genTgbp1Obt6daBYkWRTFc06DQBeXubmgi01IAiCIAiCkNOIgBayxNWrwOiBkZh+sz8WDt+a+QYSE4Hdu3EVpXEE9TCtzk82l41evXgW70GDgGI+bHKugWDsXBuN+vX1JgoUMDf5+ONZ/DKCIAiCIAiZQKbyFrLE998DX62vAWA6cAwYcP48UKlSxhu4fBkAcBMcdq7iaF39KgW0bMnrxfzzA6eAYohAUHtzOLv8+Xn2QQtc8fjjwLhxd/WVBEEQBEEQMoRYoIVM8/6TB/Duu+a0O9NnZq6RS5cAAOEf/QAA8K3h67BYsWIKAHiAoIv5clUKKODF+SVL8rYgCIIgCEJOIwJayBQJEfF4ZwUP+PNEvC09KiLZWRV7vv8eeP11AEC4B0+Y4utYP6NYMf4s0rO9w3yvgnwJFyniMFsQBEEQBCHbEQEtpMt//wEvvABcu5yC3c1fBgDMxEh8g5G2MpH/WTLe4PDhwIEDAIBwiw+ADAjoEvkd5msDCQsXzvjuBUEQBEEQ7gYR0IJDunYFvvuO1zctCcOsWUDpcq5oe5oTOw8ri15FNsLVlQf5RUUBCxYATZqk0eipU8Dixfr2Bx8gPNINLi6At7fjKpqAduaeoeWLgBYEQRAE4V4hAlqwIz4eWL3aGo954UKEjJxqV6bsN2+iUHgINm9mZRsZ44qBA4G9e4Hbt500HBAA9OvH63/+CUyYgPBwwMcHcHV1XEWLtJHsxEPEZqEWFw5BEARBEO4RIqAFO06f1td/G7wKIaiIovgPv6CfLd3dHYCbm024vhMy2JY3ebIDwXvlCpCSom83bIibN4Fvv9VFsCPcrHFijFWNaHWNE6wIgiAIgiDkJCKgBRPx8TDFWn465Rd8i5Go5BmKvs0u2ZXXBPTO+EBb2scfA/Pm6WWOHgWe6JSAJ7AcV/NVRNTEaeg92g9BQZzfoYPz/nh48KczC7W/P3/GxaXzxQRBEARBELIJiQMtICSEQzgPHQrMmWPOI+szVqXuAVBLt2PWd0CpUnq+M9/l69f19eefB3afqAqgKv7f3p3HyVnV+R7//NJ7J52FLBBIgABBlE0QEYRREVEEFF+DCwxeNxRFUYcZF/Q64njVO3pnxtEBcXDFuW6Io0aNC8M2OiISEZBVYljS2cmedHd6yZk/nuqq6iVJdajqSld93q9Xvep5znO6+td5qPDN6VPn/OGAV/Hk/ylc++AHs8C9K695Dfz2t3DVVaNf//CHYds2eNObdv0akiRJ5WSAFosXZ8/F4bmNLrpp511czby/v5RXXNAMwNvfPvRrOzpGf81t2wrHM2YUjp8cNoi9p71XWlrg6qt3fX36dPjCF3b/GpIkSeXkFI46kxJ85CPwhz/A3/wNbNmSraAx3C95KQCXczVXfrSZo48e/fUmTYK2pr4R7cWvOXv20AnKL3hB4Xj+/DH/CJIkSVVlgK4zy5fDJz8JJ54In/1sNrq7fn3h+jMb/sRneD+nv2kh6ZxzOep1z971i+V0ffpqdhIsuWVLvm3FisL1mZOHLsvxV39VOJ43b69/FEmSpKowQNeZZcuGnqcE37i+sAnKPwy8j/fzj9mCzj/5ydB1m3elo4MA5rQUhp07l3YXrnd1Del+4YWFY0egJUnSRGOArjOPPTb0/Ntf7eKp9YX/DGb9+kdw223wlrfseveS4WbPBqDjS/+cb3pqWWE0umdTDwAzOvq4++5s5Y7Xvz675vrNkiRpojFA15FHHslycbEHlrUTFEagZ80OeOELs0/vleqcc+DYY+n4+ufzTRt2TM72AAd6tuxgNmtZdesj+SXyvvY12Lq19IwuSZK0rzBA14HNm2HJEnjtawttM3kqf/xyfpY/njVrL75BUxOcey4NRUF8O1PY8fNbAejZ2s8MNtIyb3b+emMjTJmyF99LkiSpygzQdeANb4DnPhfuuw8u4lv8J2dyI6/OX3829+SPd7Wu8x4V776Ss/HhNQD0dCda6YGpU/fyxSVJkvYdBugalxLccUdhGbkP8BnO5BZedOCj+bbDWMY7z8sWaJ60t/9F5AL08vd9juv+Lft+G9Zl+2/39JAF6MFtBSVJkiawigboiDg7Ih6JiKURceUo1w+OiFsj4g8RcV9EnFPJeurR0qWwbl1wLj/hAm7kOO6D228fss7cPDq55qq1pLSbF9qThQvh0UeZ9+l3c+iCbGLz4PJ4Pb1Ba0O/E54lSVJNqNhOhBHRAFwDnAV0AndFxKKU0oNF3T4C3JBSujYingUsBg6tVE31JiU48fh+oJGP8AlO4c7sQvFOJsD8lz4Ljjvu6X/DI44AYL/9stMNG7PA3LNjElMbR262IkmSNBFVcivvk4GlKaVlABHxHeB8oDhAJ2BwYuw0YGUF66k7K1bAtu5GzuZnPO+y58DKA+AlLxnRb973PgvN5fu++QC9KfsFR0/fJOY0DZTvG0iSJFVRJQP0QcDyovNO4HnD+nwM+GVEvBuYDIxMd9prdy/ZCUzio2/uJL5wzS77lfuzfYMreazbki2F19PXSGuzAVqSJNWGSs6BHm3C6/BZthcBX08pzQPOAf49IkbUFBGXRsSSiFiybt26CpRam+75XS/BTo5b2D3q9Z/9DD7zmfJ/344OmNzQzaqtU2D5cnr6G2ltfjoTrCVJkvYdlQzQnUDxRs3zGDlF4xLgBoCU0h1AKzBiJeKU0nUppZNSSifNnj17+GWN5rbbeGrJ40xnE5P3H33B5bPPhve/vzLffm7rRlatSnDwwfTsgNYWA7QkSaoNlQzQdwELI2JBRDQDFwKLhvV5EjgTICKeSRagHWIuhzPOoOumX9NOV1X2y547eQurmAtAD620thqgJUlSbahYgE4p9QOXA78AHiJbbeOBiPh4RLwy1+1vgbdFxL3At4E3pfS0FlOreynB6055gh9zHl20ZwF6r3dH2XtzO7YPCdBtbeNegiRJUkVU8kOEpJQWky1NV9z20aLjB4HTKllDvel8YoAb7jyEG/gx5/PDqo1AHzijm8UcSQJ6aKO1ZdxLkCRJqgh3Iqwxd9++NX98M2dWbQT6sP23s40OfjDrUgBaVz027jVIkiRVggG6xtx9Z2HDkm10VG0E+q1fOJGj5m7inZOuBWD6eaePew2SJEmVYICuMY88PHQKebUCdNvBs3nP301nzdrsP7EZLyzDToeSJEn7AAN0jXlyRcOQ8/Y2oLmM2wyOwamnFo6rMItEkiSpIgzQNeaJNa38L77Bi07dAUD7X76sarXsv3/heMaMqpUhSZJUVgboGtLbC6u2tHMYy3jBi7MFVlqnVm/5i1lFW+IYoCVJUq0wQE9kq1fDN7+ZP12+HFIKDmlbx/SZ2VSO/v5qFQdNTYVjp3BIkqRaYYCeyE49FV7/eti8GYAnn8yaD5nTzdSp2XFf3y6+dpwZoCVJUq3YY4COiMsjwl/A74sefzx7vv12AJ54Ijs9+PAmWnIzN3p7x7+s0RSPRkuSJE1kpYxAHwDcFRE3RMTZERGVLkp71r1qE3NZyY94JZx/Pnz3uzzxuzUAzD9qcj6w7isj0JIkSbVijwE6pfQRYCHwFeBNwKMR8amIOLzCtWk3/vxAD6uZyxV8Nmv4/e954tqfMpeVtBxywD4ToO+9FxYv3nM/SZKkiaKkOdAppQSszj36gRnAjRHxmQrWpt1Y3Tns04F9fTzGAg7hCTj2WE44IWt+7WvHv7Zixx0HL395dWuQJEkqp8Y9dYiI9wBvBJ4Cvgy8P6XUFxGTgEeBD1S2RI1m+fLs+TEO4+u8kcP/OJ3bOIP3nXgLnH02CyJbgaOhYfevI0mSpLEpZQR6FvCXKaWXpZS+l1LqA0gp7QTOq2h12qXOzsLxm/k6d92Tzdm48rLNkJumbniWJEkqv1IC9GJgw+BJRHRExPMAUkoPVaow7d7ylUNv3db12c6D05+x/2jdJUmSVCalBOhrgW1F59tzbaqiteuHDi9vYjptdNFw6PwqVSRJklQfSgnQkfsQIZCfurHHudOqoBUr6No6wKn8hut4GwAPcxQdbIW5c6tcnCRJUm0rJUAvi4j3RERT7vFeYFmlC9NuzJtH1/3LaKObBV/63wDczzFMaeiBRv9tI0mSVEmlBOh3AM8HVgCdwPOASytZlPasmzba6WLG/s0AdDKfjpYdVa5KkiSp9u1xuDKltBa4cBxq0Z7867/CU08B0EU7bXQzdVZz/vKU9p3VqkySJKlulLIOdCtwCXA00DrYnlJ6SwXr0ig2vOcqdjKJWRRGoDtmteSvd0ypXm2SJEn1opQpHP8OHAC8DLgdmAdsrWRRGt1MNnAgK4GiEejZhQA9ZcHsapUmSZJUN0oJ0EeklP4O2J5Suh44Fzi2smVpuO2Lbgagj2zKRhfttNNF29QmJuXuYsehM6tVniRJUt0oJUD35Z43RcQxwDTg0IpVpKEeewx+8xvuOP//5psS2RSONrqJSUFHR9Y+xSkckiRJFVdKgL4uImYAHwEWAQ8Cn65oVSp44xvhtNPoZF6+qZdmdtJAO10A+QA9+CxJkqTK2e2HCCNiErAlpbQR+C/gsHGpSgCsWQPXP3gef81v2cJUABrpo5s2gHyAHjRt2riXKEmSVHd2G6BTSjsj4nLghnGqR0W++1344PoP8AgzWcBjAPTTxKv4IQBtdAOwMvtcIUceWZUyJUmS6kopUzhuioj3RcT8iNhv8FHxypT/cOB/dZzL5rnPzLffzouAwgj0ztzyz0cdNZ7VSZIk1adS9n0eXO/5XUVtCadzVNyO3MaCm/va2dJxEKwaer3tK1cPOT/88HEqTJIkqY6VshPhgvEoRCP19GTPm3vb2XLs8+FPQ6+3H5BNen772+EHP4CmpnEuUJIkqQ6VshPhG0ZrTyl9o/zlqNjgCHTvzka+8/2R1wcGsucvfjF7SJIkqfJKmcLx3KLjVuBM4G7AAF1J69ezY1UAu55u3tq6y0uSJEmqkFKmcLy7+DwippFt761KOv10eh5+B/DeEZcO4XG+9st5vOglpfz7R5IkSeVUyiocw3UBC8tdiHIG52U8/DA7aBm1S9OUFs44q5GIcaxLkiRJQAkBOiJ+HBGLco+fAI8AP6p8aXXmne+ECDjrrHxTD60cwCredvqDQ7o2zps73tVJkiQpp5Q5AP9YdNwPPJFS6qxQPfUpJbj22uz41luz5zlz2LG2hals4bpLfscFH3kWq1bBm98Mjc7ckCRJqppSotiTwKqUUg9ARLRFxKEppccrWlk92bQpe541C556Crq6YOZMeta20koPtLbyspfBb3+bdTNAS5IkVU8pc6C/B+wsOh/ItalM0uNP0EcjnHIKCej/2Cdg+3Z20EILO/LLbQzuTGiAliRJqp5SAnRjSql38CR33Fy5kurPhz85mWb66DvpVD7NB2n6f59i25PrRwTowc8XGqAlSZKqp5QAvS4iXjl4EhHnA09VrqT68w/fzxY1WX3E6XyKDwOwmWn0UJjCATB/ftb/Na+pSpmSJEmitDnQ7wC+GRFX5847gVF3JxwuIs4GPgc0AF9OKf3DsOufBc7InbYDc1JK00t57VrR21s4XrXf0WxlKpCtwLGDFmawEVo7AJg3L5suPXVqNSqVJEkSlLaRyp+BUyJiChAppa2lvHBENADXAGeRhe67ImJRSim/JltK6Yqi/u8GThhj/RPaSScVRpUBnnfOzPxxN20jRqABpk0bzwolSZI0XCnrQH8qIqanlLallLZGxIyI+EQJr30ysDSltCw3b/o7wPm76X8R8O3Syp74Bgbg97+HH/5w9OuP8Awe4JhsDnRDw/gWJ0mSpF0qZQ70y1NKmwZPUkobgXNK+LqDgOVF5525thEi4hBgAXBLCa9bE9as2f31V/N9gCxApzQOFUmSJKkUpQTohojI7ykdEW2wiz2mhxpto+ldJcELgRtTSgOjvlDEpRGxJCKWrFu3roRvve9bubK0fptOeDEce2xli5EkSVLJSgnQ/x+4OSIuiYhLgJuA60v4uk6gaIYv84BdxcYL2c30jZTSdSmlk1JKJ82ePbuEb72P6+tjxa1/GtL0zedfM2rXx9Kh2RbfkiRJ2ieU8iHCz0TEfcBLyEaVfw4cUsJr3wUsjIgFwAqykPxXwztFxDOAGcAdY6h7YrvoIlZ8fw7wBX7F6UxnE8c858VcA/zmN0O7Pv54FeqTJEnSLpUyAg2wmmw3wguAM4GH9vQFKaV+4HLgF7n+N6SUHoiIjxevK0324cHvpFRHE30XL2YlB9JAP6dyB8fwAOy3HzffDPffP7TrP/1TdUqUJEnS6HY5Ah0RR5KNGl8ErAe+S7aM3Rm7+prhUkqLgcXD2j467PxjY6h34lu7Frq7WcFBHMBqGgZ3SZ81i9ZWmDOn0HXNmqHnkiRJqr7dTeF4GPgV8IqU0lKAiLhiN/1VivvuA2AFB3EQK+CKK7J1ni++GID29kJXN0yRJEna9+wuQF9ANgJ9a0T8nGwdZz/N9nR1dgJZgH4Gj8BFF8Fzn5u/3NZW6NpSylonkiRJGle7nAOdUvpBSul1wFHAbcAVwP4RcW1EvHSc6qs927YBsJIDOZCVI7YWnFR0R1x8Q5Ikad+zxw8RppS2p5S+mVI6j2wpunuAKyteWa3ato0u2tjEjGwKh3tzS5IkTSilrsIBQEppQ0rp31JKL65UQTVv61aWTzoUgHl0OtFZkiRpghlTgNbeefRRuOwy6O8Htm3jkdbjAbI50K2t1S1OkiRJY2KALreLL4arrhrR9MUvwh9f8C74/Od5uOkYAJ7xp5840VmSJGmC2eNOhBqjb30re77qqvwnArdsyZq233EvAA+nZzB3LkxbOPoiz7fcAtOnV7xSSZIk7QVHoCvl3nvzh7292fMa9gdg6Y75LFy46y894ww44YRKFidJkqS9ZYCulM2b84eDAXot2Yjzyr45HHhgNYqSJEnS02WALqeUCseDqRno6cme1zKHBKzaOYe5c8e3NEmSJJWHAbqcduwoHOcC9M6dsH591rSG/dlKB11MNkBLkiRNUAbocuruLhznAnTRQDRr2g7lUq4DMEBLkiRNUK7CUU49PWynnWZ6acol5+JB6Vv7/4KNdAAGaEmSpInKEehy6ulhCts5j5+MGIF+BT9mY19Hvuv8+dUoUJIkSU+XAbqMtm/Ihpt/ycuy5Pzww/TOOQiA47kn3++tb4Ujj6xKiZIkSXqaDNBl9Kc/Zc/BzixA//zn9NIMwAGszvd76UurUZ0kSZLKwQBdRg//KfvjPJw/s3TZJPofepQdtACwX8OWfL9p06pSniRJksrAAF1Gf34i+0zmbNax8J/ewauue3l+BLplelu+n9t0S5IkTVwG6DLatjXbSKWLdgB+ynl0kwXn5v2m5Ps5Ai1JkjRxGaDLqKsrC9DbKITl33EyAM2zpubbHIGWJEmauAzQZdS1PXveSmG5up/xcgBa2gp/1I5AS5IkTVwG6DLq6g5gaIC+ibMAaD6msG5da+v41iVJkqTycSfCMurqyQJ0d24OdAdb2Eo2daP59a/lC0fB975XtfIkSZJUBo5Al1FXz9A/zlO5I3/c3DqJyy6DW24Z76okSZJUTgboMurqaRhyfvKcJ/LHzc3jXY0kSZIqwQBdRl29QwP0vPYN+eOWlvGuRpIkSZVggC6jrt6mIeez27fnjx2BliRJqg0G6DLq6hv6mczZU7rzxwZoSZKk2mCALofHH4ejj6Zr68CQ5lkdO/LHBmhJkqTaYIAug84bfsNrHvwY65k1pL1tcuGP1znQkiRJtcEAXQa3/bqRG3nNiPaW9sKHCpuaRlyWJEnSBGSALoNNKwofFpwaW/LHLZMLc6In+SctSZJUE4x1ZbBxTW/+eNqkbfnj4gAtSZKk2mCALoONGwvHUxsKAbp5svM2JEmSao0Bugw29U3OH09t6MofNz5wbzXKkSRJUgUZoMtg485p+eOOxkKAjrdewumnV6MiSZIkVYqTdJ+Ob30LIti486B8U0djYfMUXvEKbjkb+vurUJskSZIqwgD9dFx8MQCbuCff1NHYM6RLU5NL2EmSJNUSp3CUwUam5487mrp301OSJEkTnQG6DDYyI3/c0WCAliRJqmUVDdARcXZEPBIRSyPiyl30eW1EPBgRD0TEtypZTyX008BWpubPJ0/KAvSznlWtiiRJklRJFZsDHRENwDXAWUAncFdELEopPVjUZyHwIeC0lNLGiJhTqXrKrb8f7ud45rN8SPtZM5bQ84ZLueKKKhUmSZKkiqrkCPTJwNKU0rKUUi/wHeD8YX3eBlyTUtoIkFJaW8F6ymrRIjiRu3mAo4e0z2rcxMc/DjNm7OILJUmSNKFVMkAfBEOGZztzbcWOBI6MiP+OiN9GxNkVrKesNm2CxCQeY8GQ9hZ2VKkiSZIkjYdKLmMXo7SlUb7/QuBFwDzgVxFxTEpp05AXirgUuBTg4IMPLn+le2FgIHtexdwh7a1hgJYkSapllRyB7gTmF53PA1aO0udHKaW+lNJjwCNkgXqIlNJ1KaWTUkonzZ49u2IFj8WuAnTLpL4qVCNJkqTxUskAfRewMCIWREQzcCGwaFifHwJnAETELLIpHcsqWFPZDO4uuJoDhrS3RG8VqpEkSdJ4qViATin1A5cDvwAeAm5IKT0QER+PiFfmuv0CWB8RDwK3Au9PKa2vVE3lNNCfzUYZHqAbY6Aa5UiSJGmcVHQr75TSYmDxsLaPFh0n4G9yj33fwACsWgXz5tG/YwBoZDUH0Egf/eT2607Dp3lLkiSplrgT4Vh873uwcCFs3sxAbzbSvJlptNJT6LNzZ5WKkyRJ0ngwQI/FmjXQ0wMbNuRGoGEbU2jCDw5KkiTVCwN0iXbuhBkfejtf5O3Q1cVAXzbSvJ0pNNJf6OgUDkmSpJpmgC5Rby9s6m7lMr4I27fnR6ABR6AlSZLqiAG6RAPFi2sUjUDDsADtCLQkSVJNq+gqHLVkRIDuLTQ00s/fn/ZL1v/3QwZoSZKkGucIdIn6i6Y579zWRX/v0BHoj77wdj7HXxueizCkAAALyUlEQVSgJUmSapwBukTFI9Dr1/SPnMLR6GC+JElSPTBAl6g4QPdt20F/UYBupB+OPx5e+EK49toqVCdJkqTx4rBpiYoDdP/2HSNHoNvb4bbbxr8wSZIkjStHoEs0JEBv66G/tzDXuYk+aGioQlWSJEkabwboEhUH6IGuHQz0D5vC4RxoSZKkumCALtGQEeiuXvr7HIGWJEmqRwboEo0cgS4E6Eb6DdCSJEl1wgBdouJ1oB2BliRJql8G6BINmcLR3TdyFQ4DtCRJUl0wQJdoyBSO7t4hAdopHJIkSfXDpSNKNOJDhANO4ZAkSapHBugSDRmB7uljAAO0JElSPTJAl2jICHRPP/0NrsIhSZJUj5wDXaIRI9D9jkBLkiTVIwN0iYYsY9fTT39RoDZAS5Ik1Q8DdImGTOHYMeBGKpIkSXXKAF2iIVM4+ncOGZF2BFqSJKl+GKBLNGQEmkY3UpEkSapTBugSDRmBpmHIVt5O4ZAkSaofBugSjRiBdhUOSZKkumSALtGIAJ0mEWTTOAzQkiRJ9cMAXaIRUzhopL2xF3AKhyRJUj0xQJeoeM5zP40M0MDk5j7AEWhJkqR6YoAu0UBvYQh6cAR6cmvWZoCWJEmqHwboEg1s78kf50egZ7YBTuGQJEmqJwboEg107SgcX/Ba+lunMGVmC+AItCRJUj0xQJdoYHt3/rj/lL9gYNpMDjsMTp79GCdwD0zyj1KSJKkemPpKVDwC3d+fPaZPhztf988c2/hQFSuTJEnSeGqsdgETxUBXb+F4IHs0NABNzU7fkCRJqiMG6BINH4EeGIDGRuDCC2HOnOoVJkmSpHFlgC5R/7AR6P7BhTee+9zsIUmSpLrgHOgSDXQXAvTgHOhG//khSZJUdwzQJSoO0F1d0NcHU6ZUsSBJkiRVRUUDdEScHRGPRMTSiLhylOtvioh1EXFP7vHWStaz1/74Rwb+8xYAWlpgw4asedq0KtYkSZKkqqjYJISIaACuAc4COoG7ImJRSunBYV2/m1K6vFJ1lEV7OwNkK200NxcC9NSpVaxJkiRJVVHJEeiTgaUppWUppV7gO8D5Ffx+lXP44QzM3B+ApibYuDFrNkBLkiTVn0oG6IOA5UXnnbm24S6IiPsi4saImF/Bep6Wgbe+nYaGRGOjI9CSJEn1rJIBOkZpS8POfwwcmlI6DvhP4PpRXyji0ohYEhFL1q1bV+YySzNAAw0NMSRAOwdakiSp/lQyQHcCxSPK84CVxR1SSutTSoM7lHwJeM5oL5RSui6ldFJK6aTZs2dXpNg9GVy2rqHBEWhJkqR6VskAfRewMCIWREQzcCGwqLhDRMwtOn0l8FAF63laBrfubmzMwjQYoCVJkupRxVbhSCn1R8TlwC+ABuCrKaUHIuLjwJKU0iLgPRHxSqAf2AC8qVL1PF2DAbqhodDmFA5JkqT6U9G99FJKi4HFw9o+WnT8IeBDlayhXIpHoCFbjaOlpbo1SZIkafy5E2GJhgfoadMgRvuYpCRJkmqaAbpEw6dwHHFEdeuRJElSdRigS9DbC6tWZSPO+2f7qXDUUdWtSZIkSdVhgC7BnXfCT38KkyfDc3IL7c2YUd2aJEmSVB0G6BIcfjhccw1cfz2ce27Wdtpp1a1JkiRJ1VHRVThqxYEHwjvfWThfvbowlUOSJEn1xRHovWB4liRJql8GaEmSJGkMDNCSJEnSGBigJUmSpDEwQEuSJEljYICWJEmSxsAALUmSJI2BAVqSJEkaAwO0JEmSNAYGaEmSJGkMDNCSJEnSGERKqdo1jElErAOeqNK3nwU8VaXvrfHhPa4P3uf64H2uD97n+lCt+3xISmn28MYJF6CrKSKWpJROqnYdqhzvcX3wPtcH73N98D7Xh33tPjuFQ5IkSRoDA7QkSZI0Bgbosbmu2gWo4rzH9cH7XB+8z/XB+1wf9qn77BxoSZIkaQwcgZYkSZLGwABdgog4OyIeiYilEXFltevR3ouI+RFxa0Q8FBEPRMR7c+37RcRNEfFo7nlGrj0i4vO5e39fRJxY3Z9ApYqIhoj4Q0T8JHe+ICLuzN3j70ZEc669JXe+NHf90GrWrdJFxPSIuDEiHs69p0/1vVx7IuKK3N/X90fEtyOi1ffzxBcRX42ItRFxf1HbmN+/EfHGXP9HI+KN41W/AXoPIqIBuAZ4OfAs4KKIeFZ1q9LT0A/8bUrpmcApwLty9/NK4OaU0kLg5tw5ZPd9Ye5xKXDt+JesvfRe4KGi808Dn83d443AJbn2S4CNKaUjgM/m+mli+Bzw85TSUcDxZPfb93INiYiDgPcAJ6WUjgEagAvx/VwLvg6cPaxtTO/fiNgPuAp4HnAycNVg6K40A/SenQwsTSktSyn1At8Bzq9yTdpLKaVVKaW7c8dbyf6HexDZPb0+1+164FW54/OBb6TMb4HpETF3nMvWGEXEPOBc4Mu58wBeDNyY6zL8Hg/e+xuBM3P9tQ+LiKnAC4CvAKSUelNKm/C9XIsagbaIaATagVX4fp7wUkr/BWwY1jzW9+/LgJtSShtSShuBmxgZyivCAL1nBwHLi847c22a4HK/2jsBuBPYP6W0CrKQDczJdfP+T0z/AnwA2Jk7nwlsSin1586L72P+Hueub871177tMGAd8LXcVJ0vR8RkfC/XlJTSCuAfgSfJgvNm4Pf4fq5VY33/Vu19bYDes9H+5erSJRNcREwBvg/8dUppy+66jtLm/d+HRcR5wNqU0u+Lm0fpmkq4pn1XI3AicG1K6QRgO4Vf947G+zwB5X4dfz6wADgQmEz26/zhfD/Xtl3d16rdbwP0nnUC84vO5wErq1SLyiAimsjC8zdTSv+Ra14z+Ovc3PPaXLv3f+I5DXhlRDxONuXqxWQj0tNzvwKGofcxf49z16cx8teK2vd0Ap0ppTtz5zeSBWrfy7XlJcBjKaV1KaU+4D+A5+P7uVaN9f1btfe1AXrP7gIW5j7x20z24YVFVa5Jeyk3F+4rwEMppX8uurQIGPz07huBHxW1vyH3CeBTgM2Dv17Sviml9KGU0ryU0qFk79dbUkoXA7cCr851G36PB+/9q3P9HbHax6WUVgPLI+IZuaYzgQfxvVxrngROiYj23N/fg/fZ93NtGuv79xfASyNiRu63FS/NtVWcG6mUICLOIRvBagC+mlL6ZJVL0l6KiNOBXwF/pDA/9sNk86BvAA4m+wv7NSmlDbm/sK8m+1BCF/DmlNKScS9ceyUiXgS8L6V0XkQcRjYivR/wB+D1KaUdEdEK/DvZfPgNwIUppWXVqlmli4hnk31QtBlYBryZbGDI93INiYi/B15HtorSH4C3ks1z9f08gUXEt4EXAbOANWSrafyQMb5/I+ItZP8fB/hkSulr41K/AVqSJEkqnVM4JEmSpDEwQEuSJEljYICWJEmSxsAALUmSJI2BAVqSJEkaAwO0JE0gETEQEfcUPXa3+95YX/vQiLi/XK8nSbWqcc9dJEn7kO6U0rOrXYQk1TNHoCWpBkTE4xHx6Yj4Xe5xRK79kIi4OSLuyz0fnGvfPyJ+EBH35h7Pz71UQ0R8KSIeiIhfRkRb1X4oSdpHGaAlaWJpGzaF43VF17aklE4m27HrX3JtVwPfSCkdB3wT+Hyu/fPA7Sml44ETgQdy7QuBa1JKRwObgAsq/PNI0oTjToSSNIFExLaU0pRR2h8HXpxSWhYRTcDqlNLMiHgKmJtS6su1r0opzYqIdcC8lNKOotc4FLgppbQwd/5BoCml9InK/2SSNHE4Ai1JtSPt4nhXfUazo+h4AD8rI0kjGKAlqXa8ruj5jtzxb4ALc8cXA7/OHd8MXAYQEQ0RMXW8ipSkic6RBUmaWNoi4p6i85+nlAaXsmuJiDvJBkcuyrW9B/hqRLwfWAe8Odf+XuC6iLiEbKT5MmBVxauXpBrgHGhJqgG5OdAnpZSeqnYtklTrnMIhSZIkjYEj0JIkSdIYOAItSZIkjYEBWpIkSRoDA7QkSZI0BgZoSZIkaQwM0JIkSdIYGKAlSZKkMfgfj3RTSBxrj1QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,(ax0) = plt.subplots(nrows=1, figsize=(12,5))\n",
    "ax0.plot(acc_training.history['acc'],'red', label='Akurasi Training')\n",
    "ax0.plot(acc_training.history['val_acc'], 'blue', label='Akurasi Validasi')\n",
    "ax0.plot(label='Accuracy', loc='upper left')\n",
    "ax0.set_title('Model Accuracy')\n",
    "ax0.set_xlabel(\"Epoch\")\n",
    "ax0.set_ylabel(\"Accuracy\")\n",
    "ax0.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">Perintah dibawah ini untuk menampilkan Grafik Loss.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1d0573a9ac8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,(ax1) = plt.subplots(nrows=1, figsize=(12,5))\n",
    "ax1.plot(acc_training.history['loss'],'red', label='Loss Training')\n",
    "ax1.plot(acc_training.history['val_loss'], 'blue', label='Loss Validasi')\n",
    "ax1.plot(label='Loss', loc='upper left')\n",
    "ax1.set_title('Model Loss')\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix adalah salah satu metode yang dapat digunakan untuk mengukur kinerja suatu metode klasifikasi.Pada pengukuran kinerja menggunakan confusion matrix, terdapat 4 (empat) istilah sebagai representasi hasil proses klasifikasi yaitu :\n",
    "1. TP adalah True Positive, yaitu jumlah data positif yang terklasifikasi dengan benar oleh sistem.\n",
    "2. TN adalah True Negative, yaitu jumlah data negatif yang terklasifikasi dengan benar oleh sistem.\n",
    "3. FN adalah False Negative, yaitu jumlah data negatif namun terklasifikasi salah oleh sistem.\n",
    "4. FP adalah False Positive, yaitu jumlah data positif namun terklasifikasi salah oleh sistem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berdasarkan nilai True Negative (TN), False Positive (FP), False Negative (FN), dan True Positive (TP) dapat diperoleh nilai Accuracy, Specificity, Sensitivity, Precision, dan F1 Score. Untuk memperoleh nilai akurasi, presisi dan recall kita dapat menggunakan rumus :\n",
    "\n",
    "$$Accuracy = \\frac {tp+tn}{tp+tn+fp+fn}$$\n",
    "\n",
    "$$Specificity = \\frac {tn}{tn+fp}$$\n",
    "\n",
    "$$Sensitivity = \\frac {tp}{tp+fn}$$\n",
    "\n",
    "$$Precision = \\frac {tp}{tp+fp}$$\n",
    "\n",
    "$$F1 Score = \\frac {2 \\times Sensitivity \\times Precision}{Sensitivity+ Precision}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk dapat menghitung Confusion Matrix pada dataset yang telah diolah, kita deklarasikan model predict dari data training dan data testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_predicted = model.predict(trainX)\n",
    "testing_predicted = model.predict(validateX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "training_cm = confusion_matrix(trainY,training_predicted.round())\n",
    "testing_cm = confusion_matrix(validateY,testing_predicted.round())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"><font color=\"black\">Hasil Confusion Matrix dari data training</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1082   34]\n",
      " [  14 1087]]\n"
     ]
    }
   ],
   "source": [
    "print(training_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perolehan nilai Accuracy, Specificity, Sensitivity, Precision, dan F1 Score pada data training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy training 0.9783491204330176\n",
      "Specificity training 0.9872842870118075\n",
      "Sensitivity training 0.9695340501792115\n",
      "Precision training 0.9872262773722628\n",
      "F1 Score training 0.9783001808318263\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "tp = training_cm[0][0]\n",
    "fn = training_cm[0][1]\n",
    "fp = training_cm[1][0]\n",
    "tn = training_cm[1][1]\n",
    "\n",
    "accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "specificity = tn/(tn+fp)\n",
    "sensitivity = tp/(tp+fn)\n",
    "precision = tp/(tp+fp)\n",
    "f1_score = (2*sensitivity*precision)/(sensitivity+precision)\n",
    "\n",
    "print(\"Accuracy training {0}\".format(accuracy))\n",
    "print(\"Specificity training {0}\".format(specificity))\n",
    "print(\"Sensitivity training {0}\".format(sensitivity))\n",
    "print(\"Precision training {0}\".format(precision))\n",
    "print(\"F1 Score training {0}\".format(f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"><font color=\"black\">Hasil Confusion Matrix dari data testing</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[294  12]\n",
      " [  8 320]]\n"
     ]
    }
   ],
   "source": [
    "print(testing_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perolehan nilai Accuracy, Specificity, Sensitivity, Precision, dan F1 Score pada data testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy testing 0.9684542586750788\n",
      "Specificity testing 0.975609756097561\n",
      "Sensitivity testing 0.9607843137254902\n",
      "Precision testing 0.9735099337748344\n",
      "F1 Score testing 0.9671052631578948\n"
     ]
    }
   ],
   "source": [
    "tp = testing_cm[0][0]\n",
    "fn = testing_cm[0][1]\n",
    "fp = testing_cm[1][0]\n",
    "tn = testing_cm[1][1]\n",
    "\n",
    "accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "specificity = tn/(tn+fp)\n",
    "sensitivity = tp/(tp+fn)\n",
    "precision = tp/(tp+fp)\n",
    "f1_score = (2*sensitivity*precision)/(sensitivity+precision)\n",
    "\n",
    "print(\"Accuracy testing {0}\".format(accuracy))\n",
    "print(\"Specificity testing {0}\".format(specificity))\n",
    "print(\"Sensitivity testing {0}\".format(sensitivity))\n",
    "print(\"Precision testing {0}\".format(precision))\n",
    "print(\"F1 Score testing {0}\".format(f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.Referensi\n",
    "<ul>\n",
    "    <li>Paper: <b>Voice based gender classification using machine learning.</b></li>\n",
    "    A. Raahul, R. Sapthagiri, K. Pankaj, and V. Vijayarajan, â€œVoice based gender classification using machine learning,â€ IOP Conf. Ser. Mater. Sci. Eng., vol. 263, no. 4, 2017<br><br>\n",
    "    <li>Dataset: <a href=\"https://www.kaggle.com/primaryobjects/voicegender\">https://www.kaggle.com/primaryobjects/voicegender</a></li>\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
